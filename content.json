{"pages":[],"posts":[{"title":"GDB 源码分析 01：函数前导代码分析（上）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 函数前导代码其实很简单也很固定，它主要就是进入一个函数时进行的代码操作，用来建立栈帧，并为临时变量开好空间。这里展示一个 x86 汇编的最简单情形： 123push ebpmov ebp, espsub esp, N 很简单，很友好，不是吗？ 那么为什么要对这块代码进行重点分析呢？一方面，这是一个函数开头的部分，可以用来分析这个函数调用栈的情况，并分析这个函数所使用的临时变量地址；另一方面，虽然看起来这段代码很可爱，但是随着编译器的复杂化和在调度指令时日益激进的策略，它往往会变得面目全非。但无论如何，这段代码总归是相对简单的部分。 事实上，在现代的 gcc 编译器中往往会给出调用栈信息（call frame information, CFI），其中描述了如何寻找栈的基地址和存储的寄存器等信息，但是这些信息并不总是存在。如果它们不存在，我们就必须采用一些策略来试图解读这些信息。为了解读这些信息，我们就采用一种对指令“抽象解读”的策略，也就是下面将介绍的模糊计算策略。 值的模糊计算在 prologue-value.h 中，定义了如下结构： 12345enum prologue_value_kind { pvk_unknown, pvk_constant, pvk_register}; 这里所描述的是一个 prologue 值的类型，分别表示未知、常数和寄存器，它决定了在下面的结构体中，后面两个参数应该如何解读。 123456struct prologue_value { enum prologue_value_kind kind; int reg; CORE_ADDR k;};typedef struct prologue_value pv_t; 如果类型是 pvk_unknown，那么后面两个参数都没有意义，毕竟我们对它一无所知； 如果类型是 pvk_constant，这表明这个值就是常数，记录在 k 中。注意，所谓的 CORE_ADDR 实际上就是一个 uint64_t； 如果类型是 pvk_register，这表明寄存器 reg 所对应的原始值为 初始值 + k ，其中 reg 为 GDB 标定的寄存器编号，是为了防止不同架构带来的跨平台问题。在开始分析之前，所有寄存器都会被标为 {pvk_register, reg, 0} 每个类型都有相关的初始化函数，它们实现起来并不困难： 1234567891011121314151617181920pv_t pv_unknown(void) { pv_t v = {pvk_unknown, 0, 0}; return v;}pv_t pv_constant(CORE_ADDR k) { pv_t v; v.kind = pvk_constant; v.reg = -1; v.k = k; return v;}pv_t pv_register(int reg, CORE_ADDR k) { pv_t v; v.kind = pvk_register; v.reg = reg; v.k = k; return v;} 随后我们要对这些值进行“保守估计”，保守估计的意思是说，我们会把一个值正确估计或者设为未知，但不能出现错误的估计。对应于这种估计方式的逻辑变量是这样的： 12345enum pv_boolean { pv_maybe, pv_definite_yes, pv_definite_no}; 然后通过看相关的函数来理解其原理： 1234567static void constant_last(pv_t *a, pv_t *b) { if (a-&gt;kind == pvk_constant &amp;&amp; b-&gt;kind != pvk_constant) { pv_t temp = *a; *a = *b; *b = temp; }} 这个函数就是个辅助函数。如果前者是常数而后者不是常数，对两者做个交换。这个函数在后面只是用来减少需要处理的情况总数的。接下来是对一大批寄存器运算的模拟。 1234567891011121314pv_t pv_add(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k + b.k); } else if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k + b.k); } else { return pv_unknown(); }}pv_t pv_add_constant(pv_t v, CORE_ADDR k) { return pv_add(v, pv_constant(k));} 首先实现加法的计算。这里的过程看起来很简单：两个常数可以加，寄存器可以加上常数，但其他的加法都返回未知。如果要处理常数加法，那就将常数转换成对应的类型再相加。这里不妨停一下思考两个问题： 为什么寄存器和寄存器不能相加？ 为什么常数加法的情况在两个函数中都进行了处理？ 这里我们需要注意，我们并不会实际执行程序，只是取其中的一个片段进行分析。在分析这个片段的时候，寄存器的初始值是未知的。因此，我们总共知道的就是，某个寄存器相比其进入这个片段之前多了或者少了多少。如果将寄存器与寄存器相加，那么势必要用到初始值，也就是说，它的结果对我们来说是未知的。 对于第二个问题，需要注意，加常数的情况并不仅仅存在于显式的指令编码中。例如，在下面将读到的 logical_and 函数中，如果出现与常数 0 做 and 操作，这个寄存器的值就会变成常数 0 ，于是，当它与另一个寄存器相加时，就会进入寄存器与常数相加的情形。 接下来按照这个思路，可以很简单的实现减法和逻辑与运算，代码如下： 1234567891011121314151617181920212223242526272829pv_t pv_subtract(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg) { return pv_constant (a.k - b.k); } else { return pv_unknown(); }}pv_t pv_logical_and(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k &amp; b.k); } else if (b.kind == pvk_constant &amp;&amp; b.k == 0) { return pv_constant(0); } else if (b.kind == pvk_constant &amp;&amp; b.k == ~(CORE_ADDR) 0) { return a; } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg &amp;&amp; a.k == b.k) { return a; } else { return pv_unknown(); }} 这两段的代码逻辑也相当清晰，如果理解了什么叫做保守估计，那么应该也能很轻松地读懂。主要的难点在于理解什么情况下可以对这个操作做出准确的估计，什么时候不能。基于这些计算方式，我们就可以基本上知道某段代码结束之后，能得到怎样的结果了。 这里需要注意，如果出现了除算术指令之外的其他指令，其结果就基本上全是 pvk_unknown 了。所以，这里所做的只是一个前导代码分析，因为函数的前导代码往往不会包含太复杂的东西。 对模糊值做出判断当我们知道一段代码运行之后的结果之后，我们就可以尝试确定一些东西了，比如某个对象是否落在一个数组里。但在进行这些判断之前，先要有三个最普通的判断函数：判断某个值是否是常数、是否是某个寄存器、是否是某寄存器 初始值 + k 的结果，这三个函数将成为后面应用的基石。 1234567891011int pv_is_constant(pv_t a) { return (a.kind == pvk_constant);}int pv_is_register(pv_t a, int r) { return (a.kind == pvk_register &amp;&amp; a.reg == r);}int pv_is_register_k(pv_t a, int r, CORE_ADDR k) { return (a.kind == pvk_register &amp;&amp; a.reg == r &amp;&amp; a.k == k);} 接下来我们要开始考虑，如何判断一个对象是否落在某个数组里。很显然，我们需要考虑如何描述一个对象和如何描述一个数组。我们需要的参数有： 描述一个对象在内存中的位置和长度，pv_t addr 和 CORE_ADDR size； 描述一个数组在内存里的位置和长度，pv_t array_addr 和 array_len （数组长度），以及 CORE_ADDR elt_size （数组内每个元素的大小）； 返回值，是不是指向某个完整元素，以及如果指向某个完成元素，其对应的指标 int *i。 在开始考虑如何写这个函数之前，我们需要明确地指出这个函数的功能以及它的返回类型。它的返回类型是 enum pv_boolean 型： 如果这个对象一定落在数组中，那么返回 pv_definite_yes ，并把 I； 如果这个对象一定不落在数组中，那么返回 pv_definite_no； 如果不能判断、或者不指向完整的数组元素，那么返回 pv_maybe 。 好，接下来可以开始写这个函数了： 1234567891011121314151617enum pv_boolean pv_is_array_ref(pv_t addr, CORE_ADDR size, pv_t array_addr, CORE_ADDR array_len, CORE_ADDR elt_size, int *i) { pv_t offset = pv_subtract(addr, array_addr); if (offset.kind == pvk_constant) { if (offset.k &lt;= -size &amp;&amp; offset.k &gt;= array_len * elt_size) { return pv_definite_no; } else if (offset.k % elt_size != 0 || size != elt_size) { return pv_maybe; } else { *i = offset.k / elt_size; return pv_definite_yes; } } else { return pv_maybe; }} 这里的逻辑其实很简单：如果对象的起始地址和数组起始地址不能相减或相减不为常数，我们都不能严格做出判断。然后我们考虑这样的情形： 这里就是第一个比较的来源：只有当 offset &lt;= -size 时，才能明确判断说这个元素不在数组内，同样的，第二个比较发生在右边。然后检查是否对齐。如果不对齐，那只能是 pv_maybe。只有当对齐且元素大小等于数组元素大小，且偏移量落在数组之内时，才会返回 pv_definite_yes 。 我们上面的这些工作都只是完成了这个模块的第一部分。为了真正让这个模块得以被使用，还需要具备分析一个内存块的内容的能力。这就是第二部分将要讨论的内容。","link":"/blog/5ad3ba87/"},{"title":"从 Kolmogorov 复杂度到 Martin Löf 随机性检验（上）","text":"Per Martin-Löf, The Definition of Random Sequences, Information and Control, 9, 602-619(1966) 考虑一个在有限字母表中所有字符串的集合。记字符串 \\(x = \\xi_1\\xi_2\\dots\\xi_n\\) 的长度 \\(l(x) = n\\)。接下来我们需要考虑的问题是，这个序列有多复杂？ 很显然，直观地讲，一个“随机”（我们很快会回到这一点上来）字符串要比一个有规律的字符串复杂地多。同样很直观地，我们可以把一个字符串的复杂度定义为某种“最简单的描述方法的长度”，Kolmogorov 算术复杂度就是从这个视角出发做出的形式化定义。 “描述方法”和 Kolmogorov-Solomonoff 定理 接下来我们需要反思，“描述方法”应该如何被形式化地定义出来？既然本文的 tag 中带有计算理论，很自然的一种想法就是，“描述方法”就是一种算法。 在这里，我们使用“算法”这个概念来表达一种从一个有限二进制序列到一个有限字母表上的单子的映射。算法概念的更精确的形式化定义可以采用递归论的定义模式或者其他等价的形式（本文中将不再展开），这并不影响后文的探讨。 记 \\(A\\) 为一种算法，\\(A(p) = x\\)，\\(p\\) 为一个有限二进制串，\\(x\\) 为一个有限字母表上的字符串，我们称 \\(p\\) 是在算法 \\(A\\) 下对 \\(x\\) 的描述。接下来，延续我们前面的直观认识，我们可以定义相对于算法 \\(A\\) 字符串 \\(x\\) 的复杂度为： \\[ K_A(x) = \\min\\limits_{A(p) = x}(l(p)) \\] 那么，很自然的一个问题是，是否一定存在这样的二进制串 \\(p\\) 来对任意字符串 \\(x\\) 做出描述？答案是否定的。只要考虑一个平凡的算法 \\(A_0\\)，它将任意二进制串 \\(p\\) 都映射到字符串 \\(x_0\\)，那么，其他的字符串就都不能在这个算法下做出描述。因此，为了定义的严谨性，我们需要补充说明： \\[ K_A(x) = + \\infty, \\mathrm{if}\\ \\forall p, A(p) \\neq x \\] 现在，我们剩下的一个问题就是，我们不能摆脱算法 \\(A\\) 对我们的定义的限制。我们在考虑一个序列的复杂度时，很显然不是要考虑一个字符串“在某种描述方法下”的复杂度，我们需要使得它成为一个只与字符串 \\(x\\) 有关的数。为了实现这个定义，就需要引入 Kolmogorov-Solomonoff 定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(x) \\leqslant K_B(x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 这个算法在 Kolmogorov 的著作中被称为渐进最优的（asymptotically optimal），在 Solomonoff 的著作中被称为通用的（universial），上述定理的证明如果我不鸽的话会丢进本文的附录或者其他文章里。总之，现在我们已经有了一个最好的算法来讨论如何描述字符串 \\(x\\)，于是，我们就可以定义这个字符串的复杂度 \\(K(x) = K_A(x)\\)，称其为 Kolmogorov 复杂度，或者简单地称为复杂度。 同样地，我们可以引入条件复杂度的概念。考虑一个两变量的算法 \\(A(p, x)\\)，\\(x\\) 为一个有限字母表上的字符串，若 \\(A(p, x) = y\\)，则我们将其称为在 \\(x\\) 的条件下对（可能不同于 \\(x\\) 的）字母表上的字符串 \\(y\\) 的描述。称在 \\(x\\) 的条件下相对于算法 \\(A\\) 的 \\(y\\) 的复杂度为： \\[ K_A(y \\vert x) = \\min\\limits_{A(p, x) = y}(l(p)) \\] 这个定义也是很自然的，同样与上面的讨论和我们的直观感受匹配。幸运地是，亲爱的 Kolmogorov 先生同样给出了一个与上面的定理相对应的定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(y \\vert x) \\leqslant K_B(y \\vert x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 因此，我们也记 \\(K(y\\vert x) = K_A(y \\vert x)\\)，并称其为在 \\(x\\) 的条件下 \\(y\\) 的条件复杂度。 很直观的，对于任意长度为 \\(n\\) 的二进制串 \\(x\\)，都有 \\[ K(x \\vert n) \\leqslant n + c \\] 其中 \\(n\\) 是用于描述这个字符串所用的最多比特数，在最坏情况下，我们需要将整个串都硬编码到代码当中，那么当然需要 \\(n\\) 的长度。而 \\(c\\) 则是机器相关的常数。 同时，我们可以尝试给出一个下界，满足 \\[ K(\\xi_1\\xi_2\\dots\\xi_n \\vert n) \\geqslant n - c \\] 的序列一共有 \\((1-2^{-c})2^n\\) 个。这个结论也很平凡，留给读者自证。 于是，我们发现，当 \\(n\\) 很大的时候，会有很多字符串的复杂度的渐进上界是在 \\(O(n)\\) 这个最大的级别的。Kolmogorov 指出，这可以使我们形式化地定义一个字符串的随机性。 一些评述 看起来，对于二元算法的定义事实上意义不是很大，因为 \\(n\\) 同样可以以 \\(\\log n\\) 的复杂度编写到程序之中，这对于我们的结果并没有影响。事实上，很多较现代的论文提供了另外一种定义形式，例如 Peter D. Grünwald and Paul M. B. Vitányi, Algorithmic Information Theory 中给出的定义是： \\[ K(x) = \\min\\limits_{y, p: p(y) = x}(l(p) + l(y)) \\] 这种定义形式似乎更加符合我们的预期。另外，也将一个对象的 Kolmogorov 编码定义为 \\(E*(x)\\)，是最短的能够打印 \\(x\\) 然后停下的代码。 在这种定义形式下，我们就可以给出三种分类： 简单的对象：\\(O(\\log n)\\)，其原因已经在前面解释过了，因为 \\(n\\) 需要被硬编码进去 完全偶然对象（completely random objects）：\\(n + O(\\log n)\\)，也是显然的 随机对象（stochastic objects）：\\(\\alpha n + o(n)\\) 如果 \\(x_i\\) 是一个随机变量 \\(X_i\\) 的实现，其分布为 \\(P\\)，则这个对象是随机的，其中 \\(\\alpha &lt; 1\\)。比较常见的例子是二项分布，其 \\(\\alpha = H(p)\\) 为二值熵（binary entrophy） \\[ H(p) = -p\\log p - (1-p) \\log(1-p) \\] 随机对象的情形可以类比于扔一个有缺陷的硬币，硬币的缺陷使得这个序列不再成为完全随机的，当然，很显然，\\(p = 0.5\\) 时， \\(H(p) = 1\\)，序列还是完全偶然的。 另一个很遗憾的问题是，\\(K(x)\\) 不是可计算的，在 [Li and Vitányi, 1997] 中，他们表明它是上半可计算的（upper semicomputable），或者简单地理解就是，它是可以被近似的，但近似算法很慢，且不能确定其终点。但是，也有一些方式来解决这个问题，比如通用编码（[Cover and Thomas, 1991]），最小描述长度原理（MDL, [Solomonoff, 1997]）等方式的近似。 Blum 和 Burgin 的公理系统对于这个领域来说也是相当重要的，他们给出了关于这些性质的普遍描述，如果不鸽的话大概也会专门开一篇文章来介绍他们的成果，嗯，如果不鸽的话。","link":"/blog/dd3e0497/"},{"title":"GDB 源码分析 02：函数前导代码分析（中）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 上一次，我们考虑了如何对一个值进行模糊分析，接下来，我们要对一片内存的值做出模糊的估计。在有了这种估计方式之后，我们就能够将其进行真正的应用了。 首先考虑一个问题：如何记录一个内存中的数据？不要忘记，我们需要分析一个函数的前导代码，而前导代码往往做的是栈操作。那么，既然我们不能预先知道栈地址的值，我们自然就得以一个寄存器作为基地址，那么我们需要存储的就是某个地址距离基地址寄存器的偏移量；同时，内存中的对象并不自带类型，所以需要长度作为其标识；最后，我们还要记下它的值。这就是下面这个结构体想要做的事情： 123456struct pv_area::area_entry { struct area_entry *prev, *next; CORE_ADDR offset; CORE_ADDR size; pv_t value;} 注意到它有两个指向前后的指针。事实上，它构成了一个环形双向链表，在后面的分析中，我们还会看到，它是以偏移量的大小进行排序的。然后就是把这个双向链表包装成一个类： 123456class pv_area {private: int m_base_reg; CORE_ADDR m_addr_mask; struct area_entry *m_entry;} 其中除了指向这样一个链表的指针之外，还有基地址寄存器的寄存器号，以及一个地址的掩码。看到后面之后会更容易理解这个掩码的目的，在这里我们只需要简单地认为，我们的地址空间是一个环形，前后相连即可。 接下来看类里面的三个私有成员函数： 1234567891011void pv_area::clear_entries() { struct area_entry *e = m_entry; if (e) { do { struct area_entry *next = e.next; xfree(e); e = next; } while (e != m_entry); m_entry = 0; }} 这个函数用来清空双向链表。其中比较需要注意的就是 xfree 这个函数，事实上这个函数和内存保护有关，在读到这里的时候，我们不妨将其当成一个简单的 free 函数理解。 12345678910111213141516struct pv_area::area_entry *pv_area::find_entry(CORE_ADDR offset) { struct area_entry *e = m_entry; if (!e) { return 0; } while (((e-&gt;next-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;next; } while (((e-&gt;prev-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;prev; } m_entry = e; return e;} 这个函数用来找到在 offset 之后的第一项。如果本身这片区域一项也没有，那么就自然地返回一个空指针。而如果 offset 中一项也没有，那当然就会返回较为靠前的一项。这里需要澄清的是，因为 m_entry 指向的是环形链表中的任意一项，往后扫描和往前扫描都是必须的。最后一步将 m_entry 设为 e 就是出于局部性的假定，假定最近被访问的这项很可能再次被访问，从而提高整个数据结构的搜索效率。 在此不妨停下来思考一个问题：哪怕没有掩码的问题，是否有可能直接写成 e-&gt;next-&gt;offset &lt; e-&gt;offset ？答案是否定的，原作者在注释中特别表明了这一点： 123456/*Note that, even setting aside the addr_mask stuff, we must not simplify this, in high school algebra fashion, to (e-&gt;next-&gt;offset &lt; e-&gt;offset), because of the way &lt; interacts with wrap-around. We have to subtract offset from both sides to make sure both things we're comparing are on the same side of the discontinuity. */ 解释很清楚，在这也就不翻译了。 第三个函数就是一个判断 offset 处 size 大小的一项是否与某个 entry 重合，非常简单，直接贴代码不解释： 1234int pv_area::overlaps(struct area_entry *entry, CORE_ADDR offset, CORE_ADDR size) { return (((entry-&gt;offset - offset) &amp; m_addr_mask) &lt; size || ((offset - entry-&gt;offset) &amp; m_addr_mask) &lt; entry-&gt;size);} 接下来观察一下公有的成员函数，首先来看构建过程： 123pv_area::pv_area(int base_reg, int addr_bit): m_base_reg(base_reg), m_addr_mask(((((CORE_ADDR) 1) &lt;&lt; (addr_bit - 1)) - 1) &lt;&lt; 1) | 1), m_entry(nullptr){} 非常简单的构造函数，但是这里我们就可以重新解释一下地址掩码的含义了。当我们有一个 32 bit 的地址时，自然而然地我们只希望其比较 32 bit，但是寄存器又是可以有 64 bit 的：也就是说，有一部分是需要被抛弃的。 一个很细节的问题是，为什么不把这个表达式写成 ((CORE_ADDR) 1 &lt;&lt; addr_bit) - 1 ？注意，移位的位数与类型的宽度相同时，得到的结果是未定义的。如果采取上面代码的形式，就一定能够保证得到正确的结果。 析构函数非常简单： 123pv_area::~pv_area() { clear_entries();} 然后用了一个有趣的小技巧取消了默认析构函数和 operator=： 1DISABLE_COPY_AND_ASSIGN(pv_area); 宏定义如下，这是为了与不同版本的 c++ 标准兼容： 123456789#if defined(__cplusplus) &amp;&amp; __cplusplus &gt;= 201103#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;) = delete; \\ void operator= (const TYPE &amp;) = delete #else#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;); \\ void operator= (const TYPE &amp;)#endif 接下来我们就要正式进行模拟存取了。下面这个成员函数用来将一个 size 大小的值 value 写入到 addr 处： 123456789101112131415161718192021222324252627282930313233void pv_area::store(pv_t addr, CORE_ADDR size, pv_t value) { if (store_would_trash(addr)) { clear_entries(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); while (e &amp;&amp; overlaps(e, offset, size)) { struct area_entry *next = (e-&gt;next == e) ? 0 : e-&gt;next; e-&gt;prev-&gt;next = e-&gt;next; e-&gt;next-&gt;prev = e-&gt;prev; xfree(e); e = next; } m_entry = e; } if (value.kind == pvk_unknown) { return; } else { CORE_ADDR offset = addr.k; struct area_entry *e = XNEW(struct area_entry); e-&gt;offset = offset; e-&gt;size = size; e-&gt;value = value; if (m_entry) { e-&gt;prev = m_entry-&gt;prev; e-&gt;next = m_entry; e-&gt;prev-&gt;next = e-&gt;next-&gt;prev = e; } else { e-&gt;prev = e-&gt;next = e; m_entry = e; } }} 这个函数稍微有点长，但是思路其实挺简单的： 如果存储操作会使得我现在所有的表项都被无效化，那么直接先把表清掉； 否则的话，清掉所有与这个值重合的项，因为这些项都会被覆写掉； 然后，如果我需要存的值未知，那就直接返回； 如果我需要存的值已知，那就创建出这一项并把它插进去。 XNEW(T) 事实上拓展到了泛型 xnew&lt;T&gt;() ，这个函数和前面的 xfree 一样，只需要当成一个 new 就行，暂时不需要深究；接下来需要考虑的是，什么时候我可能无效化整个表： 12345bool pv_area::store_would_trash(pv_t addr) { return (addr.kind == pvk_unknown || addr.kind == pvk_constant || (addr.kind == pvk_register &amp;&amp; addr.reg != m_base_reg));} 事实上说这种情况可能无效化整个表是不准确的。准确地说，是我们不能确定这次存储和我们现在的表有什么关系，为了方便起见，我们就直接认为这整个表的分析是不可能的，因而就将其抛弃了。这个函数还会被在其他地方调用，比如，考虑取一个值的问题： 12345678910111213pv_t pv_area::fetch(pv_t addr, CORE_ADDR size) { if (!m_entry || store_would_trash(addr)) { return pv_unknown(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); if (e-&gt;offset == offset &amp;&amp; e-&gt;size == size) { return e-&gt;value; } else { return pv_unknown(); } }} 很显然，这个函数的核心还是保守估计。需要注意的是第一行判断，如果表里没有内容，或者这个地址和表无关，那就返回未知。这里，“和表无关”才是上面那个函数真正的语义。 当然，我们可以找找我们的表中有没有关于某个寄存器值的信息： 123456789101112131415161718bool pv_area::find_reg(struct gdbarch *gdbarch, int reg, CORE_ADDR *offset_p) { struct area_entry *e = m_entry; if (e) { do { if (e-&gt;value.kind == pvk_register &amp;&amp; e-&gt;value.reg == reg &amp;&amp; e-&gt;value.k == 0 &amp;&amp; e-&gt;size == register_size(gdbarch, reg)) { if (offset_p) { *offset_p = e-&gt;offset; } return true; } e = e-&gt;next; } while (e != m_entry); } return false;} 关于 gdbarch 结构体，现在只要知道它记录了架构信息即可，register_size 则返回某种架构中某个寄存器的大小。这个函数也没什么特别的，就是一个遍历操作。 接下来有一个稍微看起来复杂点但功能很简单的函数，也是这个类的最后一个函数： 12345678910111213141516void pv_area::scan(void (*func)(void *closure, pv_t addr, CORE_ADDR size, pv_t value), void *closure) { struct area_entry *e = m_entry; pv_t addr; addr.kind = pvk_register; addr.reg = m_base_reg; if (e) { do { addr.k = e-&gt;offset; func(closure, addr, e-&gt;size, e-&gt;value); e = e-&gt;next; } while (e != m_entry); }} 循环遍历整个表，对表中的每一项做一个自定义操作。函数指针使得整个函数看起来有些抽象，但也不难明白它的意思。 现在，我们已经获得了对一块内存区域的数据进行分析的工具，接下来，我们可以利用这些工具进行分析了。下一次将针对两种架构的整个前导代码分析过程做出解释，在那里，我们可以看见这些工具都是怎样被应用的，又能给出怎样的结果。","link":"/blog/3d571260/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 1","text":"在近二十年间，出现了两种量子计算的主要范式。一种是量子门编程模型（gate-based model of quantum computing），也叫通用量子计算（universal quantum computing）；另一种是量子退火方法（quantum annealing），也叫绝热量子计算（adiabatic quantum computing）。从数学角度上看，这两种模型具备同等的计算能力，但在实践上，两者有显著的不同。 前两次讲座主要介绍量子门编程模型，第一次讲座的内容包括量子比特（quantum bits, qubits）和量子门（quantum gates）、以及量子电路（quantum circuits）。 量子比特和量子门 正如经典计算机一样，量子计算机也一样由门电路构成，不过其用来表示信息的单元为量子比特而非高低电平，其运算模块为量子门而非数字电路的逻辑门。 单个的量子比特 单个量子比特为计算的基本单元，处在 \\(0\\) 和 \\(1\\) 的叠加状态（superposition）之中。我们可以使用类似描述振幅的方式去描述一个量子比特 \\(|\\psi\\rangle\\)： \\[ |\\psi\\rangle = \\psi_0|0\\rangle + \\psi_1|1\\rangle = \\big ( \\begin{matrix} \\psi_0 \\\\ \\psi_1 \\end{matrix} \\big ) \\] 其中 \\(\\psi_0\\) 和 \\(\\psi_1\\) 均为复数。可以将 \\(|0\\rangle\\) 和 \\(|1\\rangle\\) 理解成一组基： \\[ |0\\rangle = \\begin{bmatrix} 1 \\newline 0 \\end{bmatrix} \\newline |1\\rangle = \\begin{bmatrix} 0 \\newline 1 \\end{bmatrix} \\] 这两个复数需要满足归一化条件： \\[ \\langle \\psi \\vert \\psi \\rangle = |\\psi_0|^2 + |\\psi_1|^2 = 1 \\] 因此，我们可以表明， \\[ \\exists \\theta \\in [0, \\pi], \\mathrm{s. t.} |\\psi_0| = \\cos \\frac{\\theta}{2}, |\\psi_1| = \\sin \\frac{\\theta}{2} \\] 因为全局相位对其状态无影响，我们可以不失一般性地令 \\[ \\psi_0 = \\cos \\frac \\theta 2 \\newline \\psi_1 = e^{i\\phi}\\sin \\frac \\theta 2 \\] 其中 \\(\\phi \\in [0, 2\\pi)\\) 表示复系数之间的相对相位。 基于这些特性，我们可以在 Bloch 球面中表达一个量子比特，如下图： 其中的 \\(r^x, r^y, r^z\\) 可以以投影的方式给出： \\[ \\mathbf r = \\begin{bmatrix} r^x \\newline r^y \\newline r^z \\end{bmatrix} = \\begin{bmatrix} \\sin\\theta\\cos\\phi \\newline \\sin\\theta\\sin\\phi \\newline \\cos\\theta \\end{bmatrix} = \\begin{bmatrix} \\langle\\psi|\\sigma^x|\\psi\\rangle \\newline \\langle \\psi|\\sigma^y|\\psi\\rangle \\newline \\langle \\psi|\\sigma^z|\\psi\\rangle \\newline \\end{bmatrix} \\] 其中 \\(\\langle\\psi|\\sigma|\\psi\\rangle = \\vert \\psi \\rangle^\\dagger \\sigma \\vert \\psi \\rangle\\)，其中 \\(A^\\dagger\\) 表示 \\(A\\) 的共轭转置，\\(\\sigma^x\\)，\\(\\sigma^y\\)，\\(\\sigma^z\\) 为 Pauli 矩阵： \\[ \\sigma^x = \\begin{bmatrix} 0 &amp; 1 \\newline 1 &amp; 0 \\end{bmatrix}, \\sigma^y = \\begin{bmatrix} 0 &amp; -i \\newline i &amp; 0 \\end{bmatrix}, \\sigma^z = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; -1 \\end{bmatrix} \\] 关于 Bloch 球面，在第十讲中会有更详尽的叙述。需要注意，在进行测量时，一个量子比特会坍缩到 \\(0\\) 或者 \\(1\\) 的定态，其测量结果为 \\(0\\) 的概率为 \\(|\\psi_0|^2\\)，为 \\(1\\) 的概率为 \\(|\\psi_1|^2\\)。 量子门 量子门可以看作是对 \\(|\\psi\\rangle\\) 在 Bloch 球面上的旋转操作，事实上就是一些 \\(2 \\times 2\\) 的酉矩阵。基于 Pauli 矩阵我们可以很方便的构造出绕坐标轴旋转的 Pauli 门： \\[ R^x(\\theta) = e^{-\\frac{i\\theta\\sigma^x}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -i\\sin\\theta 2 \\newline -i\\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^y(\\theta) = e^{-\\frac{i\\theta\\sigma^y}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -\\sin\\theta 2 \\newline \\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^z(\\theta) = e^{-\\frac{i\\theta\\sigma^z}{2}} = \\begin{bmatrix} e^{-\\frac{i\\theta}{2}} &amp; 0 \\newline 0 &amp; e^{\\frac{i\\theta}{2}} \\end{bmatrix} \\newline \\] 在实际的实现中，只会实现部分基本旋转，然后将其组合起来以实现真正的旋转门。例如，IBM Q 实现了 \\(R^x(\\frac\\theta 2)\\) 和 \\(R^z(\\theta)\\)。 可以按照如下公式组合形成能够完成绕任意轴旋转的旋转门，其中 \\(\\vec n\\) 是旋转轴的单位向量： \\[ R^{\\vec n}(\\theta) = e^{-\\frac{i\\theta\\vec n\\vec \\sigma}{2}} = I\\cos\\frac \\theta 2 - in_i\\sigma^i\\sin \\frac \\theta 2 \\] 其中 \\(I\\) 为恒等矩阵，\\(i = x, y, z\\) 还有其他常用的门，罗列如下： \\[ X = \\sigma^x, Y = \\sigma^y, Z = \\sigma^z \\newline H = \\frac 1 {\\sqrt 2} \\begin{bmatrix} 1 &amp; 1 \\newline 1 &amp; -1 \\end{bmatrix}, T = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; e^{\\frac{i\\pi}{4}}\\end{bmatrix}, S = T^2 = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; i\\end{bmatrix} \\] 其中比较重要的是 \\(X\\) 门，又称 \\(NOT\\) 门、翻转门（flipping gate）；\\(H\\) 门被称为 Hadamard 门，\\(T\\) 和 \\(S\\) 为相移门。 多个量子比特的情形 在具备多个量子比特的情况下，只需要由 Kronecker 积（张量积，tensor product）将它们组合起来即可。我们首先构造这样一组基： \\[ |q_0q_1q_2\\dots q_{n-1}\\rangle = |q_0\\rangle \\otimes |q_1\\rangle \\otimes |q_2\\rangle \\otimes \\dots \\otimes|q_{n - 1}\\rangle \\] 其中 \\(q_i = 0, 1\\)，可以发现，\\(q_0q_1\\dots q_{n-1}\\) 是一个大小在 \\(0\\) 到 \\(2^n - 1\\) 之间的数 \\(j\\) 的二进制表示。记 \\(|q_0q_1...q_{n-1}\\rangle = |j\\rangle\\)，于是可以将一个 \\(n\\) bit 的系统表示为 \\(\\sum\\limits_{j}\\psi_j|j\\rangle\\)。 涉及多个量子比特的门同样可以用 Kronecker 积表出，记 \\(U_i\\) 为只对第 \\(i\\) 个比特做 \\(U\\) 操作的门，则： \\[ U_i = |q_0q_1\\dots q_{i-1}\\rangle U(q_i) |q_{i+1}q_{i+2}\\dots q_{n-1}\\rangle \\] 则很显然可以得出： \\[ U_i =\\underbrace{\\overbrace{I \\otimes I \\otimes \\cdots \\otimes I}^{i-1\\text{个}} \\otimes U \\otimes I \\otimes I \\cdots \\otimes I}_{n\\text{个}} \\] 当使用多个量子比特的系统时，很显然我们不只是想操作其中的某一个比特，而是要对其中的比特进行关联的操作，例如，当某比特为某状态时，对另一比特做某操作。受控的量子门（Controlled-U gate）就实现了这一点： \\[ CU_{i_1i_2}|q_0q_1\\dots q_{n-1}\\rangle = \\begin{cases} |q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 0 \\newline |U_{i_2}|q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 1 \\end{cases} \\] 一个暂时用不上的附注：在做 \\(CU\\) 门运算之后，全局相位会变为相对相位。 常见的多比特门如下： \\[ CNOT = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;0&amp;1\\newline 0&amp;0&amp;1&amp;0 \\end{bmatrix}, CZ = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;1&amp;0\\newline 0&amp;0&amp;0&amp;-1 \\end{bmatrix} \\] 读者不难自证，它们之间存在如下联系： \\[ CNOT = (I\\otimes H)CZ(I \\otimes H) \\] 量子电路及其编程 量子电路的结构类似下图： 上图表示的是量子电路中的一个 2 位半加器，最左边将几个比特初始化，从左向右依次由不同的量子门对每个比特进行处理，最终结果输出在右侧。 在实际用 Python 进行编程时，一般使用 qiskit 作为电路前端，后端模拟器有以下三种选择： qasm_simulator：初始值全 \\(0\\)，无噪声影响下的测量结果； statevector_simulator：在测量导致量子态坍缩之前的直接计算结果； unitary_simulator：给出计算过程的酉矩阵。","link":"/blog/dbb7e980/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 2","text":"在上一次讲座中，简单地介绍了量子电路的基本概念和量子编程的方法。这一次课将分析几个量子电路的例子和代码实现，包括： 2 位半加器 量子近似优化算法（Quantum Approximation Optimization Algorithm, QAOA），以 Ising 问题为例 Grover 搜索 2 位半加器的实现 2 位半加器的功能如下： \\[ |q_0q_1\\rangle|q_2q_3\\rangle \\rightarrow |q_0q_1\\rangle|q_0q_1 + q_2q_3\\rangle \\] 为了更好地理解其功能，我们给出几个例子： \\[ \\begin{array}{**lr**} |2\\rangle|1\\rangle \\rightarrow |2\\rangle|3\\rangle\\newline |2\\rangle \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow |2\\rangle \\dfrac{|2\\rangle + |3\\rangle}{\\sqrt{2}}\\newline \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow \\dfrac{|0\\rangle + |1\\rangle + |1\\rangle + |2\\rangle}{2} \\end{array} \\] 尤其值得关注的是第二行例子，我们似乎“并行地”做了加法，这种并行性有赖于量子电路的线性性，即对于电路 \\(U\\)，有 \\[ U(|\\psi_1\\rangle + |\\psi_2\\rangle) = U|\\psi_1\\rangle + U|\\psi_2\\rangle \\] 其电路实现已经在上一讲的例子中给出了，如下图： 从左往右，第一部分为初始化模块，这个模块通过一系列门电路将全 0 的初始值转化为我们所需要的值。 第二部分为量子傅里叶变换（Quantum Fourier Transform, QFT）模块，这个模块将信息从寄存器值转移到指数上来。我们不妨首先计算一下作用于 \\(q_2\\) 和 \\(q_3\\) 上的变换矩阵： \\[ \\begin{bmatrix} 1&amp;1&amp;1&amp;1\\newline 1&amp;-1&amp;1&amp;-1\\newline 1&amp;i&amp;-1&amp;-i\\newline 1&amp;-i&amp;-1&amp;i \\end{bmatrix} \\] 未完待续","link":"/blog/42beb83a/"},{"title":"量子计算与计算复杂度（M. N. Vyalyi） Lecture 1","text":"在之前（还没更新）的课程中，主要讨论了量子计算的几种范式，并对其进行了一些形式化。从这里开始，我们将尝试对量子计算的复杂性理论做出详细的解释和说明，并表明其与经典计算复杂度类的关系。首先，有必要快速回顾一下经典复杂性理论带给我们的一些结果。 经典的复杂性理论研究的对象是受到资源限制的计算。我们需要在“简单的”和“困难的”问题之间做出区分，并将这种区分形式化。首先，我们需要考虑计算所需的资源：时间、空间，还有什么吗？ 交互资源（interaction）也是一种非标准的资源，在我们后面的讨论中，我们会经常用到相关的概念。交互资源主要有两种，谕示机（oracle）和实验者（prover）。谕示机知道问题的答案，而且它是可信的；实验者也知道问题的答案，但它是不可信的，需要提供一个证明。 谕示机（oracle）一词本来被译为“先知、神谕”，事实上这个义项可以很好地理解其意图；实验者（prover）这个说法相当奇怪，按照其直白的含义，应该叫做受质询者之类，但 prover 这个词本身并没有这种含义，所以姑且将其作此翻译。 另，实验者这个词在标准的教科书中似乎并没有出现，在下文看来它似乎与验证者（verifier）相应，在此注明。1 既然我们要讨论量子计算，那么量子过程（quantum process）也是一种资源，我们将其归为自然法则（laws of nature）一类。这一类还包括概然过程（probabilistic process），其与量子过程的差别在后文中会进一步提及。 概然过程（probabilistic process）一词似乎看起来应该译为随机过程，但是随机过程（stochastic process）在概率论中为一个专有名词，为了避免发生混淆，在这里亦作别译。 接下来我们快速地回顾以下经典复杂度理论的成果。 基本概念 为了讨论计算复杂度，我们需要从计算开始讲起。为了定义一种计算模型，我们需要给出构形空间（configuration space，可以理解为状态空间），即其所有可能的状态的总和。而一个基本的计算步骤（elementary computation step）可以被定义为一些从构形空间到其自身的函数，一个算法（algorithm）则是一串基本的计算步骤的序列。 在众多计算模型当中，我们选用图灵机（Turing machine）作为基本的计算模型。在这个模型中，构形为一个有限字母表上的序列、一个指针和一个控制态的三元组，一个基本的计算步骤为改变指针所指位置的字符、改变一格指针位置或者改变控制态。在这种情形下，我们可以很轻松地给出时间和空间复杂度的定义： 运行时间正比于一个算法所需的基本计算步骤的个数 所需花费的空间正比于任一构型中的字符串的长度 以 \\(\\vert x \\vert\\) 作为字符串 \\(x\\) 的长度，我们可以定义图灵机 \\(M\\) 代表的算法的最坏时间复杂度为： \\[ t_M(n) = \\max\\limits_{\\vert x \\vert = n} T_M(x) \\] 其中 \\(T_M(x)\\) 为输入 \\(x\\) 时图灵机 \\(M\\) 达到停机状态（halting state）所需的步数。 在复杂度理论的讨论中，我们感兴趣的是 \\(t_M(x)\\) 的渐进界，尤其是渐进上界。一种很重要的情形是多项式时间的算法，我们形式化地定义其为： \\[ t(n) \\in \\mathrm{poly}(n),\\ \\mathrm{if}\\ \\exists c_1, c_2 \\in \\mathbb{Z}_+:\\forall n \\in \\mathbb{Z}_+ t(n) \\leqslant c_1n^{c_2} \\] 一般的，我们认为有多项式时间界的算法为足够快地或者足够高效的。 大部分计算模型都是多项式时间等价的（考虑扩展的 Church-Turing 论题），因此这种分类在一般的计算模型中都是普遍可靠的，而且，它使得我们可以使用更加有力的工具（图灵机）来给出复杂度的渐进界。2 从中，我们可以抽象出复杂度类（complexity class）的概念。一个复杂度类是一些可以被给定的资源解决的问题的集合。 为了下面讨论的便利，我们定义几种计算问题。 函数的计算。记 \\(A^\\ast\\) 为一个有限集合 \\(A\\) 上的字符串的总和，计算 \\(f:A^\\ast \\rightarrow A^\\ast\\)。以下的文本中，我们都将 \\(A\\) 假定为 \\(\\{0, 1\\}\\)。 决策问题（decision problem）。我们称 \\(L \\subseteq A^\\ast\\) 为一个语言（language），一个决策问题就是计算 \\(L\\) 的示性函数（indicator function） \\(\\mathbb{1}_L(x)\\) 。 承诺问题（promise problem）。考虑两个不交的语言 \\(L_0\\) 和 \\(L_1\\)。给定 \\(x \\in L_0 \\cup L_1\\)，需要求解 \\(\\mathbb{1}_{L_1}(x)\\) 。很显然，对语言 \\(L\\) 的决策问题等价于 \\((L, L)\\) 的承诺问题。 一个很重要的复杂度类为 \\(\\mathsf{P}\\) 类，我们称 \\(L \\in \\mathsf{P}\\) ，若存在一个确定性算法使得其决策问题关于输入长度有多项式时间界。对于承诺问题，定义是类似的。 更广泛的，可以定义类 \\(\\mathsf{FP}\\)，如果一个函数 \\(f:A^\\ast \\rightarrow A^\\ast\\) 可以在多项式时间内被计算，则称 \\(f \\in \\mathsf{FP}\\) 。 复杂度类 \\(\\mathsf{NP}\\) 、规约和完全类 对于复杂度 \\(\\mathsf{NP}\\) 的定义，我们需要回到之前给出的交互资源的提法。直观地讲，在计算过程中，有验证者（verifier）和实验者。验证者只能解决 \\(\\mathsf{P}\\) 类问题，而实验者可以解决任何问题。而实验者是不受信的，因此它必须向验证者给出证明。我们形式化这种直观，将其定义如下： 我们称 \\(L \\in \\mathsf{NP}\\)，若存在 \\(V(x, y) \\in \\mathsf{P}\\) 和多项式 \\(p\\) 满足以下条件： 完备性：若 \\(x \\in L\\)，则 \\(\\exists y\\)，使得 \\(V(x, y) = 1\\) 且 \\(\\vert y \\vert \\leqslant p(\\vert x \\vert)\\) 。 可靠性：若 \\(x \\not \\in L\\)，则 \\(\\forall y\\)，\\(V(x, y) = 0\\) 。 其中 \\(V(x, y)\\) 就是对验证者的形式化。为了证明答案 \\(x\\) 是正确的，实验者需要给出证明 \\(y\\) ，其长度（耗费的空间资源）也应该是多项式的，使得利用 \\(y\\) 验证 \\(x\\) 是一个 \\(\\mathsf{P}\\) 类问题。而如果答案 \\(x\\) 是错误的，无论给出什么证明，都不能使得验证者误认为 \\(x\\) 是正确的。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{NP}\\)。我们下面不加证明地给出三个 \\(\\mathsf{NP}\\) 问题的例子，它们可能是属于 \\(\\mathsf{NP} \\setminus \\mathsf{P}\\) 的： \\(\\text{3-SAT}\\): 给定一个三变量的合取范式，确定其是否可满足。 \\(\\text{3-COLOR}\\): 给定一个图，确定其是否能被三种颜色染色。 \\(\\large\\text{P}\\small\\text{ARTITION}\\): 给定一列正整数，确定是否存在一个平均分划。 考虑计算问题的复杂度的排序方式。很直观地，如果我们能够将某个问题化作另一个问题，这个问题肯定不会比另一个问题更难解决。这种直觉使我们能够定义规约（reduction）这个概念，它定义了复杂度类中的一种二元关系。 我们称一个承诺问题 \\((L_0, L_1)\\) 可以多项式地规约（polynomial reduction, 或者 Karp reduction）到一个问题 \\((K_0, K_1)\\) ，如果存在一个函数 \\(f \\in \\mathsf{FP}\\)，使得： \\[ x \\in L_1 \\iff f(x) \\in K_1, x \\in L_0 \\iff f(x) \\in K_0 \\] 记作 \\((L_0, L_1) \\leqslant_p (K_0, K_1)\\) 。 很容易表明，这个二元关系具备传递性，只需观察到 \\(\\mathsf{FP}\\) 类中的函数的复合还在 \\(\\mathsf{FP}\\) 类中即可。这个二元关系引导我们定义出一个复杂度类中“最难”的问题，这些问题被称为完全问题（complete），因为它们事实上表征了整个复杂度类最难解的一些问题。 我们称一个问题 \\(P \\in \\mathcal{C}\\) 为 \\(\\mathcal{C}\\)-完全的，如果对任意 \\(L \\in \\mathcal{C}\\) ，有 \\(L \\leqslant_p P\\) 成立。 \\(\\mathsf{NP}\\) 类中同样包含一个完全集，这已经由 Cook 和 Levin 证明（通过 \\(\\text{3-SAT}\\) 问题）。事实上，上面举出的三个例子均为 \\(\\mathsf{NP}\\text{-complete}\\) 问题。 复杂度类的补、\\(\\text{co-}\\mathsf{NP}\\) 类 这里的考虑很好理解，既然我们定义了复杂度类，那么它自然而然地可以定义出一个补：设 \\(\\mathcal{C}\\) 为一复杂度类，则 \\(\\text{co-}\\mathcal{C}\\) 为其补，对任意 \\(L \\in \\mathcal{C}\\)，\\(\\bar L \\in \\text{co-}\\mathcal C\\)。 一个很显然的命题是，\\(\\mathsf{P} = \\text{co-}\\mathsf{P}\\)。我们只需要将算法的输出翻转一下，就可以得到 \\(\\text{co-}\\mathsf{P}\\) 问题的解。 \\(\\text{co-}\\mathsf{NP}\\) 和 \\(\\mathsf{NP}\\) 的关系仍然悬而未决，我们在这里给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\) 的问题： \\(\\large\\text{I}\\small\\text{NTEGER FACTORING}\\) 输入：一个正整数 \\(N\\) 的二进制表示 输出：\\(N\\) 的质因数分解 很显然，这不是一个决策问题。我们需要将其改写成决策问题： \\[ \\large\\text{B}\\small{\\text{IT}}\\large\\text{O}\\small{\\text{F}}\\large\\text{F}\\small\\text{ACTORING} = \\{\\langle N, i \\rangle : N \\text{ 的质因数分解第 } i \\text{ 位为 } 1\\} \\] 证明这个问题在 \\(\\mathsf{NP}\\) 中是显然的，实验者只需要给出一个分解作为证明即可。 注意到，判断一个数是否为素数是可以在多项式时间内完成的，参考 AKS 素数测试。 证明其属于 \\(\\text{co-}\\mathsf{NP}\\) 也并不困难，和上述方法是完全相同的。 我们还可以不加证明的给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\text{-complete}\\) 的承诺问题的实例，决策问题的例子仍然是未知的。 \\(\\large\\text{O}\\small\\text{NE}\\large\\text{O}\\small\\text{F}\\large\\text{T}\\small\\text{WO}\\) 输入：两个合取范式 \\(C_1\\), \\(C_2\\) 承诺：两者中必有一个是可满足的 问题：表明 \\(C_1\\) 是可满足的 概率性的计算，类 \\(\\mathsf{BPP}\\) 和 \\(\\mathsf{PP}\\) 如前所述，计算过程中，随机数也是一种资源。接下来我们探讨可以访问随机数的算法。在这里，我们将随机位认为是独立平均分布的，\\(0\\) 和 \\(1\\) 出现的概率各占一半。 对于一个涉及随机数的计算，出错也是难免的，因此，我们要提出的第一个问题是，如何定义一个成功的计算？ 直觉地，我们认为，一个计算如果正确的概率“过半”，那它就是成功的，设 \\(f(x)\\) 为目标函数，\\(\\text{Res}(x)\\) 为计算结果，我们可以形式化这个定义为： \\[ \\forall x, \\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; a \\leqslant \\frac 1 2 \\] 注意到我们留了一个 \\(a\\) 作为参量。这是因为，\\(a\\) 是否等于 \\(\\frac 1 2\\) 的情形是完全不同的，其区别的来源是一个算法能否被强化（amplify），即，经过多次重复这个算法（ \\(t\\) 次），然后取出现最频繁的结果，这样似乎能够增加其准确性。事实上，可以证明以下命题成立： 若 \\(\\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; \\frac 1 2 - \\epsilon\\)，则增强后的算法出错的概率为： \\[ \\Big(2\\sqrt{\\frac 1 4 - \\epsilon ^2}\\Big)^t \\] 也就是说，\\(a &lt; \\frac 1 2\\) 时，算法出错的概率可以逐渐收敛到 \\(0\\)，若 \\(a = \\frac 1 2\\)，则我们并不能得出有用的结果。这样我们可以定义两个复杂度类： 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{BPP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 2 3\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 3\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{BPP}\\)，只需要取 \\(p = 0\\) 即可。 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{PP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 1 2\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 2\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 同样显然地，\\(\\mathsf{BPP} \\subseteq \\mathsf{PP}\\)，\\(\\mathsf{PP} = \\text{co-}\\mathsf{PP}\\)。 接下来，我们要表明另一个复杂度层级，\\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)，从而使我们的复杂度继承关系形如下图： 为了给出这个证明，我们需要引出一些额外的定义，并从另一个角度重新表述 \\(\\mathsf{NP}\\) 和 \\(\\mathsf{PP}\\) 的定义。 证明 \\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)：非确定性图灵机、\\(\\mathsf{\\#P}\\)-函数和间隙函数 非确定性图灵机（non-deterministic Turing machine, NTM）与确定性图灵机的差别在于，在每一步计算中，它可以在转移函数之间做出随机选择。因此，NTM 的计算过程是一棵含根的树，而非一列构形空间的序列。树的根部为起始状态，叶为停机状态，从根部到叶的一条路径称为一条计算路径（computation path），计算路径的最大值被定义为这个 NTM 的运行时间。 我们考虑停机状态有两种，接受（accept）和拒绝（reject）。记接受的路径的总数为 \\(\\text{acc}_M(x)\\)，其中 \\(M\\) 为一图灵机，\\(x\\) 为一输入。 接下来我们定义 \\(\\mathsf{\\#P}\\)-函数和间隙函数的概念。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}_+\\) 为一个 \\(\\mathsf{\\#P}\\)-函数，若存在一个多项式运行时间的 NTM \\(M\\) 使得 \\(\\forall x, f(x) = \\text{acc}_M(x)\\)。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}\\) 为一个间隙函数（gap function），若存在两个 \\(\\mathsf{\\#P}\\)-函数 \\(g, h\\)，使得 \\(\\forall x, f(x) = g(x) - h(x)\\)。 未完待续 绿色方块标识的内容均为译注，下同。↩︎ 蓝色方块标识的内容均为原注，下同。↩︎","link":"/blog/b5738fe7/"},{"title":"局部哈密顿问题的复杂性 01","text":"原文为：arXiv:quant-ph/0406180 这篇文章挺难读的，但是也很有意思。大概会分成四次把解读更新完，其实原文在大部分地方已经讲的很清楚了，但是一些计算过程可能需要澄清，毕竟文中的证明有些给的实在简洁。 这篇文章主要讨论的问题是 \\(\\text{2-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 问题的复杂度。作为第一部分这里主要把论文的前四节的比较复杂的证明过了一遍，主要是投影引理和对 Kitaev 构造的重述，虽然还没进入正题但也并不算简单，还是很有仔细研究的价值的。 基本定义 首先，我们快速回顾一下经典计算理论中复杂度类 \\(\\mathsf{NP}\\) 的量子版本，即 \\(\\mathsf {QMA}\\) 的概念： 给定 \\(\\varepsilon = \\varepsilon(|x|) = 2^{-\\Omega(|x|)}\\)，其中 \\(|x|\\) 为字符串 \\(x\\) 的长度。称一个承诺问题 \\(L = (L_{yes}, L_{no})\\) 在类 \\(\\mathsf{QMA}\\) 中，若存在一个量子的、多项式时间的验证者 \\(V\\) 和一个多项式 \\(p\\)，使得： \\(\\forall x \\in L_{yes}, \\exists |\\xi\\rangle \\in \\mathcal{B}^{\\otimes p(|x|)}, \\mathbf{P}(V(|x\\rangle, |\\xi\\rangle) = 1) \\geqslant 1 - \\varepsilon\\) \\(\\forall x \\in L_{no}, \\exists |\\xi\\rangle \\in \\mathcal{B}^{\\otimes p(|x|)}, \\mathbf{P}(V(|x\\rangle, |\\xi\\rangle) = 1) \\leqslant \\varepsilon\\) 其中 \\(\\mathcal B\\) 指描述一个量子比特的 Hilbert 空间。 注意到，只需要取 \\(\\varepsilon \\leqslant 1/3\\)，事实上也就够了，它们产生的复杂度类都是等价的。 在经典计算复杂度理论中，Cook-Levin 定理表明， \\(\\text{SAT}\\) 问题是 \\(\\mathsf{NP}\\)-完备的。在 \\(\\mathsf{QMA}\\) 中，我们取局部哈密顿问题 \\(\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 来作为其等价物。这个问题定义如下： 我们称一个算子 \\(H: \\mathcal B^{\\otimes n} \\rightarrow \\mathcal B^{\\otimes n}\\) 是 \\(k\\)-局部哈密顿（\\(k\\)-local Hamiltonian），若 \\(H = \\sum_{j=1}^rH_j\\)，其中每个 \\(H_i\\) 都是在最多 \\(k\\) 个量子比特上的哈密顿算子。 在 \\(n\\) 个量子比特上，给定一个 \\(k\\)-局部哈密顿 \\(H = \\sum_{j=1}^r H_j\\)，其中 \\(r=\\text{poly}(n)\\)。每个 \\(H_j\\) 的范数 \\(||H_j|| \\leqslant \\text{poly}(n)\\)，其中的每个元素也可以被 \\(\\text{poly}(n)\\) 个比特表示出来。有两个输入 \\(a, b\\) 满足 \\(a &lt; b\\)，我们需要判断， \\(H\\) 的最小特征值至多为 \\(a\\) 还是大于 \\(b\\)。 在下文中，我们记 \\(H\\) 的最小特征值为 \\(\\lambda(H)\\)；若 \\(\\Pi\\) 为 \\(\\mathcal{B}^{\\otimes n}\\rightarrow \\mathcal{S}\\) 的投影，则称 \\(\\Pi H\\Pi\\) 为 \\(H\\) 在子空间 \\(\\mathcal S\\) 上的限制，记作 \\(H\\vert_\\mathcal S\\)。 投影引理（Projection Lemma） 这个引理的核心意义就在于通过局部哈密顿近似一个全局哈密顿。考虑 Hilbert 空间 \\(\\mathcal H\\)，\\(H_1\\) 是其上的一个哈密顿，对于一个子空间 \\(\\mathcal S \\subseteq \\mathcal H\\) ，取一个哈密顿 \\(H_2\\)，使得 \\(\\mathcal S\\) 是其特征值 \\(0\\) 的特征子空间，且 \\(\\lambda(H_2|_\\mathcal {S^{\\perp}}) \\gg ||H_1||\\) 。考虑 \\(H = H_1 + H_2\\)，投影引理表明，\\(\\lambda(H)\\) 非常接近于 \\(\\lambda(H_1\\vert_\\mathcal S)\\)。 我们称哈密顿 \\(H\\) 的惩罚值（penalty value）为 \\(\\min_{x \\in \\mathcal H, ||x|| = 1}\\langle x | H | x \\rangle\\)。 直觉地，我们发现，\\(H_2\\) 对于那些在 \\(\\mathcal S^{\\perp}\\) 上有分量的向量给出了非常大的惩罚值，因此，\\(\\lambda(H)\\) 对应的特征向量一定接近于 \\(\\mathcal S\\)，也就是接近于 \\(H_1|_\\mathcal S\\) 的特征向量。 接下来给出一个形式化的描述： 令 \\(H = H_1 + H_2\\) 为 Hilbert 空间 \\(\\mathcal H = \\mathcal S + \\mathcal S^\\perp\\) 上的两个哈密顿之和，哈密顿 \\(H_2\\) 的零特征空间为 \\(S\\)，而其在 \\(S^\\perp\\) 上的特征向量对应的特征值至少为 \\(J &gt; 2||H_1||\\)，于是： \\[ \\lambda(H_1\\vert_\\mathcal S) - \\frac{||H_1||^2}{J - 2||H_1||} \\leqslant \\lambda(H) \\leqslant \\lambda(H_1\\vert_\\mathcal{S}) \\] 注意到，如果 \\(J \\geqslant 8||H_1||^2 + 2||H_1|| = \\text{poly}(||H_1||)\\)，则我们有 \\(\\lambda(H_1\\vert_\\mathcal S) - 1/8 \\leqslant \\lambda(H) \\leqslant\\lambda(H_1\\vert_\\mathcal S)\\)。 这个引理的证明非常简单。首先表明 \\(\\lambda(H) \\leqslant \\lambda(H_1\\vert_\\mathcal S)\\) ：令 \\(|\\eta\\rangle \\in \\mathcal S\\) 为 \\(H_1|_\\mathcal S\\) 对应 \\(\\lambda(H_1|_\\mathcal S)\\) 的特征向量，则 \\[ \\langle \\eta|H|\\eta \\rangle = \\langle \\eta|H_1|\\eta \\rangle + \\langle \\eta|H_2|\\eta\\rangle = \\lambda (H_1\\vert_\\mathcal S) \\] 因此 \\(\\lambda(H_1|_\\mathcal S)\\) 也是 \\(H\\) 的特征值，\\(\\lambda(H) \\leqslant \\lambda(H_1|_\\mathcal S)\\)。 接下来证明 \\(\\lambda(H)\\) 的下界：将单位向量 \\(|v\\rangle \\in \\mathcal H\\) 分解成 \\(|v\\rangle = \\alpha_1|v_1\\rangle + \\alpha_2 |v_2\\rangle\\)，其中 \\(|v_1\\rangle\\) 和 \\(|v_2\\rangle\\) 分别为 \\(\\mathcal S\\) 和 \\(\\mathcal S^\\perp\\) 中的两个单位向量，\\(\\alpha_1, \\alpha_2\\) 为非负实数且平方和为 \\(1\\) 。令 \\(K = ||H||\\)，则： \\[\\begin{aligned} \\langle v|H|v \\rangle &amp;\\geqslant \\langle v|H_1|v\\rangle + J\\alpha_2^2\\hfill\\newline &amp;= \\alpha_1^2\\langle v_1|H|v_1\\rangle + 2\\alpha_1\\alpha_2 \\text{Re} \\langle v_1 |H_1|v_2\\rangle + \\alpha_2^2\\langle v_2|H_1|v_2\\rangle + J\\alpha_2^2\\hfill\\newline &amp;= (1 - \\alpha_2^2)\\langle v_1|H|v_1\\rangle + 2\\alpha_1\\alpha_2 \\text{Re} \\langle v_1 |H_1|v_2\\rangle + \\alpha_2^2\\langle v_2|H_1|v_2\\rangle + J\\alpha_2^2\\hfill\\newline &amp;\\geqslant \\langle v_1|H|v_1\\rangle - K\\alpha_2^2 - 2K\\alpha_2 - K \\alpha_2^2 + J \\alpha_2\\hfill\\newline &amp;= \\langle v_1|H|v_1\\rangle + (J - 2K)\\alpha_2^2 - 2K\\alpha_2 \\hfill\\newline &amp;\\geqslant \\lambda(H_1|_\\mathcal S) + (J - 2K)\\alpha_2^2 - 2K\\alpha_2\\hfill\\newline &amp;\\geqslant \\lambda(H_1|_\\mathcal S) - \\frac{K^2}{J - 2K} \\end{aligned}\\] Kitaev 构造 这里会经常用到一个非常好用的性质，对于张量积和矩阵乘法，有： \\[ (A\\otimes B)(C\\otimes D) = AB\\otimes CD \\] 直觉上看，这很好理解，当然也是有条件的。这里懒得复述其条件和证明了，反正在这都能用。 在这一节中，作者尝试应用上述投影引理重述 Kitaev 关于 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 是 \\(\\mathsf{QMA}\\) 完全的证明。也就是说，需要表明，所有 \\(\\mathsf{QMA}\\) 中的问题都可以被多项式地规约到 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\)。 我们考虑验证者 \\(V_x = V(|x\\rangle, \\cdot) = U_T\\cdots U_1\\)，其中 \\(T = \\text{poly}(|x|)\\) 作用在 \\(N = \\text{poly}(|x|)\\) 个量子比特上。最开始前面的 \\(m = p(|x|)\\) 个量子比特包含被给出的证明，后面的 \\(N - m\\) 个辅助量子比特被初始化为 \\(0\\) ，而电路的最终结果被放在第一个量子比特上。 我们构造一个作用在 \\(n = N + \\log(T+1)\\) 个量子比特上哈密顿 \\(H\\) ，其中前面 \\(N\\) 个量子比特表征计算，最后的 \\(\\log(T + 1)\\) 个量子比特表征时钟 \\(0, \\cdots, T\\) 的可能值，使得： \\[ H = H_{out} + J_{in}H_{in} + J_{prop}H_{prop} \\] 其中 \\(J_{in}\\) 和 \\(J_{prop}\\) 为 \\(N\\) 为变量的大多项式，在后面将详细讲述其构造，而其他参量构造为： \\[\\begin{aligned} H_{in} \\hfill&amp;= \\sum\\limits^N_{i=m+1} |1\\rangle\\langle1|_i\\otimes|0\\rangle\\langle0|\\hfill\\\\ H_{out} \\hfill &amp;= (T+1)|0\\rangle\\langle0|_1 \\otimes |T\\rangle\\langle T|\\hfill\\\\ H_{prop} \\hfill &amp;= \\sum\\limits_{t=1}^T H_{prop, t}\\hfill\\\\ H_{prop, t} \\hfill &amp;= \\frac 1 2 \\big(I \\otimes |t\\rangle\\langle t| + I \\otimes |t-1\\rangle\\langle t-1| - U_t \\otimes |t\\rangle\\langle t-1| - U_t^\\dagger|t-1\\rangle\\langle t| \\big) \\end{aligned}\\] 其中 \\(|\\alpha\\rangle\\langle\\alpha|_i\\) 表示在第 \\(i\\) 个量子比特为 \\(|\\alpha\\rangle\\) 的子空间上的投影。上面的张量积中，第一部分都是在 \\(N\\) 个量子比特的空间上的作用，第二部分则是为了处理时钟量子比特，\\(U_t\\) 和 \\(U_t^\\dagger\\) 作用的量子比特与在原来的电路中完全相同。直观地讲，现在构造的这一系列哈密顿量中： \\(H_{in}\\) 检查我们的输入值是正确的，也就是说，后面的 \\(N - m\\) 个量子比特确实被初始化为 \\(0\\)； \\(H_{out}\\) 检查表征结果的输出位； \\(H_{prop}\\) 检查我们的结果确实是按照原来电路的状态转移方式得到的。 由于我们只有 \\(\\log(T + 1) = O(\\log n)\\) 个时钟量子比特，所以这些哈密顿算子都是 \\(O(\\log n)\\)-局部的。接下来我们表明任何一个 \\(\\mathsf{QMA}\\) 中的问题都能规约为对上述 \\(H\\) 的 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 问题： 如果电路 \\(V_x\\) 对某个输入 \\(|\\xi, 0\\rangle\\) 的接受概率大于 \\(1-\\varepsilon\\)，那么哈密顿 \\(H\\) 有一个小于 \\(\\varepsilon\\) 的特征值；如果它对所有输入 \\(|\\xi, 0\\rangle\\) 的接受概率小于 \\(\\varepsilon\\)，那么哈密顿 \\(H\\) 的所有特征值均大于 \\(3/4 - \\varepsilon\\)。 这个引理的前半部分非常好证明，只需要取 \\[ |\\eta\\rangle = \\frac{1}{\\sqrt{T+1}} \\sum\\limits^T_{t=0}U_t\\cdots U_1 |\\xi, 0\\rangle \\otimes |t\\rangle \\] 接下来就可以表明： \\[ \\langle \\eta|H_{prop}|\\eta \\rangle = 0 \\] 记 \\(\\eta_j = U_j\\cdots U_1|\\xi, 0\\rangle \\otimes |j\\rangle\\)，注意到： \\[ \\langle \\eta|H_{prop}|\\eta\\rangle = \\sum\\limits_{t=1}^t \\langle\\eta|H_{prop, t}|\\eta\\rangle \\] 再次逐项展开，得： \\[ \\langle \\eta|(\\frac 1 2 I \\otimes |t\\rangle\\langle t|)|\\eta\\rangle = \\frac {1} {2(T+1)} \\langle \\sum\\limits_{t=0}^T \\eta_t |(I\\otimes |t\\rangle\\langle t|)|\\sum\\limits_{t=0}^T \\eta_t\\rangle \\] 这里如果将 \\(\\eta_t\\) 再展开，就会出现交叉项，首先考虑能不能消除它： \\[\\begin{aligned} \\langle \\eta_i | (I \\otimes |t\\rangle \\langle t|) | \\eta_j\\rangle &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle \\otimes |j\\rangle)^\\dagger(I\\otimes|t\\rangle\\langle t |)(U_i \\cdots U_1 |\\xi, 0\\rangle \\otimes |i\\rangle)\\hfill\\\\ &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_i \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle i|t\\rangle\\langle t|j\\rangle)\\hfill\\\\ &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_i \\cdots U_1 |\\xi, 0\\rangle) \\otimes 0\\hfill\\\\ &amp;= 0\\hfill \\end{aligned}\\] 那么非交叉项呢？事实上按照上面的式子，我们已经表明，所有这些和式中只会剩下一项： \\[\\begin{aligned} \\langle \\eta|(I \\otimes |t\\rangle\\langle t|)|\\eta\\rangle &amp;= (U_t \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_t \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t|t\\rangle\\langle t|t\\rangle) \\hfill\\\\ &amp;= I \\otimes 1\\hfill\\\\ &amp;= I\\hfill \\end{aligned}\\] 第二项如法炮制： \\[\\begin{aligned} \\langle \\eta|(I \\otimes |t-1\\rangle\\langle t-1|)|\\eta\\rangle &amp;= (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t-1|t-1\\rangle\\langle t-1|t-1\\rangle)\\hfill\\\\ &amp;= I \\otimes 1\\hfill\\\\ &amp;= I\\hfill \\end{aligned}\\] 后面两项同理展开，不过需要注意左边的不再是 \\(I\\) 了： \\[\\begin{aligned} \\langle \\eta|(U_t \\otimes |t\\rangle\\langle t -1 |)|\\eta\\rangle &amp;= \\langle \\eta_{t}|(U_t \\otimes |t\\rangle\\langle t-1|)|\\eta_{t-1}\\rangle\\hfill\\\\ &amp;= (U_{t} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger U_t (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t|t\\rangle\\langle t-1|t-1\\rangle)\\hfill\\\\ &amp;= I \\otimes1\\hfill\\\\ &amp;= I\\hfill\\\\ \\langle \\eta|(U_t \\otimes |t -1\\rangle\\langle t |)|\\eta\\rangle &amp;= \\langle \\eta_{t-1}|(U_t^\\dagger \\otimes |t-1\\rangle\\langle t|)|\\eta_{t}\\rangle\\hfill\\\\ &amp;= (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger U_t^\\dagger (U_{t} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t-1|t-1\\rangle\\langle t|t\\rangle)\\hfill\\\\ &amp;= I \\otimes1\\hfill\\\\ &amp;= I\\hfill\\\\ \\end{aligned}\\] 于是我们成功地表明了 \\(\\langle \\eta|H_{prop}|\\eta \\rangle = 0\\)。 接下来的式子就简单了： \\[\\begin{aligned} \\langle \\eta|H_{in}|\\eta \\rangle = 0, \\langle \\eta|H_{out}|\\eta \\rangle &lt; \\varepsilon \\end{aligned}\\] 合起来就有： \\[ \\lambda(H) \\leqslant\\langle \\eta|H|\\eta \\rangle = \\langle \\eta|H_{out}|\\eta \\rangle &lt; \\varepsilon \\] 嗯，确实非常好证明，容易到原作者都没有仔细写。接下来的第二部分会更加复杂一些：假设 \\(V_x\\) 对于所有输入 \\(|\\xi, 0\\rangle\\) 的接受概率都小于 \\(|\\varepsilon\\rangle\\) ，令 \\(\\mathcal S_{prop}\\) 为 \\(H_{prop}\\) 的基态空间，很显然，它是 \\(2^N\\) 维的，它的一组基是： \\[ |\\eta_i\\rangle = \\frac {1}{\\sqrt{T + 1}} \\sum\\limits^{T}_{t=0} U_t\\cdots U_1|i\\rangle \\otimes |t\\rangle \\] 其中 \\(|i\\rangle\\) 表示 \\(N\\) 个进入计算的量子比特，它们的特征值为 \\(0\\)，\\(\\mathcal S_{prop}\\) 事实上就表征了正确的状态转移方式。接下来我们要对这个子空间应用可爱的投影引理，为了做到这一点，首先需要标明 \\(J_{prop}H_{prop}\\) 对处于 \\(\\mathcal{S}_{prop}^\\perp\\) 中的状态给出了一个 \\(\\text{poly}(N)\\) 的惩罚值，也就是说，\\(H_{prop}\\) 中最小的非零特征值反比于某个关于 \\(N\\) 的多项式。于是，我们给出以下命题： \\(\\exists c &gt; 0\\)，使得 \\(H_{prop}\\) 的最小非零特征值至少为 \\(c/T^2\\)。 这个命题的证明也不太复杂，首先构造一个基的变换： \\[ W = \\sum\\limits_{t=0}^T U_t\\cdots U_1 \\otimes |t\\rangle\\langle t| \\] 将其应用到 \\(H_{prop}\\) 上： \\[ W^\\dagger H_{prop}W = \\sum\\limits_{t=1}^T I \\otimes \\frac 1 2(|t\\rangle\\langle t| + |t-1\\rangle\\langle t-1| - |t\\rangle\\langle t-1| - |t-1\\rangle\\langle t|) \\] 这里的计算方式和上面的证明很像，就不再重复了。当然，这个变换并不会改变 \\(H_{prop}\\) 的特征谱，但它成功地将我们的哈密顿块对角化了： \\[ W^\\dagger H_{prop}W = I \\otimes \\begin{bmatrix} \\frac 1 2 &amp; -\\frac 1 2 &amp; 0 &amp;&amp;&amp;\\cdots&amp; 0\\\\ -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;&amp; \\vdots\\\\ 0 &amp; -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;\\vdots \\\\ &amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\vdots\\\\ \\vdots&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 \\\\ &amp;&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 \\\\ 0 &amp;&amp;\\cdots&amp;&amp; 0 &amp;-\\frac 1 2 &amp;\\frac 1 2 \\end{bmatrix} \\] 漂亮，这样我们就可以开始估计 \\((T+1) \\times (T+1)\\) 小矩阵的特征值了。作者在这里说，使用“标准方法”即可，本来打算用 Givens 变换求解，但是算着实在烦人，于是在这里给出一个（看上去）稍微简单点的思路： 考虑到第一行和最后一行破坏了这个矩阵的美感，我们先把它们无视掉，来看一看中间这个矩阵： \\[ \\begin{bmatrix} 1 &amp; -\\frac 1 2 &amp; 0 &amp;&amp;&amp;\\cdots&amp; 0\\\\ -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;&amp; \\vdots\\\\ 0 &amp; -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;\\vdots \\\\ &amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\vdots\\\\ \\vdots&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 \\\\ &amp;&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 \\\\ 0 &amp;&amp;\\cdots&amp;&amp; 0 &amp;-\\frac 1 2 &amp; 1 \\end{bmatrix} \\] 这个矩阵是个 Toeplitz 矩阵，其特征值还是比较容易获得的：考虑其特征多项式为 \\(\\varphi_n(\\lambda)\\) ，若其为一个 \\(n \\times n\\) 矩阵，则可以很容易地得到： \\[ \\varphi_n(\\lambda) = (1-\\lambda)\\varphi_{n-1}(\\lambda) - \\frac 1 4 \\varphi_{n-2}(\\lambda) \\] 然后观察一下这个式子，考虑到： \\[ \\varphi_0(\\lambda) = 1, \\varphi_1(\\lambda) = 1-\\lambda \\] 发现它长得和第二类切比雪夫多项式的递推式长得有点神似： \\[ \\varphi_0(x) = 1, \\varphi_1(x) = 2x, \\varphi_n(x) = 2x\\varphi_{n-1}(\\lambda) - \\varphi_{n-2}(\\lambda) \\] 那么我们可以考虑折腾一下这个矩阵，让它能够变成切比雪夫多项式的样子，只要把 \\(-\\frac 1 2\\) 这个系数提出来就可以了。这样的话得到的多项式就是： \\[ \\varphi_0 (\\lambda) = 1, \\varphi_1(\\lambda) = 2-\\lambda, \\varphi_n(\\lambda) = (2-\\lambda)\\varphi_{n-1}(\\lambda) - \\varphi_{n-2}(\\lambda) \\] 这下子我们就大功告成，只欠换元，令 \\(2x = 2-\\lambda\\)，于是 \\(\\phi_n(x) = \\varphi_n(\\lambda) = U_n(x)\\)。 接下来的事情就好办了，众所周知，第二类切比雪夫多项式的表达式是： \\[ U_n = \\frac{\\sin((n+1)\\cos^{-1}x)}{\\sin(\\cos^{-1}x)}, |x| \\leqslant 1 \\] 它的根就是： \\[ \\cos\\frac{k\\pi}{n+1}, k = 1, 2, \\cdots, n \\] 所以我们求出现在这个矩阵的特征值为： \\[ 1-\\cos\\frac{k\\pi}{n+1}, k = 1, 2, \\cdots, n \\] 接下来我们考虑按照和最后一行展开原来的矩阵，新的特征多项式为： \\[ \\psi(\\lambda) = (\\frac 1 2-\\lambda)\\xi(\\lambda) - \\frac 1 4 \\xi\\prime(\\lambda) \\] 其中： \\[\\begin{aligned} \\xi(\\lambda) &amp;= (\\frac 1 2 - \\lambda)\\varphi_{T-1}(\\lambda) - \\frac 1 4 \\varphi_{T-2}(\\lambda)\\hfill\\\\ \\xi\\prime(\\lambda) &amp;= (\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda) - \\frac 1 4 \\varphi_{T-3}(\\lambda)\\hfill\\\\ \\end{aligned}\\] 嗯，看上去很丑。整理一下，就有： \\[ \\psi(\\lambda) = (\\frac 1 2 - \\lambda)^2\\varphi_{T-1}(\\lambda) - \\frac 1 2(\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda)+ \\frac 1 {16} \\varphi_{T-3}(\\lambda) \\] 看上去似乎就没什么办法了，但是别忘了我们有 \\(\\varphi_n(\\lambda)\\) 的递推公式，现在这是我们最后的希望了： \\[\\begin{aligned} \\psi(\\lambda) &amp;= (\\frac 1 2 - \\lambda)^2\\varphi_{T-1}(\\lambda) - \\frac 1 2(\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda) - \\frac 1 4 \\varphi_{T-1}(\\lambda) + \\frac{1-\\lambda}4 \\varphi_{T-2}(\\lambda)\\hfill\\\\ &amp;= (\\lambda^2-\\lambda) \\varphi_{T-1}(\\lambda) + \\frac{\\lambda}{4}\\varphi_{T-2}(\\lambda)\\hfill\\\\ &amp;= -\\lambda((1-\\lambda)\\varphi_{T-1}(\\lambda) - \\frac 1 4\\varphi_{T-2}(\\lambda))\\hfill\\\\ &amp;= -\\lambda\\varphi_{T}(\\lambda)\\hfill \\end{aligned}\\] 诶嘿，这下我们就发现了，原来加边矩阵的特征值和没加边的情形是一样的。所以，特征值中的较小值就是： \\[ 1 - \\cos\\frac{\\pi}{T+1} \\geqslant \\frac c {T^2} \\] 这个不等式挺显然的，就不做证明了。 好，准备工作做完了，接下来我们就要应用我们的投影引理了。上面表明了，\\(J\\geqslant cJ_{prop}/T^2\\)。我们取： \\[ H_1 = H_{out} + J_{in}H_{in}， H_2 = J_{prop}H_{prop} \\] 只需要令 \\(J_{prop} = JT^2/c=\\text{poly}(n)\\)，那么 \\(\\lambda(H) \\geqslant \\lambda(H_1|_\\mathcal {S_{prop}}) - \\frac 1 8\\)。接下来我们考察 \\(\\lambda(H_1|_\\mathcal {S_{prop}})\\)。 考虑 \\(\\mathcal{S}_{in} \\subset \\mathcal{S}_{prop}\\) 为 \\(H_{in}|_{\\mathcal S_{prop}}\\) 的基态空间，很显然，它也是一个 \\(2^m\\) 维子空间，其基为 \\[ |\\eta_i\\rangle = \\frac{1}{\\sqrt{T+1}}\\sum\\limits^T_{t=0}U_t\\cdots U_1|j, 0\\rangle \\otimes |t\\rangle \\] 其中 \\(|j\\rangle\\) 为前面 \\(m\\) 个计算用的量子比特的基。接下来在 \\(\\mathcal S_{prop}\\) 中应用投影引理，其中： \\[ H_1 = H_{out}|_{\\mathcal S_{prop}}, H_2 = J_{in}H_{in}|_{\\mathcal S_{prop}} \\] 很显然地，\\(||H_1|| \\leqslant ||H_{out}|| = T+1 = \\text{poly}(N)\\)。而任意处于 \\(\\mathcal S_{in}^\\perp\\) 中的 \\(H_2\\) 的特征向量的特征值都至少是 \\(J_{in} / (T+1)\\)，因此，可以找到 \\(J_{in} = \\text{poly}(N)\\) 使得 \\(\\lambda(H_1+H_2) \\geqslant \\lambda(H_{out}|_{\\mathcal S_{in}}) - \\frac 1 8\\)。 根据我们在上面给出的接受概率小于 \\(\\varepsilon\\) 的假定，我们可以表明，\\(\\lambda(H_{out}|_{\\mathcal S_{in}}) &gt; 1-\\varepsilon\\)。综上所述，\\(\\lambda(H) \\geqslant 1-\\varepsilon - \\frac 2 8 = \\frac 3 4 - \\varepsilon\\)。","link":"/blog/dab644cb/"},{"title":"计算、计算模型和我们的目标","text":"假定你在使用一台计算机看这篇文章，好吧，或许不用假定。那么，你是否想过，计算机是个什么东西？更进一步地说，什么是“计算”？ 从小我们就开始学习计算，从最开始的加减乘除到后来的乘方开方，或许你还学了积分和微分，甚至也知道了加减乘除都是在某种代数结构上的二元运算，这些代数结构也有它们自己的特殊性……但是，当我们思考如何定义计算的时候，呈现在眼前的却是乱花渐欲迷人眼的杂乱景观：似乎一切对“数”的操作都是计算。 或许你想到了算法。算法就像是一个菜谱，它精准地告诉你在哪里、什么时候需要做什么，从而使得你可以由一个特定的输入（又或许没有）给出一个输出：它是一系列基本操作的集合。在这里依然存在问题：基本操作有哪些，它们构成的集合是否必须是有限的？有限的基本操作是否能描述一切可能的算法？为了回答这些问题，我们必须引入计算模型的概念。 计算模型：三种视角 什么是“计算模型”？这又是一个极具争议性的问题。如果你去翻看维基百科上相应的界面，你会发现在讨论区里大家吵得不可开交，页面本身也只给出了杂乱无章的例子。在这里，我们参照 [Robič2015]1 给出一个定义：计算模型就是一种形式化“计算”和“算法”的方式，这样就把问题抛了回去：到底什么是计算，什么是算法？ 对于这个问题的回答可以是多个层面的。从最高层次来说，这取决于我们要用这套定义来干什么。这就是争议的来源：在硬件设计、算法设计、可计算性和计算复杂度等领域对于计算和算法的表述大相径庭，希望达到的目的和得出的结论也各不相同。根据 [Jekovec2012]2 ，我们将其概括为三种可能的模型： 代价模型（cost model），或者更常称为抽象机器模型（abstract machine model）或性能模型（performance model），它的目标是提供一个足以解决某类问题的执行器，并且能准确给出我们所需要的关于计算过程的信息。这种模型在可计算性与计算复杂度中非常重要，也是我们在这系列文章中要重点探讨的模型之一。 编程模型（performance model），这是最实用的模型之一，它给出的是程序抽象的语义模型，也就是说，一个程序所想要表达的语义是什么，它是否被正确表达，在程序分析和形式化验证领域这是一个关键的问题。在这个系列文章中，我们将主要探讨形式语言与前一种模型相关联的地方，对于这种模型本身不会进行深入探讨。 体系结构或硬件模型（architectual or hardware model），这种模型主要专注于编程语言的底层实现，用于高性能机器的设计和算法分析。在讨论布尔电路和（如果可能的话）可逆计算等话题的时候，我们将会回到这种模型，但是我们讨论的核心还是这些模型带来的复杂度结果。 嗯，看起来有点复杂。粗略的讲，第一种模型专注于对计算能力的分析、第二种专注于编程过程、第三种专注于硬件实现。为了进行下面的讨论，我们拿出几个第一种模型的例子来看看，它们的提出时间都在上个世纪 30 年代左右。 怎样设计计算模型：取法自然 我们最开始的讨论事实上暗示了一种很简单的思路：函数不就是一种计算嘛。但是，很显然函数的范围太大了，对于计算机而言，很多东西也不是可以求解的。因此，我们需要将函数的范围缩小一下。 首先我们考虑限制函数的定义域，也就是自然数相关的函数。出于简化考虑，我们让输入可以是多个自然数，输出则是单个自然数，也就是说，考虑函数 \\(f: \\mathbb{N}^k \\rightarrow \\mathbb{N}\\) 。在这些函数中，最简单的函数有三种： 零函数 \\(\\zeta\\) ，不管我给什么自然数，它都输出 \\(0\\) 。 后继函数 \\(\\sigma\\) ，如果我们给它 \\(n\\) ，它就输出 \\(n+1\\) 。 投影函数 \\(\\pi_i^k\\) ，当我们输入 \\(k\\) 个自然数，它给我们其中的第 \\(i\\) 个 。 接下来我们要通过这些函数组合构成新的函数，组合的方式同样有三种： 复合：给定函数 \\(g: \\mathbb{N}^k \\rightarrow \\mathbb{N}\\) 和 \\(h_i: \\mathbb{N}^m \\rightarrow \\mathbb{N}\\) ，可以定义函数 \\(f: \\mathbb{N}^m \\rightarrow \\mathbb{N}\\) ： \\[ f(x_1, x_2, \\cdots, x_m) = g(h_1(x_1, x_2, \\cdots, x_m), h_2(x_1, x_2, \\cdots, x_m), \\cdots, h_k(x_1, x_2, \\cdots, x_m)) \\] 原始递归：给定函数 \\(g: \\mathbb{N}^k \\rightarrow \\mathbb{N}\\) 和 \\(h: \\mathbb{N}^{k+2} \\rightarrow \\mathbb{N}\\) ，可以定义函数 \\(f: \\mathbb{N}^{k+1} \\rightarrow \\mathbb{N}\\)： \\[\\begin{aligned} f(x_1, x_2, \\cdots, x_k, 0) &amp;= g(x_1, x_2, \\cdots, x_k)\\newline f(x_1, x_2, \\cdots, x_k, m+1) &amp;= h(x_1, x_2, \\cdots, x_k, m, f(x_1, x_2, \\cdots, x_k, m)) \\end{aligned}\\] 如果看这个符号化的定义感觉头疼，就这样考虑：首先 \\(g\\) 是 \\(f\\) 的初始态，然后 \\(h\\) 定义了 \\(f\\) 在最后一个参数变化过程中的转移方式，事实上，这和后继函数的思路是一样的。 \\(\\mu\\)-操作：给定函数 \\(g: \\mathbb{N}^{k+1} \\rightarrow \\mathbb{N}\\) ，可以定义函数 \\(f: \\mathbb{N}^k \\rightarrow \\mathbb{N}\\) ： \\[ f(x_1, x_2, \\cdots, x_k) = \\mu x g(x_1, x_2, \\cdots, x_k, x) \\] 其中 \\(\\mu x g(x_1, x_2, \\cdots, x_k, m+1, x)\\) 定义为最小的使 \\(g(x_1, x_2, \\cdots, x_k, x)\\) 为 \\(0\\) 的自然数，而且要求对于所有小于它的自然数 \\(n\\) ，\\(g(x_1, x_2, \\cdots, x_k, n)\\) 都是有定义的。 这个操作是不是看起来就觉得画风不太一致？事实上，这个操作是由 Kleene 在 1936 年强加在 Gödel 第二定理的证明过程给出的原来的定义之上的。它的主要目的是为了解决 Ackermann 函数带来的问题。这个函数和它所带来的问题会在后面详细讨论，在这里就暂时承认这个操作就行。 于是这样我们就给出了一种定义，它被称为递归函数模型或者 Gödel-Kleene 模型，它的主要论点如下： 递归函数模型： 一个递归函数要么是三种初始函数，要么是三种初始函数经过三种基本操作组合而成的函数； 一个算法就是一个递归函数； 一个计算就是按照定义展开一个递归函数并求值的过程； 一个可计算函数就是一个递归函数。 这个模型是最常见的模型之一。如果看得感觉不太明确也没有关系，把它放在这里只是为了让读者更早熟悉递归函数的思路，这个思路会在后面的章节中重述，而且成为我们最有力的工具之一。当然，也不能忽视另一种对函数的简化，它对代数复杂性理论有着特别的意义： 当我们考虑一个代数系统的时候，它的加减乘除是它内蕴的性质。如果按照上面那种定义方案，事实上我们是将所有代数系统都放到自然数系统中去考虑了。于是，Scholz 在 1937 年给出了另一个看起来更加自然的方式：我就尊重代数系统的自然性质，加减乘除都是可计算的，由它们组合而来的东西也是，不需要反思。通过这种方式他的主要贡献是加链的定义，从此也就引发了线性程序和算术电路等方向的研究。 在 1954 年，Ostrowski 重新考虑了 Scholz 的思路。他将其应用于 Horner 规则的证明（一个 \\(n\\) 阶多项式可以通过 \\(n\\) 次加法和 \\(n\\) 次乘法求值），最终催发出代数复杂性理论的整个大分支，我们也会在后面进行介绍。 第二种方式是通过模拟人的行为。这样就可以生发出 Turing 最引人注目的成果，Turing 机，以及后起的 Turing-Post 机可以被认为是模拟了人的语言。这些概念因为并不难以理解，没必要在引言和后面的部分重复出现，所以在这里就不再赘述，而是放到后面的章节中讨论了。 我们的目标 计算是什么？在有了这种定义之后，我们自然就会问这些问题： 计算的极限是什么？有哪些东西是能计算的，有哪些东西是不能计算的？ 计算需要付出多少代价？求解一个问题需要的时间和空间开销有多大？ 如何描述一个计算过程？有没有一套形式化的语言能够描述所有类型的计算，或者某些计算？ 这三个问题分别对应了我们将会讨论的三个分支，即可计算性、计算复杂度和形式语言。在可计算性部分中，我们会详细讨论更多的计算模型，并且通过它们来表明一个问题是否可计算，同时给出对于一种模型的计算能力的度量；另一方面，我们会考虑对计算问题进行分类，不能计算的问题有多困难，是否有一些特殊的结构；如果有可能，还会展示更多的可计算代数结构，比如环和域的可计算性。而在计算复杂度部分中，我们则专注于能计算的问题，对它们进行一再细分，通过不同的计算模型展示复杂度类的大观园并表明其间的关系。对于形式语言，我们讲的内容不会太多，主要穿插于其中介绍基本概念和 Chomsky 文法等重要成果。 在开始之前，我们先做一个历史回顾，然后再继续…… 参考文献懒得按照格式标了，能看懂就行，看不懂来打我啊。 B. Robič, The Foundations of Computability Theory, 2015, Springer↩︎ M. Jekovec et al., Survey of the sequential and parallel models of computation: Technical report LUSY-2012/02↩︎","link":"/blog/2736e16f/"}],"tags":[{"name":"源码阅读","slug":"源码阅读","link":"/blog/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"程序分析","slug":"程序分析","link":"/blog/tags/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"复杂度","slug":"复杂度","link":"/blog/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6/"},{"name":"概率论","slug":"概率论","link":"/blog/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"信息论","slug":"信息论","link":"/blog/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"},{"name":"计算理论","slug":"计算理论","link":"/blog/tags/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"量子计算","slug":"量子计算","link":"/blog/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"},{"name":"计算复杂性理论","slug":"计算复杂性理论","link":"/blog/tags/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7%E7%90%86%E8%AE%BA/"}],"categories":[{"name":"源码阅读笔记","slug":"源码阅读笔记","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"论文笔记","slug":"论文笔记","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"课程笔记","slug":"课程笔记","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"GDB 源码分析","slug":"源码阅读笔记/GDB-源码分析","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/GDB-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"计算理论","slug":"论文笔记/计算理论","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"量子算法与编程暑期讲习班","slug":"课程笔记/量子算法与编程暑期讲习班","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/"},{"name":"量子编程","slug":"课程笔记/量子算法与编程暑期讲习班/量子编程","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/%E9%87%8F%E5%AD%90%E7%BC%96%E7%A8%8B/"},{"name":"Kempe(2005)","slug":"论文笔记/计算理论/Kempe-2005","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/Kempe-2005/"},{"name":"Martin-Löf(1966)","slug":"论文笔记/计算理论/Martin-Lof-1966","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/Martin-Lof-1966/"},{"name":"量子计算复杂性","slug":"课程笔记/量子算法与编程暑期讲习班/量子计算复杂性","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7/"},{"name":"写点教程","slug":"写点教程","link":"/blog/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/"},{"name":"从零开始的计算理论","slug":"写点教程/从零开始的计算理论","link":"/blog/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"引言","slug":"写点教程/从零开始的计算理论/引言","link":"/blog/categories/%E5%86%99%E7%82%B9%E6%95%99%E7%A8%8B/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/%E5%BC%95%E8%A8%80/"}]}