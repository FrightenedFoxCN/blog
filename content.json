{"pages":[],"posts":[{"title":"GDB 源码分析 01：函数前导代码分析（上）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 函数前导代码其实很简单也很固定，它主要就是进入一个函数时进行的代码操作，用来建立栈帧，并为临时变量开好空间。这里展示一个 x86 汇编的最简单情形： 123push ebpmov ebp, espsub esp, N 很简单，很友好，不是吗？ 那么为什么要对这块代码进行重点分析呢？一方面，这是一个函数开头的部分，可以用来分析这个函数调用栈的情况，并分析这个函数所使用的临时变量地址；另一方面，虽然看起来这段代码很可爱，但是随着编译器的复杂化和在调度指令时日益激进的策略，它往往会变得面目全非。但无论如何，这段代码总归是相对简单的部分。 事实上，在现代的 gcc 编译器中往往会给出调用栈信息（call frame information, CFI），其中描述了如何寻找栈的基地址和存储的寄存器等信息，但是这些信息并不总是存在。如果它们不存在，我们就必须采用一些策略来试图解读这些信息。为了解读这些信息，我们就采用一种对指令“抽象解读”的策略，也就是下面将介绍的模糊计算策略。 值的模糊计算 在 prologue-value.h 中，定义了如下结构： 12345enum prologue_value_kind { pvk_unknown, pvk_constant, pvk_register}; 这里所描述的是一个 prologue 值的类型，分别表示未知、常数和寄存器，它决定了在下面的结构体中，后面两个参数应该如何解读。 123456struct prologue_value { enum prologue_value_kind kind; int reg; CORE_ADDR k;};typedef struct prologue_value pv_t; 如果类型是 pvk_unknown，那么后面两个参数都没有意义，毕竟我们对它一无所知； 如果类型是 pvk_constant，这表明这个值就是常数，记录在 k 中。注意，所谓的 CORE_ADDR 实际上就是一个 uint64_t； 如果类型是 pvk_register，这表明寄存器 reg 所对应的原始值为 初始值 + k ，其中 reg 为 GDB 标定的寄存器编号，是为了防止不同架构带来的跨平台问题。在开始分析之前，所有寄存器都会被标为 {pvk_register, reg, 0} 每个类型都有相关的初始化函数，它们实现起来并不困难： 1234567891011121314151617181920pv_t pv_unknown(void) { pv_t v = {pvk_unknown, 0, 0}; return v;}pv_t pv_constant(CORE_ADDR k) { pv_t v; v.kind = pvk_constant; v.reg = -1; v.k = k; return v;}pv_t pv_register(int reg, CORE_ADDR k) { pv_t v; v.kind = pvk_register; v.reg = reg; v.k = k; return v;} 随后我们要对这些值进行“保守估计”，保守估计的意思是说，我们会把一个值正确估计或者设为未知，但不能出现错误的估计。对应于这种估计方式的逻辑变量是这样的： 12345enum pv_boolean { pv_maybe, pv_definite_yes, pv_definite_no}; 然后通过看相关的函数来理解其原理： 1234567static void constant_last(pv_t *a, pv_t *b) { if (a-&gt;kind == pvk_constant &amp;&amp; b-&gt;kind != pvk_constant) { pv_t temp = *a; *a = *b; *b = temp; }} 这个函数就是个辅助函数。如果前者是常数而后者不是常数，对两者做个交换。这个函数在后面只是用来减少需要处理的情况总数的。接下来是对一大批寄存器运算的模拟。 1234567891011121314pv_t pv_add(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k + b.k); } else if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k + b.k); } else { return pv_unknown(); }}pv_t pv_add_constant(pv_t v, CORE_ADDR k) { return pv_add(v, pv_constant(k));} 首先实现加法的计算。这里的过程看起来很简单：两个常数可以加，寄存器可以加上常数，但其他的加法都返回未知。如果要处理常数加法，那就将常数转换成对应的类型再相加。这里不妨停一下思考两个问题： 为什么寄存器和寄存器不能相加？ 为什么常数加法的情况在两个函数中都进行了处理？ 这里我们需要注意，我们并不会实际执行程序，只是取其中的一个片段进行分析。在分析这个片段的时候，寄存器的初始值是未知的。因此，我们总共知道的就是，某个寄存器相比其进入这个片段之前多了或者少了多少。如果将寄存器与寄存器相加，那么势必要用到初始值，也就是说，它的结果对我们来说是未知的。 对于第二个问题，需要注意，加常数的情况并不仅仅存在于显式的指令编码中。例如，在下面将读到的 logical_and 函数中，如果出现与常数 0 做 and 操作，这个寄存器的值就会变成常数 0 ，于是，当它与另一个寄存器相加时，就会进入寄存器与常数相加的情形。 接下来按照这个思路，可以很简单的实现减法和逻辑与运算，代码如下： 1234567891011121314151617181920212223242526272829pv_t pv_subtract(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg) { return pv_constant (a.k - b.k); } else { return pv_unknown(); }}pv_t pv_logical_and(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k &amp; b.k); } else if (b.kind == pvk_constant &amp;&amp; b.k == 0) { return pv_constant(0); } else if (b.kind == pvk_constant &amp;&amp; b.k == ~(CORE_ADDR) 0) { return a; } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg &amp;&amp; a.k == b.k) { return a; } else { return pv_unknown(); }} 这两段的代码逻辑也相当清晰，如果理解了什么叫做保守估计，那么应该也能很轻松地读懂。主要的难点在于理解什么情况下可以对这个操作做出准确的估计，什么时候不能。基于这些计算方式，我们就可以基本上知道某段代码结束之后，能得到怎样的结果了。 这里需要注意，如果出现了除算术指令之外的其他指令，其结果就基本上全是 pvk_unknown 了。所以，这里所做的只是一个前导代码分析，因为函数的前导代码往往不会包含太复杂的东西。 对模糊值做出判断 当我们知道一段代码运行之后的结果之后，我们就可以尝试确定一些东西了，比如某个对象是否落在一个数组里。但在进行这些判断之前，先要有三个最普通的判断函数：判断某个值是否是常数、是否是某个寄存器、是否是某寄存器 初始值 + k 的结果，这三个函数将成为后面应用的基石。 1234567891011int pv_is_constant(pv_t a) { return (a.kind == pvk_constant);}int pv_is_register(pv_t a, int r) { return (a.kind == pvk_register &amp;&amp; a.reg == r);}int pv_is_register_k(pv_t a, int r, CORE_ADDR k) { return (a.kind == pvk_register &amp;&amp; a.reg == r &amp;&amp; a.k == k);} 接下来我们要开始考虑，如何判断一个对象是否落在某个数组里。很显然，我们需要考虑如何描述一个对象和如何描述一个数组。我们需要的参数有： 描述一个对象在内存中的位置和长度，pv_t addr 和 CORE_ADDR size； 描述一个数组在内存里的位置和长度，pv_t array_addr 和 array_len （数组长度），以及 CORE_ADDR elt_size （数组内每个元素的大小）； 返回值，是不是指向某个完整元素，以及如果指向某个完成元素，其对应的指标 int *i。 在开始考虑如何写这个函数之前，我们需要明确地指出这个函数的功能以及它的返回类型。它的返回类型是 enum pv_boolean 型： 如果这个对象一定落在数组中，那么返回 pv_definite_yes ，并把 I； 如果这个对象一定不落在数组中，那么返回 pv_definite_no； 如果不能判断、或者不指向完整的数组元素，那么返回 pv_maybe 。 好，接下来可以开始写这个函数了： 1234567891011121314151617enum pv_boolean pv_is_array_ref(pv_t addr, CORE_ADDR size, pv_t array_addr, CORE_ADDR array_len, CORE_ADDR elt_size, int *i) { pv_t offset = pv_subtract(addr, array_addr); if (offset.kind == pvk_constant) { if (offset.k &lt;= -size &amp;&amp; offset.k &gt;= array_len * elt_size) { return pv_definite_no; } else if (offset.k % elt_size != 0 || size != elt_size) { return pv_maybe; } else { *i = offset.k / elt_size; return pv_definite_yes; } } else { return pv_maybe; }} 这里的逻辑其实很简单：如果对象的起始地址和数组起始地址不能相减或相减不为常数，我们都不能严格做出判断。然后我们考虑这样的情形： 这里就是第一个比较的来源：只有当 offset &lt;= -size 时，才能明确判断说这个元素不在数组内，同样的，第二个比较发生在右边。然后检查是否对齐。如果不对齐，那只能是 pv_maybe。只有当对齐且元素大小等于数组元素大小，且偏移量落在数组之内时，才会返回 pv_definite_yes 。 我们上面的这些工作都只是完成了这个模块的第一部分。为了真正让这个模块得以被使用，还需要具备分析一个内存块的内容的能力。这就是第二部分将要讨论的内容。","link":"/blog/5ad3ba87/"},{"title":"从 Kolmogorov 复杂度到 Martin Löf 随机性检验（上）","text":"Per Martin-Löf, The Definition of Random Sequences, Information and Control, 9, 602-619(1966) 考虑一个在有限字母表中所有字符串的集合。记字符串 \\(x = \\xi_1\\xi_2\\dots\\xi_n\\) 的长度 \\(l(x) = n\\)。接下来我们需要考虑的问题是，这个序列有多复杂？ 很显然，直观地讲，一个“随机”（我们很快会回到这一点上来）字符串要比一个有规律的字符串复杂地多。同样很直观地，我们可以把一个字符串的复杂度定义为某种“最简单的描述方法的长度”，Kolmogorov 算术复杂度就是从这个视角出发做出的形式化定义。 “描述方法”和 Kolmogorov-Solomonoff 定理 接下来我们需要反思，“描述方法”应该如何被形式化地定义出来？既然本文的 tag 中带有计算理论，很自然的一种想法就是，“描述方法”就是一种算法。 在这里，我们使用“算法”这个概念来表达一种从一个有限二进制序列到一个有限字母表上的单子的映射。算法概念的更精确的形式化定义可以采用递归论的定义模式或者其他等价的形式（本文中将不再展开），这并不影响后文的探讨。 记 \\(A\\) 为一种算法，\\(A(p) = x\\)，\\(p\\) 为一个有限二进制串，\\(x\\) 为一个有限字母表上的字符串，我们称 \\(p\\) 是在算法 \\(A\\) 下对 \\(x\\) 的描述。接下来，延续我们前面的直观认识，我们可以定义相对于算法 \\(A\\) 字符串 \\(x\\) 的复杂度为： \\[ K_A(x) = \\min\\limits_{A(p) = x}(l(p)) \\] 那么，很自然的一个问题是，是否一定存在这样的二进制串 \\(p\\) 来对任意字符串 \\(x\\) 做出描述？答案是否定的。只要考虑一个平凡的算法 \\(A_0\\)，它将任意二进制串 \\(p\\) 都映射到字符串 \\(x_0\\)，那么，其他的字符串就都不能在这个算法下做出描述。因此，为了定义的严谨性，我们需要补充说明： \\[ K_A(x) = + \\infty, \\mathrm{if}\\ \\forall p, A(p) \\neq x \\] 现在，我们剩下的一个问题就是，我们不能摆脱算法 \\(A\\) 对我们的定义的限制。我们在考虑一个序列的复杂度时，很显然不是要考虑一个字符串“在某种描述方法下”的复杂度，我们需要使得它成为一个只与字符串 \\(x\\) 有关的数。为了实现这个定义，就需要引入 Kolmogorov-Solomonoff 定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(x) \\leqslant K_B(x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 这个算法在 Kolmogorov 的著作中被称为渐进最优的（asymptotically optimal），在 Solomonoff 的著作中被称为通用的（universial），上述定理的证明如果我不鸽的话会丢进本文的附录或者其他文章里。总之，现在我们已经有了一个最好的算法来讨论如何描述字符串 \\(x\\)，于是，我们就可以定义这个字符串的复杂度 \\(K(x) = K_A(x)\\)，称其为 Kolmogorov 复杂度，或者简单地称为复杂度。 同样地，我们可以引入条件复杂度的概念。考虑一个两变量的算法 \\(A(p, x)\\)，\\(x\\) 为一个有限字母表上的字符串，若 \\(A(p, x) = y\\)，则我们将其称为在 \\(x\\) 的条件下对（可能不同于 \\(x\\) 的）字母表上的字符串 \\(y\\) 的描述。称在 \\(x\\) 的条件下相对于算法 \\(A\\) 的 \\(y\\) 的复杂度为： \\[ K_A(y \\vert x) = \\min\\limits_{A(p, x) = y}(l(p)) \\] 这个定义也是很自然的，同样与上面的讨论和我们的直观感受匹配。幸运地是，亲爱的 Kolmogorov 先生同样给出了一个与上面的定理相对应的定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(y \\vert x) \\leqslant K_B(y \\vert x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 因此，我们也记 \\(K(y\\vert x) = K_A(y \\vert x)\\)，并称其为在 \\(x\\) 的条件下 \\(y\\) 的条件复杂度。 很直观的，对于任意长度为 \\(n\\) 的二进制串 \\(x\\)，都有 \\[ K(x \\vert n) \\leqslant n + c \\] 其中 \\(n\\) 是用于描述这个字符串所用的最多比特数，在最坏情况下，我们需要将整个串都硬编码到代码当中，那么当然需要 \\(n\\) 的长度。而 \\(c\\) 则是机器相关的常数。 同时，我们可以尝试给出一个下界，满足 \\[ K(\\xi_1\\xi_2\\dots\\xi_n \\vert n) \\geqslant n - c \\] 的序列一共有 \\((1-2^{-c})2^n\\) 个。这个结论也很平凡，留给读者自证。 于是，我们发现，当 \\(n\\) 很大的时候，会有很多字符串的复杂度的渐进上界是在 \\(O(n)\\) 这个最大的级别的。Kolmogorov 指出，这可以使我们形式化地定义一个字符串的随机性。 一些评述 看起来，对于二元算法的定义事实上意义不是很大，因为 \\(n\\) 同样可以以 \\(\\log n\\) 的复杂度编写到程序之中，这对于我们的结果并没有影响。事实上，很多较现代的论文提供了另外一种定义形式，例如 Peter D. Grünwald and Paul M. B. Vitányi, Algorithmic Information Theory 中给出的定义是： \\[ K(x) = \\min\\limits_{y, p: p(y) = x}(l(p) + l(y)) \\] 这种定义形式似乎更加符合我们的预期。另外，也将一个对象的 Kolmogorov 编码定义为 \\(E*(x)\\)，是最短的能够打印 \\(x\\) 然后停下的代码。 在这种定义形式下，我们就可以给出三种分类： 简单的对象：\\(O(\\log n)\\)，其原因已经在前面解释过了，因为 \\(n\\) 需要被硬编码进去 完全偶然对象（completely random objects）：\\(n + O(\\log n)\\)，也是显然的 随机对象（stochastic objects）：\\(\\alpha n + o(n)\\) 如果 \\(x_i\\) 是一个随机变量 \\(X_i\\) 的实现，其分布为 \\(P\\)，则这个对象是随机的，其中 \\(\\alpha &lt; 1\\)。比较常见的例子是二项分布，其 \\(\\alpha = H(p)\\) 为二值熵（binary entrophy） \\[ H(p) = -p\\log p - (1-p) \\log(1-p) \\] 随机对象的情形可以类比于扔一个有缺陷的硬币，硬币的缺陷使得这个序列不再成为完全随机的，当然，很显然，\\(p = 0.5\\) 时， \\(H(p) = 1\\)，序列还是完全偶然的。 另一个很遗憾的问题是，\\(K(x)\\) 不是可计算的，在 [Li and Vitányi, 1997] 中，他们表明它是上半可计算的（upper semicomputable），或者简单地理解就是，它是可以被近似的，但近似算法很慢，且不能确定其终点。但是，也有一些方式来解决这个问题，比如通用编码（[Cover and Thomas, 1991]），最小描述长度原理（MDL, [Solomonoff, 1997]）等方式的近似。 Blum 和 Burgin 的公理系统对于这个领域来说也是相当重要的，他们给出了关于这些性质的普遍描述，如果不鸽的话大概也会专门开一篇文章来介绍他们的成果，嗯，如果不鸽的话。","link":"/blog/dd3e0497/"},{"title":"GDB 源码分析 02：函数前导代码分析（中）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 上一次，我们考虑了如何对一个值进行模糊分析，接下来，我们要对一片内存的值做出模糊的估计。在有了这种估计方式之后，我们就能够将其进行真正的应用了。 首先考虑一个问题：如何记录一个内存中的数据？不要忘记，我们需要分析一个函数的前导代码，而前导代码往往做的是栈操作。那么，既然我们不能预先知道栈地址的值，我们自然就得以一个寄存器作为基地址，那么我们需要存储的就是某个地址距离基地址寄存器的偏移量；同时，内存中的对象并不自带类型，所以需要长度作为其标识；最后，我们还要记下它的值。这就是下面这个结构体想要做的事情： 123456struct pv_area::area_entry { struct area_entry *prev, *next; CORE_ADDR offset; CORE_ADDR size; pv_t value;} 注意到它有两个指向前后的指针。事实上，它构成了一个环形双向链表，在后面的分析中，我们还会看到，它是以偏移量的大小进行排序的。然后就是把这个双向链表包装成一个类： 123456class pv_area {private: int m_base_reg; CORE_ADDR m_addr_mask; struct area_entry *m_entry;} 其中除了指向这样一个链表的指针之外，还有基地址寄存器的寄存器号，以及一个地址的掩码。看到后面之后会更容易理解这个掩码的目的，在这里我们只需要简单地认为，我们的地址空间是一个环形，前后相连即可。 接下来看类里面的三个私有成员函数： 1234567891011void pv_area::clear_entries() { struct area_entry *e = m_entry; if (e) { do { struct area_entry *next = e.next; xfree(e); e = next; } while (e != m_entry); m_entry = 0; }} 这个函数用来清空双向链表。其中比较需要注意的就是 xfree 这个函数，事实上这个函数和内存保护有关，在读到这里的时候，我们不妨将其当成一个简单的 free 函数理解。 12345678910111213141516struct pv_area::area_entry *pv_area::find_entry(CORE_ADDR offset) { struct area_entry *e = m_entry; if (!e) { return 0; } while (((e-&gt;next-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;next; } while (((e-&gt;prev-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;prev; } m_entry = e; return e;} 这个函数用来找到在 offset 之后的第一项。如果本身这片区域一项也没有，那么就自然地返回一个空指针。而如果 offset 中一项也没有，那当然就会返回较为靠前的一项。这里需要澄清的是，因为 m_entry 指向的是环形链表中的任意一项，往后扫描和往前扫描都是必须的。最后一步将 m_entry 设为 e 就是出于局部性的假定，假定最近被访问的这项很可能再次被访问，从而提高整个数据结构的搜索效率。 在此不妨停下来思考一个问题：哪怕没有掩码的问题，是否有可能直接写成 e-&gt;next-&gt;offset &lt; e-&gt;offset ？答案是否定的，原作者在注释中特别表明了这一点： 123456/*Note that, even setting aside the addr_mask stuff, we must not simplify this, in high school algebra fashion, to (e-&gt;next-&gt;offset &lt; e-&gt;offset), because of the way &lt; interacts with wrap-around. We have to subtract offset from both sides to make sure both things we're comparing are on the same side of the discontinuity. */ 解释很清楚，在这也就不翻译了。 第三个函数就是一个判断 offset 处 size 大小的一项是否与某个 entry 重合，非常简单，直接贴代码不解释： 1234int pv_area::overlaps(struct area_entry *entry, CORE_ADDR offset, CORE_ADDR size) { return (((entry-&gt;offset - offset) &amp; m_addr_mask) &lt; size || ((offset - entry-&gt;offset) &amp; m_addr_mask) &lt; entry-&gt;size);} 接下来观察一下公有的成员函数，首先来看构建过程： 123pv_area::pv_area(int base_reg, int addr_bit): m_base_reg(base_reg), m_addr_mask(((((CORE_ADDR) 1) &lt;&lt; (addr_bit - 1)) - 1) &lt;&lt; 1) | 1), m_entry(nullptr){} 非常简单的构造函数，但是这里我们就可以重新解释一下地址掩码的含义了。当我们有一个 32 bit 的地址时，自然而然地我们只希望其比较 32 bit，但是寄存器又是可以有 64 bit 的：也就是说，有一部分是需要被抛弃的。 一个很细节的问题是，为什么不把这个表达式写成 ((CORE_ADDR) 1 &lt;&lt; addr_bit) - 1 ？注意，移位的位数与类型的宽度相同时，得到的结果是未定义的。如果采取上面代码的形式，就一定能够保证得到正确的结果。 析构函数非常简单： 123pv_area::~pv_area() { clear_entries();} 然后用了一个有趣的小技巧取消了默认析构函数和 operator=： 1DISABLE_COPY_AND_ASSIGN(pv_area); 宏定义如下，这是为了与不同版本的 c++ 标准兼容： 123456789#if defined(__cplusplus) &amp;&amp; __cplusplus &gt;= 201103#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;) = delete; \\ void operator= (const TYPE &amp;) = delete #else#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;); \\ void operator= (const TYPE &amp;)#endif 接下来我们就要正式进行模拟存取了。下面这个成员函数用来将一个 size 大小的值 value 写入到 addr 处： 123456789101112131415161718192021222324252627282930313233void pv_area::store(pv_t addr, CORE_ADDR size, pv_t value) { if (store_would_trash(addr)) { clear_entries(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); while (e &amp;&amp; overlaps(e, offset, size)) { struct area_entry *next = (e-&gt;next == e) ? 0 : e-&gt;next; e-&gt;prev-&gt;next = e-&gt;next; e-&gt;next-&gt;prev = e-&gt;prev; xfree(e); e = next; } m_entry = e; } if (value.kind == pvk_unknown) { return; } else { CORE_ADDR offset = addr.k; struct area_entry *e = XNEW(struct area_entry); e-&gt;offset = offset; e-&gt;size = size; e-&gt;value = value; if (m_entry) { e-&gt;prev = m_entry-&gt;prev; e-&gt;next = m_entry; e-&gt;prev-&gt;next = e-&gt;next-&gt;prev = e; } else { e-&gt;prev = e-&gt;next = e; m_entry = e; } }} 这个函数稍微有点长，但是思路其实挺简单的： 如果存储操作会使得我现在所有的表项都被无效化，那么直接先把表清掉； 否则的话，清掉所有与这个值重合的项，因为这些项都会被覆写掉； 然后，如果我需要存的值未知，那就直接返回； 如果我需要存的值已知，那就创建出这一项并把它插进去。 XNEW(T) 事实上拓展到了泛型 xnew&lt;T&gt;() ，这个函数和前面的 xfree 一样，只需要当成一个 new 就行，暂时不需要深究；接下来需要考虑的是，什么时候我可能无效化整个表： 12345bool pv_area::store_would_trash(pv_t addr) { return (addr.kind == pvk_unknown || addr.kind == pvk_constant || (addr.kind == pvk_register &amp;&amp; addr.reg != m_base_reg));} 事实上说这种情况可能无效化整个表是不准确的。准确地说，是我们不能确定这次存储和我们现在的表有什么关系，为了方便起见，我们就直接认为这整个表的分析是不可能的，因而就将其抛弃了。这个函数还会被在其他地方调用，比如，考虑取一个值的问题： 12345678910111213pv_t pv_area::fetch(pv_t addr, CORE_ADDR size) { if (!m_entry || store_would_trash(addr)) { return pv_unknown(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); if (e-&gt;offset == offset &amp;&amp; e-&gt;size == size) { return e-&gt;value; } else { return pv_unknown(); } }} 很显然，这个函数的核心还是保守估计。需要注意的是第一行判断，如果表里没有内容，或者这个地址和表无关，那就返回未知。这里，“和表无关”才是上面那个函数真正的语义。 当然，我们可以找找我们的表中有没有关于某个寄存器值的信息： 123456789101112131415161718bool pv_area::find_reg(struct gdbarch *gdbarch, int reg, CORE_ADDR *offset_p) { struct area_entry *e = m_entry; if (e) { do { if (e-&gt;value.kind == pvk_register &amp;&amp; e-&gt;value.reg == reg &amp;&amp; e-&gt;value.k == 0 &amp;&amp; e-&gt;size == register_size(gdbarch, reg)) { if (offset_p) { *offset_p = e-&gt;offset; } return true; } e = e-&gt;next; } while (e != m_entry); } return false;} 关于 gdbarch 结构体，现在只要知道它记录了架构信息即可，register_size 则返回某种架构中某个寄存器的大小。这个函数也没什么特别的，就是一个遍历操作。 接下来有一个稍微看起来复杂点但功能很简单的函数，也是这个类的最后一个函数： 12345678910111213141516void pv_area::scan(void (*func)(void *closure, pv_t addr, CORE_ADDR size, pv_t value), void *closure) { struct area_entry *e = m_entry; pv_t addr; addr.kind = pvk_register; addr.reg = m_base_reg; if (e) { do { addr.k = e-&gt;offset; func(closure, addr, e-&gt;size, e-&gt;value); e = e-&gt;next; } while (e != m_entry); }} 循环遍历整个表，对表中的每一项做一个自定义操作。函数指针使得整个函数看起来有些抽象，但也不难明白它的意思。 现在，我们已经获得了对一块内存区域的数据进行分析的工具，接下来，我们可以利用这些工具进行分析了。下一次将针对两种架构的整个前导代码分析过程做出解释，在那里，我们可以看见这些工具都是怎样被应用的，又能给出怎样的结果。","link":"/blog/3d571260/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 1","text":"在近二十年间，出现了两种量子计算的主要范式。一种是量子门编程模型（gate-based model of quantum computing），也叫通用量子计算（universal quantum computing）；另一种是量子退火方法（quantum annealing），也叫绝热量子计算（adiabatic quantum computing）。从数学角度上看，这两种模型具备同等的计算能力，但在实践上，两者有显著的不同。 前两次讲座主要介绍量子门编程模型，第一次讲座的内容包括量子比特（quantum bits, qubits）和量子门（quantum gates）、以及量子电路（quantum circuits）。 量子比特和量子门 正如经典计算机一样，量子计算机也一样由门电路构成，不过其用来表示信息的单元为量子比特而非高低电平，其运算模块为量子门而非数字电路的逻辑门。 单个的量子比特 单个量子比特为计算的基本单元，处在 \\(0\\) 和 \\(1\\) 的叠加状态（superposition）之中。我们可以使用类似描述振幅的方式去描述一个量子比特 \\(|\\psi\\rangle\\)： \\[ |\\psi\\rangle = \\psi_0|0\\rangle + \\psi_1|1\\rangle = \\big ( \\begin{matrix} \\psi_0 \\\\ \\psi_1 \\end{matrix} \\big ) \\] 其中 \\(\\psi_0\\) 和 \\(\\psi_1\\) 均为复数。可以将 \\(|0\\rangle\\) 和 \\(|1\\rangle\\) 理解成一组基： \\[ |0\\rangle = \\begin{bmatrix} 1 \\newline 0 \\end{bmatrix} \\newline |1\\rangle = \\begin{bmatrix} 0 \\newline 1 \\end{bmatrix} \\] 这两个复数需要满足归一化条件： \\[ \\langle \\psi \\vert \\psi \\rangle = |\\psi_0|^2 + |\\psi_1|^2 = 1 \\] 因此，我们可以表明， \\[ \\exists \\theta \\in [0, \\pi], \\mathrm{s. t.} |\\psi_0| = \\cos \\frac{\\theta}{2}, |\\psi_1| = \\sin \\frac{\\theta}{2} \\] 因为全局相位对其状态无影响，我们可以不失一般性地令 \\[ \\psi_0 = \\cos \\frac \\theta 2 \\newline \\psi_1 = e^{i\\phi}\\sin \\frac \\theta 2 \\] 其中 \\(\\phi \\in [0, 2\\pi)\\) 表示复系数之间的相对相位。 基于这些特性，我们可以在 Bloch 球面中表达一个量子比特，如下图： 其中的 \\(r^x, r^y, r^z\\) 可以以投影的方式给出： \\[ \\mathbf r = \\begin{bmatrix} r^x \\newline r^y \\newline r^z \\end{bmatrix} = \\begin{bmatrix} \\sin\\theta\\cos\\phi \\newline \\sin\\theta\\sin\\phi \\newline \\cos\\theta \\end{bmatrix} = \\begin{bmatrix} \\langle\\psi|\\sigma^x|\\psi\\rangle \\newline \\langle \\psi|\\sigma^y|\\psi\\rangle \\newline \\langle \\psi|\\sigma^z|\\psi\\rangle \\newline \\end{bmatrix} \\] 其中 \\(\\langle\\psi|\\sigma|\\psi\\rangle = \\vert \\psi \\rangle^\\dagger \\sigma \\vert \\psi \\rangle\\)，其中 \\(A^\\dagger\\) 表示 \\(A\\) 的共轭转置，\\(\\sigma^x\\)，\\(\\sigma^y\\)，\\(\\sigma^z\\) 为 Pauli 矩阵： \\[ \\sigma^x = \\begin{bmatrix} 0 &amp; 1 \\newline 1 &amp; 0 \\end{bmatrix}, \\sigma^y = \\begin{bmatrix} 0 &amp; -i \\newline i &amp; 0 \\end{bmatrix}, \\sigma^z = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; -1 \\end{bmatrix} \\] 关于 Bloch 球面，在第十讲中会有更详尽的叙述。需要注意，在进行测量时，一个量子比特会坍缩到 \\(0\\) 或者 \\(1\\) 的定态，其测量结果为 \\(0\\) 的概率为 \\(|\\psi_0|^2\\)，为 \\(1\\) 的概率为 \\(|\\psi_1|^2\\)。 量子门 量子门可以看作是对 \\(|\\psi\\rangle\\) 在 Bloch 球面上的旋转操作，事实上就是一些 \\(2 \\times 2\\) 的酉矩阵。基于 Pauli 矩阵我们可以很方便的构造出绕坐标轴旋转的 Pauli 门： \\[ R^x(\\theta) = e^{-\\frac{i\\theta\\sigma^x}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -i\\sin\\theta 2 \\newline -i\\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^y(\\theta) = e^{-\\frac{i\\theta\\sigma^y}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -\\sin\\theta 2 \\newline \\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^z(\\theta) = e^{-\\frac{i\\theta\\sigma^z}{2}} = \\begin{bmatrix} e^{-\\frac{i\\theta}{2}} &amp; 0 \\newline 0 &amp; e^{\\frac{i\\theta}{2}} \\end{bmatrix} \\newline \\] 在实际的实现中，只会实现部分基本旋转，然后将其组合起来以实现真正的旋转门。例如，IBM Q 实现了 \\(R^x(\\frac\\theta 2)\\) 和 \\(R^z(\\theta)\\)。 可以按照如下公式组合形成能够完成绕任意轴旋转的旋转门，其中 \\(\\vec n\\) 是旋转轴的单位向量： \\[ R^{\\vec n}(\\theta) = e^{-\\frac{i\\theta\\vec n\\vec \\sigma}{2}} = I\\cos\\frac \\theta 2 - in_i\\sigma^i\\sin \\frac \\theta 2 \\] 其中 \\(I\\) 为恒等矩阵，\\(i = x, y, z\\) 还有其他常用的门，罗列如下： \\[ X = \\sigma^x, Y = \\sigma^y, Z = \\sigma^z \\newline H = \\frac 1 {\\sqrt 2} \\begin{bmatrix} 1 &amp; 1 \\newline 1 &amp; -1 \\end{bmatrix}, T = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; e^{\\frac{i\\pi}{4}}\\end{bmatrix}, S = T^2 = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; i\\end{bmatrix} \\] 其中比较重要的是 \\(X\\) 门，又称 \\(NOT\\) 门、翻转门（flipping gate）；\\(H\\) 门被称为 Hadamard 门，\\(T\\) 和 \\(S\\) 为相移门。 多个量子比特的情形 在具备多个量子比特的情况下，只需要由 Kronecker 积（张量积，tensor product）将它们组合起来即可。我们首先构造这样一组基： \\[ |q_0q_1q_2\\dots q_{n-1}\\rangle = |q_0\\rangle \\otimes |q_1\\rangle \\otimes |q_2\\rangle \\otimes \\dots \\otimes|q_{n - 1}\\rangle \\] 其中 \\(q_i = 0, 1\\)，可以发现，\\(q_0q_1\\dots q_{n-1}\\) 是一个大小在 \\(0\\) 到 \\(2^n - 1\\) 之间的数 \\(j\\) 的二进制表示。记 \\(|q_0q_1...q_{n-1}\\rangle = |j\\rangle\\)，于是可以将一个 \\(n\\) bit 的系统表示为 \\(\\sum\\limits_{j}\\psi_j|j\\rangle\\)。 涉及多个量子比特的门同样可以用 Kronecker 积表出，记 \\(U_i\\) 为只对第 \\(i\\) 个比特做 \\(U\\) 操作的门，则： \\[ U_i = |q_0q_1\\dots q_{i-1}\\rangle U(q_i) |q_{i+1}q_{i+2}\\dots q_{n-1}\\rangle \\] 则很显然可以得出： \\[ U_i =\\underbrace{\\overbrace{I \\otimes I \\otimes \\cdots \\otimes I}^{i-1\\text{个}} \\otimes U \\otimes I \\otimes I \\cdots \\otimes I}_{n\\text{个}} \\] 当使用多个量子比特的系统时，很显然我们不只是想操作其中的某一个比特，而是要对其中的比特进行关联的操作，例如，当某比特为某状态时，对另一比特做某操作。受控的量子门（Controlled-U gate）就实现了这一点： \\[ CU_{i_1i_2}|q_0q_1\\dots q_{n-1}\\rangle = \\begin{cases} |q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 0 \\newline |U_{i_2}|q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 1 \\end{cases} \\] 一个暂时用不上的附注：在做 \\(CU\\) 门运算之后，全局相位会变为相对相位。 常见的多比特门如下： \\[ CNOT = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;0&amp;1\\newline 0&amp;0&amp;1&amp;0 \\end{bmatrix}, CZ = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;1&amp;0\\newline 0&amp;0&amp;0&amp;-1 \\end{bmatrix} \\] 读者不难自证，它们之间存在如下联系： \\[ CNOT = (I\\otimes H)CZ(I \\otimes H) \\] 量子电路及其编程 量子电路的结构类似下图： 上图表示的是量子电路中的一个 2 位半加器，最左边将几个比特初始化，从左向右依次由不同的量子门对每个比特进行处理，最终结果输出在右侧。 在实际用 Python 进行编程时，一般使用 qiskit 作为电路前端，后端模拟器有以下三种选择： qasm_simulator：初始值全 \\(0\\)，无噪声影响下的测量结果； statevector_simulator：在测量导致量子态坍缩之前的直接计算结果； unitary_simulator：给出计算过程的酉矩阵。","link":"/blog/dbb7e980/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 2","text":"在上一次讲座中，简单地介绍了量子电路的基本概念和量子编程的方法。这一次课将分析几个量子电路的例子和代码实现，包括： 2 位半加器 量子近似优化算法（Quantum Approximation Optimization Algorithm, QAOA），以 Ising 问题为例 Grover 搜索 2 位半加器的实现 2 位半加器的功能如下： \\[ |q_0q_1\\rangle|q_2q_3\\rangle \\rightarrow |q_0q_1\\rangle|q_0q_1 + q_2q_3\\rangle \\] 为了更好地理解其功能，我们给出几个例子： \\[ \\begin{array}{**lr**} |2\\rangle|1\\rangle \\rightarrow |2\\rangle|3\\rangle\\newline |2\\rangle \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow |2\\rangle \\dfrac{|2\\rangle + |3\\rangle}{\\sqrt{2}}\\newline \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow \\dfrac{|0\\rangle + |1\\rangle + |1\\rangle + |2\\rangle}{2} \\end{array} \\] 尤其值得关注的是第二行例子，我们似乎“并行地”做了加法，这种并行性有赖于量子电路的线性性，即对于电路 \\(U\\)，有 \\[ U(|\\psi_1\\rangle + |\\psi_2\\rangle) = U|\\psi_1\\rangle + U|\\psi_2\\rangle \\] 其电路实现已经在上一讲的例子中给出了，如下图： 从左往右，第一部分为初始化模块，这个模块通过一系列门电路将全 0 的初始值转化为我们所需要的值。 第二部分为量子傅里叶变换（Quantum Fourier Transform, QFT）模块，这个模块将信息从寄存器值转移到指数上来。我们不妨首先计算一下作用于 \\(q_2\\) 和 \\(q_3\\) 上的变换矩阵： \\[ \\begin{bmatrix} 1&amp;1&amp;1&amp;1\\newline 1&amp;-1&amp;1&amp;-1\\newline 1&amp;i&amp;-1&amp;-i\\newline 1&amp;-i&amp;-1&amp;i \\end{bmatrix} \\] 未完待续","link":"/blog/42beb83a/"},{"title":"量子计算与计算复杂度（M. N. Vyalyi） Lecture 1","text":"在之前（还没更新）的课程中，主要讨论了量子计算的几种范式，并对其进行了一些形式化。从这里开始，我们将尝试对量子计算的复杂性理论做出详细的解释和说明，并表明其与经典计算复杂度类的关系。首先，有必要快速回顾一下经典复杂性理论带给我们的一些结果。 经典的复杂性理论研究的对象是受到资源限制的计算。我们需要在“简单的”和“困难的”问题之间做出区分，并将这种区分形式化。首先，我们需要考虑计算所需的资源：时间、空间，还有什么吗？ 交互资源（interaction）也是一种非标准的资源，在我们后面的讨论中，我们会经常用到相关的概念。交互资源主要有两种，谕示机（oracle）和实验者（prover）。谕示机知道问题的答案，而且它是可信的；实验者也知道问题的答案，但它是不可信的，需要提供一个证明。 谕示机（oracle）一词本来被译为“先知、神谕”，事实上这个义项可以很好地理解其意图；实验者（prover）这个说法相当奇怪，按照其直白的含义，应该叫做受质询者之类，但 prover 这个词本身并没有这种含义，所以姑且将其作此翻译。 另，实验者这个词在标准的教科书中似乎并没有出现，在下文看来它似乎与验证者（verifier）相应，在此注明。1 既然我们要讨论量子计算，那么量子过程（quantum process）也是一种资源，我们将其归为自然法则（laws of nature）一类。这一类还包括概然过程（probabilistic process），其与量子过程的差别在后文中会进一步提及。 概然过程（probabilistic process）一词似乎看起来应该译为随机过程，但是随机过程（stochastic process）在概率论中为一个专有名词，为了避免发生混淆，在这里亦作别译。 接下来我们快速地回顾以下经典复杂度理论的成果。 基本概念 为了讨论计算复杂度，我们需要从计算开始讲起。为了定义一种计算模型，我们需要给出构形空间（configuration space，可以理解为状态空间），即其所有可能的状态的总和。而一个基本的计算步骤（elementary computation step）可以被定义为一些从构形空间到其自身的函数，一个算法（algorithm）则是一串基本的计算步骤的序列。 在众多计算模型当中，我们选用图灵机（Turing machine）作为基本的计算模型。在这个模型中，构形为一个有限字母表上的序列、一个指针和一个控制态的三元组，一个基本的计算步骤为改变指针所指位置的字符、改变一格指针位置或者改变控制态。在这种情形下，我们可以很轻松地给出时间和空间复杂度的定义： 运行时间正比于一个算法所需的基本计算步骤的个数 所需花费的空间正比于任一构型中的字符串的长度 以 \\(\\vert x \\vert\\) 作为字符串 \\(x\\) 的长度，我们可以定义图灵机 \\(M\\) 代表的算法的最坏时间复杂度为： \\[ t_M(n) = \\max\\limits_{\\vert x \\vert = n} T_M(x) \\] 其中 \\(T_M(x)\\) 为输入 \\(x\\) 时图灵机 \\(M\\) 达到停机状态（halting state）所需的步数。 在复杂度理论的讨论中，我们感兴趣的是 \\(t_M(x)\\) 的渐进界，尤其是渐进上界。一种很重要的情形是多项式时间的算法，我们形式化地定义其为： \\[ t(n) \\in \\mathrm{poly}(n),\\ \\mathrm{if}\\ \\exists c_1, c_2 \\in \\mathbb{Z}_+:\\forall n \\in \\mathbb{Z}_+ t(n) \\leqslant c_1n^{c_2} \\] 一般的，我们认为有多项式时间界的算法为足够快地或者足够高效的。 大部分计算模型都是多项式时间等价的（考虑扩展的 Church-Turing 论题），因此这种分类在一般的计算模型中都是普遍可靠的，而且，它使得我们可以使用更加有力的工具（图灵机）来给出复杂度的渐进界。2 从中，我们可以抽象出复杂度类（complexity class）的概念。一个复杂度类是一些可以被给定的资源解决的问题的集合。 为了下面讨论的便利，我们定义几种计算问题。 函数的计算。记 \\(A^\\ast\\) 为一个有限集合 \\(A\\) 上的字符串的总和，计算 \\(f:A^\\ast \\rightarrow A^\\ast\\)。以下的文本中，我们都将 \\(A\\) 假定为 \\(\\{0, 1\\}\\)。 决策问题（decision problem）。我们称 \\(L \\subseteq A^\\ast\\) 为一个语言（language），一个决策问题就是计算 \\(L\\) 的示性函数（indicator function） \\(\\mathbb{1}_L(x)\\) 。 承诺问题（promise problem）。考虑两个不交的语言 \\(L_0\\) 和 \\(L_1\\)。给定 \\(x \\in L_0 \\cup L_1\\)，需要求解 \\(\\mathbb{1}_{L_1}(x)\\) 。很显然，对语言 \\(L\\) 的决策问题等价于 \\((L, L)\\) 的承诺问题。 一个很重要的复杂度类为 \\(\\mathsf{P}\\) 类，我们称 \\(L \\in \\mathsf{P}\\) ，若存在一个确定性算法使得其决策问题关于输入长度有多项式时间界。对于承诺问题，定义是类似的。 更广泛的，可以定义类 \\(\\mathsf{FP}\\)，如果一个函数 \\(f:A^\\ast \\rightarrow A^\\ast\\) 可以在多项式时间内被计算，则称 \\(f \\in \\mathsf{FP}\\) 。 复杂度类 \\(\\mathsf{NP}\\) 、规约和完全类 对于复杂度 \\(\\mathsf{NP}\\) 的定义，我们需要回到之前给出的交互资源的提法。直观地讲，在计算过程中，有验证者（verifier）和实验者。验证者只能解决 \\(\\mathsf{P}\\) 类问题，而实验者可以解决任何问题。而实验者是不受信的，因此它必须向验证者给出证明。我们形式化这种直观，将其定义如下： 我们称 \\(L \\in \\mathsf{NP}\\)，若存在 \\(V(x, y) \\in \\mathsf{P}\\) 和多项式 \\(p\\) 满足以下条件： 完备性：若 \\(x \\in L\\)，则 \\(\\exists y\\)，使得 \\(V(x, y) = 1\\) 且 \\(\\vert y \\vert \\leqslant p(\\vert x \\vert)\\) 。 可靠性：若 \\(x \\not \\in L\\)，则 \\(\\forall y\\)，\\(V(x, y) = 0\\) 。 其中 \\(V(x, y)\\) 就是对验证者的形式化。为了证明答案 \\(x\\) 是正确的，实验者需要给出证明 \\(y\\) ，其长度（耗费的空间资源）也应该是多项式的，使得利用 \\(y\\) 验证 \\(x\\) 是一个 \\(\\mathsf{P}\\) 类问题。而如果答案 \\(x\\) 是错误的，无论给出什么证明，都不能使得验证者误认为 \\(x\\) 是正确的。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{NP}\\)。我们下面不加证明地给出三个 \\(\\mathsf{NP}\\) 问题的例子，它们可能是属于 \\(\\mathsf{NP} \\setminus \\mathsf{P}\\) 的： \\(\\text{3-SAT}\\): 给定一个三变量的合取范式，确定其是否可满足。 \\(\\text{3-COLOR}\\): 给定一个图，确定其是否能被三种颜色染色。 \\(\\large\\text{P}\\small\\text{ARTITION}\\): 给定一列正整数，确定是否存在一个平均分划。 考虑计算问题的复杂度的排序方式。很直观地，如果我们能够将某个问题化作另一个问题，这个问题肯定不会比另一个问题更难解决。这种直觉使我们能够定义规约（reduction）这个概念，它定义了复杂度类中的一种二元关系。 我们称一个承诺问题 \\((L_0, L_1)\\) 可以多项式地规约（polynomial reduction, 或者 Karp reduction）到一个问题 \\((K_0, K_1)\\) ，如果存在一个函数 \\(f \\in \\mathsf{FP}\\)，使得： \\[ x \\in L_1 \\iff f(x) \\in K_1, x \\in L_0 \\iff f(x) \\in K_0 \\] 记作 \\((L_0, L_1) \\leqslant_p (K_0, K_1)\\) 。 很容易表明，这个二元关系具备传递性，只需观察到 \\(\\mathsf{FP}\\) 类中的函数的复合还在 \\(\\mathsf{FP}\\) 类中即可。这个二元关系引导我们定义出一个复杂度类中“最难”的问题，这些问题被称为完全问题（complete），因为它们事实上表征了整个复杂度类最难解的一些问题。 我们称一个问题 \\(P \\in \\mathcal{C}\\) 为 \\(\\mathcal{C}\\)-完全的，如果对任意 \\(L \\in \\mathcal{C}\\) ，有 \\(L \\leqslant_p P\\) 成立。 \\(\\mathsf{NP}\\) 类中同样包含一个完全集，这已经由 Cook 和 Levin 证明（通过 \\(\\text{3-SAT}\\) 问题）。事实上，上面举出的三个例子均为 \\(\\mathsf{NP}\\text{-complete}\\) 问题。 复杂度类的补、\\(\\text{co-}\\mathsf{NP}\\) 类 这里的考虑很好理解，既然我们定义了复杂度类，那么它自然而然地可以定义出一个补：设 \\(\\mathcal{C}\\) 为一复杂度类，则 \\(\\text{co-}\\mathcal{C}\\) 为其补，对任意 \\(L \\in \\mathcal{C}\\)，\\(\\bar L \\in \\text{co-}\\mathcal C\\)。 一个很显然的命题是，\\(\\mathsf{P} = \\text{co-}\\mathsf{P}\\)。我们只需要将算法的输出翻转一下，就可以得到 \\(\\text{co-}\\mathsf{P}\\) 问题的解。 \\(\\text{co-}\\mathsf{NP}\\) 和 \\(\\mathsf{NP}\\) 的关系仍然悬而未决，我们在这里给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\) 的问题： \\(\\large\\text{I}\\small\\text{NTEGER FACTORING}\\) 输入：一个正整数 \\(N\\) 的二进制表示 输出：\\(N\\) 的质因数分解 很显然，这不是一个决策问题。我们需要将其改写成决策问题： \\[ \\large\\text{B}\\small{\\text{IT}}\\large\\text{O}\\small{\\text{F}}\\large\\text{F}\\small\\text{ACTORING} = \\{\\langle N, i \\rangle : N \\text{ 的质因数分解第 } i \\text{ 位为 } 1\\} \\] 证明这个问题在 \\(\\mathsf{NP}\\) 中是显然的，实验者只需要给出一个分解作为证明即可。 注意到，判断一个数是否为素数是可以在多项式时间内完成的，参考 AKS 素数测试。 证明其属于 \\(\\text{co-}\\mathsf{NP}\\) 也并不困难，和上述方法是完全相同的。 我们还可以不加证明的给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\text{-complete}\\) 的承诺问题的实例，决策问题的例子仍然是未知的。 \\(\\large\\text{O}\\small\\text{NE}\\large\\text{O}\\small\\text{F}\\large\\text{T}\\small\\text{WO}\\) 输入：两个合取范式 \\(C_1\\), \\(C_2\\) 承诺：两者中必有一个是可满足的 问题：表明 \\(C_1\\) 是可满足的 概率性的计算，类 \\(\\mathsf{BPP}\\) 和 \\(\\mathsf{PP}\\) 如前所述，计算过程中，随机数也是一种资源。接下来我们探讨可以访问随机数的算法。在这里，我们将随机位认为是独立平均分布的，\\(0\\) 和 \\(1\\) 出现的概率各占一半。 对于一个涉及随机数的计算，出错也是难免的，因此，我们要提出的第一个问题是，如何定义一个成功的计算？ 直觉地，我们认为，一个计算如果正确的概率“过半”，那它就是成功的，设 \\(f(x)\\) 为目标函数，\\(\\text{Res}(x)\\) 为计算结果，我们可以形式化这个定义为： \\[ \\forall x, \\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; a \\leqslant \\frac 1 2 \\] 注意到我们留了一个 \\(a\\) 作为参量。这是因为，\\(a\\) 是否等于 \\(\\frac 1 2\\) 的情形是完全不同的，其区别的来源是一个算法能否被强化（amplify），即，经过多次重复这个算法（ \\(t\\) 次），然后取出现最频繁的结果，这样似乎能够增加其准确性。事实上，可以证明以下命题成立： 若 \\(\\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; \\frac 1 2 - \\epsilon\\)，则增强后的算法出错的概率为： \\[ \\Big(2\\sqrt{\\frac 1 4 - \\epsilon ^2}\\Big)^t \\] 也就是说，\\(a &lt; \\frac 1 2\\) 时，算法出错的概率可以逐渐收敛到 \\(0\\)，若 \\(a = \\frac 1 2\\)，则我们并不能得出有用的结果。这样我们可以定义两个复杂度类： 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{BPP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 2 3\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 3\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{BPP}\\)，只需要取 \\(p = 0\\) 即可。 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{PP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 1 2\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 2\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 同样显然地，\\(\\mathsf{BPP} \\subseteq \\mathsf{PP}\\)，\\(\\mathsf{PP} = \\text{co-}\\mathsf{PP}\\)。 接下来，我们要表明另一个复杂度层级，\\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)，从而使我们的复杂度继承关系形如下图： 为了给出这个证明，我们需要引出一些额外的定义，并从另一个角度重新表述 \\(\\mathsf{NP}\\) 和 \\(\\mathsf{PP}\\) 的定义。 证明 \\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)：非确定性图灵机、\\(\\mathsf{\\#P}\\)-函数和间隙函数 非确定性图灵机（non-deterministic Turing machine, NTM）与确定性图灵机的差别在于，在每一步计算中，它可以在转移函数之间做出随机选择。因此，NTM 的计算过程是一棵含根的树，而非一列构形空间的序列。树的根部为起始状态，叶为停机状态，从根部到叶的一条路径称为一条计算路径（computation path），计算路径的最大值被定义为这个 NTM 的运行时间。 我们考虑停机状态有两种，接受（accept）和拒绝（reject）。记接受的路径的总数为 \\(\\text{acc}_M(x)\\)，其中 \\(M\\) 为一图灵机，\\(x\\) 为一输入。 接下来我们定义 \\(\\mathsf{\\#P}\\)-函数和间隙函数的概念。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}_+\\) 为一个 \\(\\mathsf{\\#P}\\)-函数，若存在一个多项式运行时间的 NTM \\(M\\) 使得 \\(\\forall x, f(x) = \\text{acc}_M(x)\\)。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}\\) 为一个间隙函数（gap function），若存在两个 \\(\\mathsf{\\#P}\\)-函数 \\(g, h\\)，使得 \\(\\forall x, f(x) = g(x) - h(x)\\)。 未完待续 绿色方块标识的内容均为译注，下同。↩︎ 蓝色方块标识的内容均为原注，下同。↩︎","link":"/blog/b5738fe7/"}],"tags":[{"name":"源码阅读","slug":"源码阅读","link":"/blog/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"程序分析","slug":"程序分析","link":"/blog/tags/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"复杂度","slug":"复杂度","link":"/blog/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6/"},{"name":"概率论","slug":"概率论","link":"/blog/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"信息论","slug":"信息论","link":"/blog/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"},{"name":"计算理论","slug":"计算理论","link":"/blog/tags/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"量子计算","slug":"量子计算","link":"/blog/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"},{"name":"复杂度理论","slug":"复杂度理论","link":"/blog/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6%E7%90%86%E8%AE%BA/"}],"categories":[{"name":"源码阅读笔记","slug":"源码阅读笔记","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"论文笔记","slug":"论文笔记","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"课程笔记","slug":"课程笔记","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"GDB 源码分析","slug":"源码阅读笔记/GDB-源码分析","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/GDB-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"计算理论","slug":"论文笔记/计算理论","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"量子算法与编程暑期讲习班","slug":"课程笔记/量子算法与编程暑期讲习班","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/"},{"name":"Martin Löf(1966)","slug":"论文笔记/计算理论/Martin-Lof-1966","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/Martin-Lof-1966/"},{"name":"量子编程","slug":"课程笔记/量子算法与编程暑期讲习班/量子编程","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/%E9%87%8F%E5%AD%90%E7%BC%96%E7%A8%8B/"}]}