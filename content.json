{"pages":[],"posts":[{"title":"抽象代数续论笔记 01 群、幺半群、可解群以及一些例子","text":"因为这门课是续论课，所以对于很多基本的概念性内容都报以回顾性的态度，在这里也同样会过得很快，简单的证明也会略过。第一次课回顾了群的一些基本概念，给出了一些例子；定义了可解群且给出了一个矩阵群中的例子。 这门课的思路比较混乱，因为是一门拾遗类型的课程，主要是起到衔接的作用，因此这里的笔记也不算太有条理。 基本定义和例子 我们称满足以下三条公理的带有二元运算的集合 (G, ) 为一个群： 二元运算满足结合律； 存在单位元； 每个元素都存在逆元； 如果只满足上面两条公理，则称其为幺半群（monoid）。容易表明，幺半群中的单位元具备唯一性。根据二元运算是否满足交换律，我们将幺半群分为交换的与非交换的；如果幺半群 \\(M\\) 的一个子集 \\(S\\) 含有单位元并对二元运算封闭，则称其为一个子幺半群（submonoid），子群的定义与之类似。 很容易给出子幺半群的一些例子，例如，线性空间中 \\(V\\) 上的自同构群 \\(\\mathrm{Aut}(V)\\) （也记作一般线性群 \\(GL(V)\\)）是其自同态幺半群 \\(\\mathrm{End}(V)\\) 的一个子幺半群。 我们称幺半群间的映射 \\(\\varphi: M_1 \\to M_2\\) 为一个幺半群同态，若其保乘法、保单位元；若 \\(M_1\\) 和 \\(M_2\\) 都是群，也将其称为一个群同态。 一个例子是域 \\(K\\) 上的线性空间 \\(V\\) 的自同态群 \\(\\mathrm{End}V\\) 到视作幺半群的 \\((K, \\cdot)\\) 的一个幺半群同态行列式运算 \\(\\det\\)。注意，这里的 \\((K, \\cdot)\\) 不是群，因为 \\(0\\) 没有乘法逆元。 我们可以定义一个群结构 \\(M(S, G)\\)，其元素是从非空集合 \\(S\\) 到群 \\(G\\) 的映射全体，对于任意 \\(f, g \\in M(S, G)\\)，我们定义 \\((fg)(a) = f(a)g(a)\\)，称其为 pointwise multiplication。当然，它的乘法单位元就是将 \\(S\\) 中的所有元素映到 \\(G\\) 的单位元，映射 \\(f\\) 的逆元定义为 \\((f^{-1})(a) = (f(a))^{-1}\\)。 这个定义是为了什么引入的来着？ 置换群也是一类很常见的群，设 \\(S\\) 为一有限集合，记 \\(\\mathrm{Perm}(S) = \\{f: S \\to S \\vert f 是双射\\}\\)。其中的复合、单位元和逆元的定义都是简单的。很显然，若 \\(G\\) 为一群，\\(\\mathrm{Aut} (G)\\) 是 \\(\\mathrm{Perm} (G)\\) 的子群。 对域 \\(K\\) 上的线性空间 \\(V\\)，我们显然可以定义一个群同构 \\(GL(n, K) \\to GL(V)\\)，其中 \\(n = \\dim_KV\\)。 我们可以建立正多边形的自同构，设 \\(A_n\\) 为正 \\(n\\) 边形，我们记 \\(\\mathrm{Aut}(A_n) = \\{\\varphi \\vert \\varphi(A_n) = A_n, \\varphi 为等距映射\\}\\)，我们称这样的群为二面体群，记作 \\(D_{2n}\\)，有些书也会记作 \\(D_n\\)。任何 \\(n \\leqslant 3\\) 的二面体群 \\(D_{n}\\) 都可表成 \\(\\langle \\sigma \\tau \\vert \\sigma^n = 1, \\tau^2 = 1, \\tau \\sigma \\tau^{-1} = \\sigma^{-1}\\rangle\\) 的形式，称为 \\(n\\) 阶二面体群。 类似地我们可以定义 \\(\\mathbb{R}^2\\) 上的等距同构，对于一个距离 \\(d\\)，我们记 \\(\\mathrm{Aut}(\\mathbb{R^2}, d)\\) 为 \\(\\mathbb{R}\\) 上的等距同构全体。我们也已经知道，它可以被写成旋转群 \\(O(\\mathbb R^2)\\) 和平移群 \\(T(\\mathbb R^2)\\) 的半直积（semi-direct product）。 下一个例子是关于多项式环 \\(K[x, y]\\) 上的自同构群。设 \\(\\varphi: K[x, y] \\to K[x, y]\\) 是一个线性保持乘法的双射，将 \\(x\\) 映到 \\(f(x, y)\\), 将 \\(y\\) 映到 \\(g(x, y)\\)，则一个将 \\(h(x, y)\\) 映到 \\(h(f, g)\\) 的映射是一个自同态。它是否是一个自同构是一个开放问题，一般称为 Jacobi 猜想或者 Keller 问题。 很容易定义群的直积的概念，给定群 \\(G, H\\)，称它们的直积为一个笛卡尔积 \\(G \\times H\\)，其上的二元运算定义为每一个分量分别做运算。群的生成元的定义在此也不再赘述。 接下来考虑一个很常见的群，四元数群。其中有八个元素 \\(\\{\\pm 1, \\pm i, \\pm j, \\pm k\\}\\)。其乘法定义为： \\[ ij=k=-ji, jk=i=-kj, ki=j=-ik, i^2=j^2=k^2=-1 \\] 它是八阶群中的一个，容易证明八阶群一共有五个，分别是 \\(C_8, C_2 \\times C_4, C_2^3, D_8\\) 和四元数群。 四元数群在 \\(\\mathbb R\\) 上张成一个四维线性空间，其中 \\(1, i, j, k\\) 构成了标准正交基，四元数群是其中单位球面群的子群。其上的实内积定义为 \\((a, b) = \\Re(a\\bar b)\\)，由此内积定义的范数是可乘的。我们在后面还会再次碰到四元数群。 我们定义一个群 \\(G\\) 的内自同构群 \\(\\mathrm{Inn}(G)\\)。首先定义 \\(G\\) 上关于元素 \\(a\\) 的共轭，记作 \\(C_a: G \\to G\\)，它将每个元素 \\(g\\) 映到 \\(aga^{-1}\\)。容易证明，\\(\\varphi: G \\to \\mathrm{Aut}(G)\\) 为一个同态，记 \\(\\mathrm{Inn}(G) = \\mathrm{Im}(G)\\)，不难证明其为 \\(\\mathrm{Aut}(G)\\) 的正规子群。同样容易表明，如果 \\(G\\) 是交换群，那么 \\(\\mathrm{Inn}(G)\\) 为平凡群。 自同态的概念不再赘述，可以观察到以下结果：对于有理数加群 \\(\\mathbb{Q}\\)，把 \\(a\\) 映到 \\(na\\) 的映射 \\(\\varphi_n\\) 是一个自同构，而对于整数加群 \\(\\mathbb Z\\)，这只是一个自同态。 考虑投影 \\(P_1: G_1 \\times G_2 \\to G_1\\) 和 \\(P_2: G_1 \\times G_2 \\to G_2\\)，很显然，它们都是满射，而且它们的核 \\(\\mathrm{Ker} P_i \\simeq G_{2-i}\\)。 在这里可以补叙 Goursat 定理，它出现在了作业题中（Algebra, S. Lang, p75 Ex. 5） 设 \\(G\\)，\\(G'\\) 为群，\\(H\\) 为 \\(G \\times G'\\) 的子群，且满足投影 \\(P_1: H \\to G\\) 和 \\(P_2: H \\to G'\\) 都是满射。设 \\(N = \\mathrm{Ker}(P_2), N' = \\mathrm{Ker}(P_1)\\)，容易表明，\\(N, N'\\) 分别同构于 \\(G, G'\\) 的一个正规子群，则 \\(H\\) 在 \\(G/N \\times G'/N'\\) 中的图像是 \\(G/N\\) 到 \\(G'/N'\\) 的一个同构。 接下来我们给出一个类似于半直积的构造的命题：设 \\(G\\) 为一群，\\(H, K\\) 为其子群，\\(H \\cap K = \\{e\\}\\)，\\(HK = G\\)，且 \\(\\forall x \\in H, y \\in K, xy=yx\\)，则 \\(\\varphi: H \\times K \\to G\\)，\\(\\varphi(x, y) = xy\\) 为一个同构。 首先证明它是一个群同态。很显然： \\[\\begin{align} \\varphi(x_1, y_1)\\varphi(x_2, y_2) = x_1y_1x_2y_2 =x_1x_2y_1y_2 =\\varphi(x_1x_2, y_1y_2) \\end{align}\\] 这里利用了上面给出的可交换性； 它是满射直接由 \\(HK=G\\) 得出，然后表明它是单射，考虑它的核中的元素 \\((x, y)\\)： \\[\\begin{align} \\varphi(x, y) = xy = e \\Rightarrow x=y^{-1} \\in H \\cap K \\Rightarrow x=y=e \\Rightarrow \\mathrm{Ker}(\\varphi) = {e} \\end{align}\\] 由此，\\(\\varphi\\) 是一个满射。 有一个看起来比较优雅的推论：设 \\(H \\triangleleft G, K \\triangleleft G, H \\cap K = \\{e\\}\\)，则 \\(H \\times K \\to G\\) 为一个嵌入。 如上我们只要证明交换性： \\[\\begin{align} hkh^{-1}k^{-1} = (hkh^{-1})k^{-1} = h(kh^{-1}k^{-1}) \\in H \\cap K \\Rightarrow hkh^{-1}k^{-1} = e \\Rightarrow hk=kh \\end{align}\\] 这个证明很自然地体现了一个问题，即 \\(aba^{-1}b^{-1}\\) 事实上刻画了一个群的“交换性”。延续这个思路可以引入换位子群（或导群）的概念，记 \\(G' = \\{aba^{-1}b^{-1} \\mid a, b \\in G\\}\\)。 首先，可以表明它是群 \\(G\\) 的一个正规子群： \\[\\begin{align} \\forall a \\in G', g \\in G, gag^{-1} = (gag^{-1}a^{-1})a \\in G' \\end{align}\\] 接下来，很容易表明，\\(G/G'\\) 是一个交换群： \\[\\begin{align} \\forall gG', hG' \\in G/G', (hg)^{-1}(gh) = g^{-1}h^{-1}gh \\in G' \\Rightarrow ghG' = hgG' \\end{align}\\] 最后，读者当不难自证，设 \\(N \\triangleleft G\\)，若 \\(G/N\\) 交换，则 \\(G' \\subseteq N\\)。 这个群在表示论和 Galois 理论等方面都有应用，在此稍作叙述。 接下来对于陪集、商群、指标和阶的定义都直接略去，Lagrange 定理读者应当也已经熟悉。正规子群的交和乘仍然是正规子群，这个结论也不再证明。 设 \\(S\\) 为群 \\(G\\) 的一个子集。称 \\(N_G(S) = \\{g \\in G \\mid gSg^{-1} = S\\}\\) 为群 \\(G\\) 对于集合 \\(S\\) 的正规化子（Normalizer）。不难证明，\\(\\langle S \\rangle \\triangleleft N_G(S) \\leqslant G\\)。称 \\(C_G(S) = \\{g \\in G \\mid ga = ag, \\forall a \\in S\\}\\) 为群 \\(G\\) 对集合 \\(S\\) 的中心化子，同样不难证明，\\(C_G(S) \\leqslant G\\)。称 \\(C_G(G)\\) 为群的中心（center）。 称 \\(x\\) 和 \\(y\\) 关于 \\(H\\) 同余（congruent），若 \\(xH = yH\\)，记作 \\(x \\equiv y\\ (\\mathrm{mod}\\ H)\\)。 我们称如下群与态射的序列为一个正合列（exact sequence） \\[\\begin{align} G_1 \\stackrel{f_1}{\\longrightarrow} G_2 \\stackrel{f_2}{\\longrightarrow} \\cdots \\stackrel{f_{n-1}}{\\longrightarrow} G_n \\end{align}\\] 若 \\(\\forall 1 &lt; i &lt; n-2, \\mathrm{Im} f_i = \\mathrm{Ker} f_{i+1}\\)。一个形如 \\[ 1 \\rightarrow G' \\rightarrow G \\rightarrow G' \\rightarrow 1 \\] 的正合列被称为一个短正合列。 事实上，我们会发现，在一个范畴中的对象有： \\[ 1 \\rightarrow \\mathrm{Ker}\\ f \\rightarrow A \\stackrel{f}{\\longrightarrow} B \\rightarrow \\mathrm{Coker}\\ f \\rightarrow 1 \\] 是一种非常常见的现象。当然，在 \\(\\mathsf{Grp}\\) 中，由于只有 \\(\\mathrm{Im}\\ f \\triangleleft B\\) 才能考虑 \\(\\mathrm{Coker}\\ f\\)，所以在这里它不完全成立。 正合列是同调代数研究的中心问题。 一个很显然的短正合列是这样的： \\[ 1 \\rightarrow H \\hookrightarrow G \\stackrel{\\mathrm{can.}}{\\longrightarrow} G/H \\rightarrow 1 \\] 我们应当已经很熟悉群的同态基本定理，设 \\(f: G \\to G'\\) 为一群同态，\\(N \\triangleleft G\\)，则存在 \\(f*: G/N \\to G'\\) 使得 \\(\\varphi \\circ f = f*\\)，其中 \\(\\varphi\\) 为典范同态。它的一个典型应用如下图： \\(\\require{AMScd}\\) \\[\\begin{CD} 1 @&gt;&gt;&gt; H @&gt;&gt;&gt; G @&gt;&gt;&gt; G/H @&gt;&gt;&gt; 1\\\\ @. @VVV @VVV @VVV @.\\\\ 1 @&gt;&gt;&gt; H/K @&gt;&gt;&gt; G/K @&gt;&gt;&gt; G/H @&gt;&gt;&gt; 1 \\end{CD}\\] 其中 \\(K \\triangleleft H \\triangleleft G\\)，每行都是一个短正合列。 其他同构定理在此不再叙述，可参考 Algebra, S. Lang p16 起的内容。 顺便给出两个命题：正规子群在群同态下的原像是正规的；正规子群在满同态下的像是正规的，这其实是上面的 remark 中 cokernel 存在性问题的另一种描述。 群塔和可解群 我们称以下一个群序列为一个群塔（tower of groups）： \\[ G = G_0 \\supset G_1 \\supset \\cdots \\supset G_m \\] 称其为一个正规群塔，若 \\(G_i \\triangleright G_{i+1}\\)，称其为一个交换群塔，若它在正规的同时还满足 \\(G_i/G_{i+1}\\) 是交换的。同理可以定义循环群塔。 若 \\(G\\) 为一个群，存在一个交换群塔： \\[ G = G_0 \\supset G_1 \\supset \\cdots \\supset G_m = 1 \\] 则称 \\(G\\) 是可解群（solvable group）。可以证明，若 \\(G\\) 可解，则它的子群和商群均可解；若 \\(H \\triangleleft G\\)，\\(G/H\\) 可解，则 \\(G\\) 可解。 接下来我们在矩阵群中给出可解群的一个例子。设 \\(T=T(n, K)\\) 为 \\(n\\) 维方阵在域 \\(K\\) 的上三角矩阵群，\\(D=D(n, K)\\) 为域 \\(K\\) 上对角线不为 \\(0\\) 的 \\(n\\) 维对角方阵群，\\(N(n, K)\\) 维对角线下方及对角线上为 \\(0\\) 的幂零矩阵的加法群。则可以很容易构造一个从 \\(T(n, K)\\) 到 \\(D(n, K)\\) 的满同态，即只取其对角线上的元素。这个群同态的核显然就是 \\(U = I + N\\)，其中 \\(I\\) 为单位矩阵。 记 \\(N^r(n, K)\\) 为幂零矩阵的 \\(r\\) 次方的加法群，\\(U_r = I + N^r(n, K)\\)，注意到 \\(U_i\\) 构成了 \\(U\\) 的一个正规群塔，而 \\(U\\) 是 \\(T\\) 的正规子群，\\(T/U=D\\) 为交换群，所以有交换群塔： \\[ T \\supset U = U_1 \\supset U_2 \\supset \\cdots \\supset U_n = \\{I\\} \\] 故 \\(T\\) 为可解群。","link":"/blog/39b94080/"},{"title":"GDB 源码分析 01：函数前导代码分析（上）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 函数前导代码其实很简单也很固定，它主要就是进入一个函数时进行的代码操作，用来建立栈帧，并为临时变量开好空间。这里展示一个 x86 汇编的最简单情形： 123push ebpmov ebp, espsub esp, N 很简单，很友好，不是吗？ 那么为什么要对这块代码进行重点分析呢？一方面，这是一个函数开头的部分，可以用来分析这个函数调用栈的情况，并分析这个函数所使用的临时变量地址；另一方面，虽然看起来这段代码很可爱，但是随着编译器的复杂化和在调度指令时日益激进的策略，它往往会变得面目全非。但无论如何，这段代码总归是相对简单的部分。 事实上，在现代的 gcc 编译器中往往会给出调用栈信息（call frame information, CFI），其中描述了如何寻找栈的基地址和存储的寄存器等信息，但是这些信息并不总是存在。如果它们不存在，我们就必须采用一些策略来试图解读这些信息。为了解读这些信息，我们就采用一种对指令“抽象解读”的策略，也就是下面将介绍的模糊计算策略。 值的模糊计算 在 prologue-value.h 中，定义了如下结构： 12345enum prologue_value_kind { pvk_unknown, pvk_constant, pvk_register}; 这里所描述的是一个 prologue 值的类型，分别表示未知、常数和寄存器，它决定了在下面的结构体中，后面两个参数应该如何解读。 123456struct prologue_value { enum prologue_value_kind kind; int reg; CORE_ADDR k;};typedef struct prologue_value pv_t; 如果类型是 pvk_unknown，那么后面两个参数都没有意义，毕竟我们对它一无所知； 如果类型是 pvk_constant，这表明这个值就是常数，记录在 k 中。注意，所谓的 CORE_ADDR 实际上就是一个 uint64_t； 如果类型是 pvk_register，这表明寄存器 reg 所对应的原始值为 初始值 + k ，其中 reg 为 GDB 标定的寄存器编号，是为了防止不同架构带来的跨平台问题。在开始分析之前，所有寄存器都会被标为 {pvk_register, reg, 0} 每个类型都有相关的初始化函数，它们实现起来并不困难： 1234567891011121314151617181920pv_t pv_unknown(void) { pv_t v = {pvk_unknown, 0, 0}; return v;}pv_t pv_constant(CORE_ADDR k) { pv_t v; v.kind = pvk_constant; v.reg = -1; v.k = k; return v;}pv_t pv_register(int reg, CORE_ADDR k) { pv_t v; v.kind = pvk_register; v.reg = reg; v.k = k; return v;} 随后我们要对这些值进行“保守估计”，保守估计的意思是说，我们会把一个值正确估计或者设为未知，但不能出现错误的估计。对应于这种估计方式的逻辑变量是这样的： 12345enum pv_boolean { pv_maybe, pv_definite_yes, pv_definite_no}; 然后通过看相关的函数来理解其原理： 1234567static void constant_last(pv_t *a, pv_t *b) { if (a-&gt;kind == pvk_constant &amp;&amp; b-&gt;kind != pvk_constant) { pv_t temp = *a; *a = *b; *b = temp; }} 这个函数就是个辅助函数。如果前者是常数而后者不是常数，对两者做个交换。这个函数在后面只是用来减少需要处理的情况总数的。接下来是对一大批寄存器运算的模拟。 1234567891011121314pv_t pv_add(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k + b.k); } else if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k + b.k); } else { return pv_unknown(); }}pv_t pv_add_constant(pv_t v, CORE_ADDR k) { return pv_add(v, pv_constant(k));} 首先实现加法的计算。这里的过程看起来很简单：两个常数可以加，寄存器可以加上常数，但其他的加法都返回未知。如果要处理常数加法，那就将常数转换成对应的类型再相加。这里不妨停一下思考两个问题： 为什么寄存器和寄存器不能相加？ 为什么常数加法的情况在两个函数中都进行了处理？ 这里我们需要注意，我们并不会实际执行程序，只是取其中的一个片段进行分析。在分析这个片段的时候，寄存器的初始值是未知的。因此，我们总共知道的就是，某个寄存器相比其进入这个片段之前多了或者少了多少。如果将寄存器与寄存器相加，那么势必要用到初始值，也就是说，它的结果对我们来说是未知的。 对于第二个问题，需要注意，加常数的情况并不仅仅存在于显式的指令编码中。例如，在下面将读到的 logical_and 函数中，如果出现与常数 0 做 and 操作，这个寄存器的值就会变成常数 0 ，于是，当它与另一个寄存器相加时，就会进入寄存器与常数相加的情形。 接下来按照这个思路，可以很简单的实现减法和逻辑与运算，代码如下： 1234567891011121314151617181920212223242526272829pv_t pv_subtract(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_constant) { return pv_register(a.reg, a.k - b.k); } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg) { return pv_constant (a.k - b.k); } else { return pv_unknown(); }}pv_t pv_logical_and(pv_t a, pv_t b) { constant_last(&amp;a, &amp;b); if (a.kind == pvk_constant &amp;&amp; b.kind == pvk_constant) { return pv_constant(a.k &amp; b.k); } else if (b.kind == pvk_constant &amp;&amp; b.k == 0) { return pv_constant(0); } else if (b.kind == pvk_constant &amp;&amp; b.k == ~(CORE_ADDR) 0) { return a; } else if (a.kind == pvk_register &amp;&amp; b.kind == pvk_register &amp;&amp; a.reg == b.reg &amp;&amp; a.k == b.k) { return a; } else { return pv_unknown(); }} 这两段的代码逻辑也相当清晰，如果理解了什么叫做保守估计，那么应该也能很轻松地读懂。主要的难点在于理解什么情况下可以对这个操作做出准确的估计，什么时候不能。基于这些计算方式，我们就可以基本上知道某段代码结束之后，能得到怎样的结果了。 这里需要注意，如果出现了除算术指令之外的其他指令，其结果就基本上全是 pvk_unknown 了。所以，这里所做的只是一个前导代码分析，因为函数的前导代码往往不会包含太复杂的东西。 对模糊值做出判断 当我们知道一段代码运行之后的结果之后，我们就可以尝试确定一些东西了，比如某个对象是否落在一个数组里。但在进行这些判断之前，先要有三个最普通的判断函数：判断某个值是否是常数、是否是某个寄存器、是否是某寄存器 初始值 + k 的结果，这三个函数将成为后面应用的基石。 1234567891011int pv_is_constant(pv_t a) { return (a.kind == pvk_constant);}int pv_is_register(pv_t a, int r) { return (a.kind == pvk_register &amp;&amp; a.reg == r);}int pv_is_register_k(pv_t a, int r, CORE_ADDR k) { return (a.kind == pvk_register &amp;&amp; a.reg == r &amp;&amp; a.k == k);} 接下来我们要开始考虑，如何判断一个对象是否落在某个数组里。很显然，我们需要考虑如何描述一个对象和如何描述一个数组。我们需要的参数有： 描述一个对象在内存中的位置和长度，pv_t addr 和 CORE_ADDR size； 描述一个数组在内存里的位置和长度，pv_t array_addr 和 array_len （数组长度），以及 CORE_ADDR elt_size （数组内每个元素的大小）； 返回值，是不是指向某个完整元素，以及如果指向某个完成元素，其对应的指标 int *i。 在开始考虑如何写这个函数之前，我们需要明确地指出这个函数的功能以及它的返回类型。它的返回类型是 enum pv_boolean 型： 如果这个对象一定落在数组中，那么返回 pv_definite_yes ，并把 I； 如果这个对象一定不落在数组中，那么返回 pv_definite_no； 如果不能判断、或者不指向完整的数组元素，那么返回 pv_maybe 。 好，接下来可以开始写这个函数了： 1234567891011121314151617enum pv_boolean pv_is_array_ref(pv_t addr, CORE_ADDR size, pv_t array_addr, CORE_ADDR array_len, CORE_ADDR elt_size, int *i) { pv_t offset = pv_subtract(addr, array_addr); if (offset.kind == pvk_constant) { if (offset.k &lt;= -size &amp;&amp; offset.k &gt;= array_len * elt_size) { return pv_definite_no; } else if (offset.k % elt_size != 0 || size != elt_size) { return pv_maybe; } else { *i = offset.k / elt_size; return pv_definite_yes; } } else { return pv_maybe; }} 这里的逻辑其实很简单：如果对象的起始地址和数组起始地址不能相减或相减不为常数，我们都不能严格做出判断。然后我们考虑这样的情形： 这里就是第一个比较的来源：只有当 offset &lt;= -size 时，才能明确判断说这个元素不在数组内，同样的，第二个比较发生在右边。然后检查是否对齐。如果不对齐，那只能是 pv_maybe。只有当对齐且元素大小等于数组元素大小，且偏移量落在数组之内时，才会返回 pv_definite_yes 。 我们上面的这些工作都只是完成了这个模块的第一部分。为了真正让这个模块得以被使用，还需要具备分析一个内存块的内容的能力。这就是第二部分将要讨论的内容。","link":"/blog/5ad3ba87/"},{"title":"GDB 源码分析 02：函数前导代码分析（中）","text":"代码：gdb/prologue-value.h，gdb/prologue-value.c 上一次，我们考虑了如何对一个值进行模糊分析，接下来，我们要对一片内存的值做出模糊的估计。在有了这种估计方式之后，我们就能够将其进行真正的应用了。 首先考虑一个问题：如何记录一个内存中的数据？不要忘记，我们需要分析一个函数的前导代码，而前导代码往往做的是栈操作。那么，既然我们不能预先知道栈地址的值，我们自然就得以一个寄存器作为基地址，那么我们需要存储的就是某个地址距离基地址寄存器的偏移量；同时，内存中的对象并不自带类型，所以需要长度作为其标识；最后，我们还要记下它的值。这就是下面这个结构体想要做的事情： 123456struct pv_area::area_entry { struct area_entry *prev, *next; CORE_ADDR offset; CORE_ADDR size; pv_t value;} 注意到它有两个指向前后的指针。事实上，它构成了一个环形双向链表，在后面的分析中，我们还会看到，它是以偏移量的大小进行排序的。然后就是把这个双向链表包装成一个类： 123456class pv_area {private: int m_base_reg; CORE_ADDR m_addr_mask; struct area_entry *m_entry;} 其中除了指向这样一个链表的指针之外，还有基地址寄存器的寄存器号，以及一个地址的掩码。看到后面之后会更容易理解这个掩码的目的，在这里我们只需要简单地认为，我们的地址空间是一个环形，前后相连即可。 接下来看类里面的三个私有成员函数： 1234567891011void pv_area::clear_entries() { struct area_entry *e = m_entry; if (e) { do { struct area_entry *next = e.next; xfree(e); e = next; } while (e != m_entry); m_entry = 0; }} 这个函数用来清空双向链表。其中比较需要注意的就是 xfree 这个函数，事实上这个函数和内存保护有关，在读到这里的时候，我们不妨将其当成一个简单的 free 函数理解。 12345678910111213141516struct pv_area::area_entry *pv_area::find_entry(CORE_ADDR offset) { struct area_entry *e = m_entry; if (!e) { return 0; } while (((e-&gt;next-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;next; } while (((e-&gt;prev-&gt;offset - offset) &amp; m_addr_mask) &lt; ((e-&gt;offset - offset) &amp; m_addr_mask)) { e = e-&gt;prev; } m_entry = e; return e;} 这个函数用来找到在 offset 之后的第一项。如果本身这片区域一项也没有，那么就自然地返回一个空指针。而如果 offset 中一项也没有，那当然就会返回较为靠前的一项。这里需要澄清的是，因为 m_entry 指向的是环形链表中的任意一项，往后扫描和往前扫描都是必须的。最后一步将 m_entry 设为 e 就是出于局部性的假定，假定最近被访问的这项很可能再次被访问，从而提高整个数据结构的搜索效率。 在此不妨停下来思考一个问题：哪怕没有掩码的问题，是否有可能直接写成 e-&gt;next-&gt;offset &lt; e-&gt;offset ？答案是否定的，原作者在注释中特别表明了这一点： 123456/*Note that, even setting aside the addr_mask stuff, we must not simplify this, in high school algebra fashion, to (e-&gt;next-&gt;offset &lt; e-&gt;offset), because of the way &lt; interacts with wrap-around. We have to subtract offset from both sides to make sure both things we're comparing are on the same side of the discontinuity. */ 解释很清楚，在这也就不翻译了。 第三个函数就是一个判断 offset 处 size 大小的一项是否与某个 entry 重合，非常简单，直接贴代码不解释： 1234int pv_area::overlaps(struct area_entry *entry, CORE_ADDR offset, CORE_ADDR size) { return (((entry-&gt;offset - offset) &amp; m_addr_mask) &lt; size || ((offset - entry-&gt;offset) &amp; m_addr_mask) &lt; entry-&gt;size);} 接下来观察一下公有的成员函数，首先来看构建过程： 123pv_area::pv_area(int base_reg, int addr_bit): m_base_reg(base_reg), m_addr_mask(((((CORE_ADDR) 1) &lt;&lt; (addr_bit - 1)) - 1) &lt;&lt; 1) | 1), m_entry(nullptr){} 非常简单的构造函数，但是这里我们就可以重新解释一下地址掩码的含义了。当我们有一个 32 bit 的地址时，自然而然地我们只希望其比较 32 bit，但是寄存器又是可以有 64 bit 的：也就是说，有一部分是需要被抛弃的。 一个很细节的问题是，为什么不把这个表达式写成 ((CORE_ADDR) 1 &lt;&lt; addr_bit) - 1 ？注意，移位的位数与类型的宽度相同时，得到的结果是未定义的。如果采取上面代码的形式，就一定能够保证得到正确的结果。 析构函数非常简单： 123pv_area::~pv_area() { clear_entries();} 然后用了一个有趣的小技巧取消了默认析构函数和 operator=： 1DISABLE_COPY_AND_ASSIGN(pv_area); 宏定义如下，这是为了与不同版本的 c++ 标准兼容： 123456789#if defined(__cplusplus) &amp;&amp; __cplusplus &gt;= 201103#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;) = delete; \\ void operator= (const TYPE &amp;) = delete #else#define DISABLE_COPY_AND_ASSIGN(TYPE) \\ TYPE (const TYPE&amp;); \\ void operator= (const TYPE &amp;)#endif 接下来我们就要正式进行模拟存取了。下面这个成员函数用来将一个 size 大小的值 value 写入到 addr 处： 123456789101112131415161718192021222324252627282930313233void pv_area::store(pv_t addr, CORE_ADDR size, pv_t value) { if (store_would_trash(addr)) { clear_entries(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); while (e &amp;&amp; overlaps(e, offset, size)) { struct area_entry *next = (e-&gt;next == e) ? 0 : e-&gt;next; e-&gt;prev-&gt;next = e-&gt;next; e-&gt;next-&gt;prev = e-&gt;prev; xfree(e); e = next; } m_entry = e; } if (value.kind == pvk_unknown) { return; } else { CORE_ADDR offset = addr.k; struct area_entry *e = XNEW(struct area_entry); e-&gt;offset = offset; e-&gt;size = size; e-&gt;value = value; if (m_entry) { e-&gt;prev = m_entry-&gt;prev; e-&gt;next = m_entry; e-&gt;prev-&gt;next = e-&gt;next-&gt;prev = e; } else { e-&gt;prev = e-&gt;next = e; m_entry = e; } }} 这个函数稍微有点长，但是思路其实挺简单的： 如果存储操作会使得我现在所有的表项都被无效化，那么直接先把表清掉； 否则的话，清掉所有与这个值重合的项，因为这些项都会被覆写掉； 然后，如果我需要存的值未知，那就直接返回； 如果我需要存的值已知，那就创建出这一项并把它插进去。 XNEW(T) 事实上拓展到了泛型 xnew&lt;T&gt;() ，这个函数和前面的 xfree 一样，只需要当成一个 new 就行，暂时不需要深究；接下来需要考虑的是，什么时候我可能无效化整个表： 12345bool pv_area::store_would_trash(pv_t addr) { return (addr.kind == pvk_unknown || addr.kind == pvk_constant || (addr.kind == pvk_register &amp;&amp; addr.reg != m_base_reg));} 事实上说这种情况可能无效化整个表是不准确的。准确地说，是我们不能确定这次存储和我们现在的表有什么关系，为了方便起见，我们就直接认为这整个表的分析是不可能的，因而就将其抛弃了。这个函数还会被在其他地方调用，比如，考虑取一个值的问题： 12345678910111213pv_t pv_area::fetch(pv_t addr, CORE_ADDR size) { if (!m_entry || store_would_trash(addr)) { return pv_unknown(); } else { CORE_ADDR offset = addr.k; struct area_entry *e = find_entry(offset); if (e-&gt;offset == offset &amp;&amp; e-&gt;size == size) { return e-&gt;value; } else { return pv_unknown(); } }} 很显然，这个函数的核心还是保守估计。需要注意的是第一行判断，如果表里没有内容，或者这个地址和表无关，那就返回未知。这里，“和表无关”才是上面那个函数真正的语义。 当然，我们可以找找我们的表中有没有关于某个寄存器值的信息： 123456789101112131415161718bool pv_area::find_reg(struct gdbarch *gdbarch, int reg, CORE_ADDR *offset_p) { struct area_entry *e = m_entry; if (e) { do { if (e-&gt;value.kind == pvk_register &amp;&amp; e-&gt;value.reg == reg &amp;&amp; e-&gt;value.k == 0 &amp;&amp; e-&gt;size == register_size(gdbarch, reg)) { if (offset_p) { *offset_p = e-&gt;offset; } return true; } e = e-&gt;next; } while (e != m_entry); } return false;} 关于 gdbarch 结构体，现在只要知道它记录了架构信息即可，register_size 则返回某种架构中某个寄存器的大小。这个函数也没什么特别的，就是一个遍历操作。 接下来有一个稍微看起来复杂点但功能很简单的函数，也是这个类的最后一个函数： 12345678910111213141516void pv_area::scan(void (*func)(void *closure, pv_t addr, CORE_ADDR size, pv_t value), void *closure) { struct area_entry *e = m_entry; pv_t addr; addr.kind = pvk_register; addr.reg = m_base_reg; if (e) { do { addr.k = e-&gt;offset; func(closure, addr, e-&gt;size, e-&gt;value); e = e-&gt;next; } while (e != m_entry); }} 循环遍历整个表，对表中的每一项做一个自定义操作。函数指针使得整个函数看起来有些抽象，但也不难明白它的意思。 现在，我们已经获得了对一块内存区域的数据进行分析的工具，接下来，我们可以利用这些工具进行分析了。下一次将针对两种架构的整个前导代码分析过程做出解释，在那里，我们可以看见这些工具都是怎样被应用的，又能给出怎样的结果。","link":"/blog/3d571260/"},{"title":"GDB 源码分析 03：函数前导代码分析（下）","text":"在上一次分析中，我们基本上通读了对前导代码分析实现通用的支持的代码，在这里，我们将针对多种不同架构的代码进行分析。 这篇文章将不可避免地要求对一些架构中汇编指令有一定的熟悉程度，但基本上只需要了解汇编指令的含义即可，可以参考相关的开发者指南。我们将首先从相对简单的 RISC-V 架构的分析开始。 RISC-V 架构的前导代码分析 文件：riscv-tdep.c 在 RISC-V 架构下的前导代码分析只被用来在没有充足的 DWARF 调试信息的情况下跳过函数的前导代码1，因此它确实是比较简单的。但是，它仍然有保留栈帧缓存（frame cache）等相关功能，这使得它的代码还是不太简单。 核心函数定义如下： 1static CORE_ADDR riscv_scan_prologue(struct gdbarch *gdbarch, CORE_ADDR start_pc, CORE_ADDR end_pc, struct riscv_unwind_cache *cache); 这里面的大部分结构体应该都是在之前的分析中曾经见过的。唯一可能有点陌生的就是最后一个关于栈帧缓存的结构体，其形态如下： 1234567struct riscv_unwind_cache { int frame_base_reg; int frame_base_offset; trad_frame_saved_reg *regs; struct frame_id this_id; CORE_ADDR frame_base;} 其中前两个参数表明栈基地址寄存器和实际栈基地址到栈基地址寄存器的偏移量，后两个参数标识栈帧中存储的寄存器和栈帧的 id，在后面栈帧分析相关代码我们会仔细讨论；最后一个参数保存在进入此栈帧时的堆栈指针。 在进入函数时，首先进行了一系列初始化： 12CORE_ADDR cur_pc, next_pc, after_prologue_pc;CORE_ADDR end_prologue_addr = 0; 然后试图使用调试信息找到前导代码的上限，具体方法留待分析符号表的时候再讨论： 1234567after_prologue_pc = skip_prologue_using_sal (gdbarch, start_pc);if (after_prologue_pc == 0) { after_prologue_pc = start_pc + 100;}if (after_prologue_pc &lt; end_pc) { end_pc = after_prologue_pc;} 如果不能利用调试信息完成跳过，则我们给我们的代码起点加上一个足够大的数假装我们得到了一个合理的预测值；然后，如果这个预测值比原先传入的预测值更加精确，也就是说更小，那就采用这个预测值。 然后初始化寄存器并进行分析： 12345pv_t regs[RISCV_NUM_INTEGER_REGS];for (int regno = 0; regno &lt; RISCV_NUM_INTEGER_REGS; regno++) { regs[regno] = pv_register(regno, 0);}pv_area stack(RISCV_SP_REGNUM, gdbarch_addr_bit(gdbarch)); 然后我们根据 start_pc 和 end_pc 开始正式进行前导代码分析，这是一个大循环： 123for (next_pc = cur_pc = start_pc; cur_pc &lt; end_pc; cur_pc = next_pc) { /* Do something*/} 首先对代码进行解码，这一步是非常简单的，被隐藏的实现因为并不重要所以不多做分析，唯一需要说明的是指令长度不大于零表明解码失败： 1234struct riscv_insn insn;insn.decode(gdbarch, cur_pc);gdb_assert(insn.length() &gt; 0);next_pc = cur_pc + insn.length(); 接下来我们需要寻找用来调整栈的指令，这些指令大概有以下几种： addi 和 addiw 引起的，其目标寄存器和源寄存器都是 sp，这是用来调整栈的基地址的； sw 和 sd 引起的，其源寄存器为 fp 和 sp，这是用来向栈中保存寄存器的； addi 引起的，源寄存器为 sp 而目标寄存器为 fp 的以及 add 和 addw 引起的，源寄存器为 sp 和 zero，目标寄存器为 fp的，这是用来设置栈帧的； 其代码因为结构很简单但是较长所以不在此展示了，基本上就是利用中篇写好的各种工具，改寄存器的动数组，改内存的动 stack，除此之外做一下寄存器序号边界的检验即可。 接下来是对一些其他指令的处理，包括 auipc，lui，addi，add，ld，lw 和 mv，如果这一串代码到了无法再分析的地方，那就终止。终止时的 end_prologue_addr 设置为当前的 pc 值，即 curr_pc。 再往下就需要处理有 cache 的情形，这些会在我们讨论栈帧分析的时候再做讨论。 注意到，这里前导代码的含义似乎已经与最开始大相径庭。前导代码似乎包含了很多单纯的算术运算，对栈和寄存器的操作基本上都被置于其中。这一方面是因为更充分地分析函数运行时的数据流能够有助于后续的分析，另一方面是因为日渐复杂的编译器使得前导代码本身不再简单，因此必须以这种复杂的方式被加以分析——哪怕分析的内容是过度的，它也是“安全”的，这也是保守估计思想的一环。 i386 前导代码分析 文件：i386-tdep.c 前面已经讲过，对于 RISC-V 架构代码的前导代码分析是相对简单的，哪怕循环中的结构看起来很长，它还是易懂且亲切的。但是对于 i386 架构代码来说，它的代码复杂度几乎让人望而却步。接下来，我们走出摇篮，开始直面这个不可名状的巨物，首先从第一根触手——啊不，第一个函数开始： 1234567891011static CORE_ADDRi386_analyze_prologue (struct gdbarch *gdbarch, CORE_ADDR pc, CORE_ADDR current_pc, struct i386_frame_cache *cache) { pc = i386_skip_endbr(pc); pc = i386_skip_noop(pc); pc = i386_follow_jump(gdbarch, pc); pc = i386_analyze_struct_return(pc, current_pc, cache); pc = i386_skip_probe(pc); pc = i386_analyze_stack_align(pc, current_pc, cache); pc = i386_analyze_frame_setup(gdbarch, pc, current_pc, cache); return i386_analyze_register_saves(pc, current_pc, cache);} 啊哈，确实有点吓人不是吗？别急，我们慢慢来，你可以喝一杯茶，或者先读读 Intel 的开发者手册，或者看看 CTFWiki 中关于 ROP 的段落……如果准备好了，那我们直接开始。 第一个函数是对 endbr 的处理——明白为什么要读读 ROP 的相关内容了嘛？如果你没读，那也没事，在这里简单解释一下花不了多少时间。当我们面对一个程序且需要绕过它的部分功能，比如注册机时，我们会操作函数的返回地址，也就是说，面向返回地址编程（return-oriented programming，ROP），而 endbr 就是 Intel 引入的 CET 技术的结果： 当一个跳转发生时，CPU 的状态机切换到 WAIT_FOR_ENDBRANCH 状态，它会确保跳转发生后的下一条指令一定是 endbr 指令。但是，这个指令本身没有意义，它不执行，只起到了缩小攻击面的作用。 所以，明白我们要做什么了吗？没错，直接跳过它。因为它是函数入口必不可少的东西，但是对我们来说，不能说是举足轻重，也可以说是毫无意义了。因此，这个函数就是这样： 1234567891011static CORE_ADDR i386_skip_endbr(CORE_ADDR pc) { static const gdb_byte endbr32[] = {0xf3, 0x0f, 0x1e, 0xfb}; gdb_byte buf[sizeof(endbr32)]; if (target_read_code(pc, buf, sizeof(endbr32))) { return pc; } if (memcmp(buf, endbr32, sizeof(endbr32))) { return pc; } return pc + sizeof(endbr32);} 如果读不出指令，终止；如果不是 endbr32，终止——这是因为 CET 是可选开启的，可以调整为不需要 endbr 也能正常执行；如果是，跳过它。 i386_skip_noop 函数当然也是类似的：跳过 nop 指令以及一些功能类似的指令，它的框架如下： 123456789101112static CORE_ADDR i386_skip_noop(CORE_ADDR pc) { gdb_byte op; int check = 1; if (target_read_code(pc, &amp;op, 1)) { return pc; } while (check) { check = 0; /* Do something*/ } return pc;} 也是一样的，如果不能成功读取指令，那就直接终止，接下来的 nop 指令，有几个算几个，全都跳过。 首先检查 nop 指令本体，这很简单： 1234567if (op == 0x90) { pc += 1; if (target_read_code(pc, &amp;op, 1)) { return pc; } check = 1;} else // ... 先在这里停一下，稍微注意一下，i386 的非定长特征赤裸裸地暴露在我们眼前了。nop 指令只有 1 个字节长，而 endbr32 则是 4 个字节，这使得很多处理方式不够优雅，而不太优雅的情形还不止于此，下面的操作，则是一个更加不优雅但有用的案例： 123456789101112/* cont. */ if (op == 0x8b) { if (target_read_code(pc + 1, &amp;op, 1)) { return pc; } if (op == 0xff) { pc += 2; if (target_read_code(pc + 1, &amp;op, 1)) { return pc; } check = 1; }} 哦，忘了说了，0x8bff 是一条 mov edi, edi 指令。事实上，0x89ff 也是——这是因为这两种编码都是成立的。当然，这里只检查了前一种情况，这是因为…… 因为 Windows 的系统动态链接库用到了这条指令！每个函数都会以五个 0x8bff 开头，在执行的时候，CPU 自然而然地将其解析为 nop 的等价指令，当然也就不会发生什么。而这五个指令可以被填充成五个短程跳转指令，这就使得热更新变得可能：只需要改变这几个空位，就可以改变函数的一些功能。 那么，在直面了这里的险恶之后，我们就要被迫思考这可能带来什么结果了。还记得吗，在前面的分析中，我们从来不考虑跳转这回事，但是这时候我们不得不考虑了——如果发生了跳转，它还是在函数最开头，在分析都没有开始的地方，而且对于 Windows 动态链接库函数这可能是普遍的，那么放弃就显得有些过于仓促了。所以，下一个函数就是要解决这个问题： 1234567891011121314151617181920212223242526272829static CORE_ADDR i386_follow_jump(struct) { enum bfd_endian byte_order = gdbarch_byte_order(gdbarch); gdb_byte op; long delta = 0; int data16 = 0; if (target_read_code(pc, &amp;op, 1)) { return pc; } if (op == 0x66) { data16 = 1; op = read_code_unsigned_integer(pc + 1, 1, byte_order); } switch (op) { case 0xe9: if (data16) { delta = read_memory_integer(pc + 2, 2, byte_order); delta += 4; } else { delta = read_memory_integer(pc + 1, 4, byte_order); delta += 5; } break; case 0xeb: delta = read_memory_integer(pc + data16 + 1, 1, byte_order); delta += data16 + 2; break; } return pc + delta;} 如果对 i386 不熟悉的话，想必这时候已经有点晕了。这段代码事实上就是把 pc 跳到跳转的目标地址，支持的是 jmp 指令，也就是 0xe9 和 0xeb，它的编码自己查手册应当不难。需要注意的是 0x66 前缀，如果直接查或许查不到，它的意思是 data16，也就是说偏移量按 16 bit 解读，在我们这里，它事实上没有带来任何本质上的不同。 下一个函数的名字可能并不太容易让人理解它在表达什么，首先要考虑的是一个问题，一个函数如何返回结构体或指针？很显然，它将不得不在栈中开辟空间用以填充这个指针，这是一段额外的代码： 123popl %eax 0x58xchgl %eax, (%esp) 0x87 0x04 0x24 or xchgl %eax, 0(%esp) 0x87 0x44 0x24 0x00 这个函数就是用来跳过这种原型的，经历了上面几个函数，我想或许不需要附上代码也能大致猜出它长什么样子了，不过保险起见，代码如下： 12345678910111213141516171819202122232425262728293031323334static CORE_ADDR i386_analyze_struct_return(CORE_ADDR pc, CORE_ADDR current_pc, struct i386_frame_cache cache) { static gdb_byte_proto1[3] = {0x87, 0x04, 0x24}; static gdb_byte_proto2[4] = {0x87, 0x44, 0x24, 0x00}; gdb_byte buf[4]; gdb_byte op; if (current_pc &lt;= pc) { return pc; } if (target_read_code(pc, &amp;op, 1)) { return pc; } if (op != 0x58) { return pc; } if (target_read_code(pc + 1, buf, 4)) { return pc; } if (memcmp(buf, proto1, 3) != 0 &amp;&amp; memcmp(buf, proto2, 4 != 0)) { return pc; } if (current_pc == pc) { cache-&gt;sp_offset += 4; return current_pc; } if (current_pc == pc + 1) { cache-&gt;pc_in_eax = 1; return current_pc; } if (buf[1] == proto1[1]) { return pc + 4; } else { return pc + 5; }} 里面当然涉及到一些 cache 的处理，今天也不做分析——再分析下去这篇文章就太长了，鉴于我们已经花了太多笔墨来考虑这些具体的乏味的代码，接下来我们要快进了。 i386_skip_probe，跳过最开始的一次对 _probe 函数的调用： 123pushl constantcall _probeaddl esp, 4 i386_analyze_stack_align 跳过用来对齐栈的代码： 123leal reg, esp[4]andl esp, -16(or -256)pushl reg[-4] 或者 1234pushl regleal reg, esp[8]andl esp, -16(or -256)pushl reg[-4] i386_analyze_frame_setup 跳过建立栈帧的代码，即这个系列最开始介绍的那一段代码，当然，中间可能插入了别的东西； i386_analyze_register_saves 跳过存储寄存器的代码，也就是一开始的一连串 push。 好，快进结束。反思一下，这个代码和分析 RISC-V 的部分显得极为不同。分析 RISC-V 时，我们根据的是抽象解读和逐一代码的分析，而分析 i386 时我们将其分块，因为编译器生成的代码的形式是完全一致的。新老架构在这里如此不同，我们或许可以窥见技术世界中年迈者的从容和无奈…… 关于 DWARF 调试信息的内容，在以后读到相关代码时将详细解释，在这里，只需要理解它是一种用来描述整个程序功能的信息文件即可。↩︎","link":"/blog/38fef59d/"},{"title":"局部哈密顿问题的复杂性 01","text":"原文为：arXiv:quant-ph/0406180 这篇文章挺难读的，但是也很有意思。大概会分成四次把解读更新完，其实原文在大部分地方已经讲的很清楚了，但是一些计算过程可能需要澄清，毕竟文中的证明有些给的实在简洁。 这篇文章主要讨论的问题是 \\(\\text{2-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 问题的复杂度。作为第一部分这里主要把论文的前四节的比较复杂的证明过了一遍，主要是投影引理和对 Kitaev 构造的重述，虽然还没进入正题但也并不算简单，还是很有仔细研究的价值的。 基本定义 首先，我们快速回顾一下经典计算理论中复杂度类 \\(\\mathsf{NP}\\) 的量子版本，即 \\(\\mathsf {QMA}\\) 的概念： 给定 \\(\\varepsilon = \\varepsilon(|x|) = 2^{-\\Omega(|x|)}\\)，其中 \\(|x|\\) 为字符串 \\(x\\) 的长度。称一个承诺问题 \\(L = (L_{yes}, L_{no})\\) 在类 \\(\\mathsf{QMA}\\) 中，若存在一个量子的、多项式时间的验证者 \\(V\\) 和一个多项式 \\(p\\)，使得： \\(\\forall x \\in L_{yes}, \\exists |\\xi\\rangle \\in \\mathcal{B}^{\\otimes p(|x|)}, \\mathbf{P}(V(|x\\rangle, |\\xi\\rangle) = 1) \\geqslant 1 - \\varepsilon\\) \\(\\forall x \\in L_{no}, \\exists |\\xi\\rangle \\in \\mathcal{B}^{\\otimes p(|x|)}, \\mathbf{P}(V(|x\\rangle, |\\xi\\rangle) = 1) \\leqslant \\varepsilon\\) 其中 \\(\\mathcal B\\) 指描述一个量子比特的 Hilbert 空间。 注意到，只需要取 \\(\\varepsilon \\leqslant 1/3\\)，事实上也就够了，它们产生的复杂度类都是等价的。 在经典计算复杂度理论中，Cook-Levin 定理表明， \\(\\text{SAT}\\) 问题是 \\(\\mathsf{NP}\\)-完备的。在 \\(\\mathsf{QMA}\\) 中，我们取局部哈密顿问题 \\(\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 来作为其等价物。这个问题定义如下： 我们称一个算子 \\(H: \\mathcal B^{\\otimes n} \\rightarrow \\mathcal B^{\\otimes n}\\) 是 \\(k\\)-局部哈密顿（\\(k\\)-local Hamiltonian），若 \\(H = \\sum_{j=1}^rH_j\\)，其中每个 \\(H_i\\) 都是在最多 \\(k\\) 个量子比特上的哈密顿算子。 在 \\(n\\) 个量子比特上，给定一个 \\(k\\)-局部哈密顿 \\(H = \\sum_{j=1}^r H_j\\)，其中 \\(r=\\text{poly}(n)\\)。每个 \\(H_j\\) 的范数 \\(||H_j|| \\leqslant \\text{poly}(n)\\)，其中的每个元素也可以被 \\(\\text{poly}(n)\\) 个比特表示出来。有两个输入 \\(a, b\\) 满足 \\(a &lt; b\\)，我们需要判断， \\(H\\) 的最小特征值至多为 \\(a\\) 还是大于 \\(b\\)。 在下文中，我们记 \\(H\\) 的最小特征值为 \\(\\lambda(H)\\)；若 \\(\\Pi\\) 为 \\(\\mathcal{B}^{\\otimes n}\\rightarrow \\mathcal{S}\\) 的投影，则称 \\(\\Pi H\\Pi\\) 为 \\(H\\) 在子空间 \\(\\mathcal S\\) 上的限制，记作 \\(H\\vert_\\mathcal S\\)。 投影引理（Projection Lemma） 这个引理的核心意义就在于通过局部哈密顿近似一个全局哈密顿。考虑 Hilbert 空间 \\(\\mathcal H\\)，\\(H_1\\) 是其上的一个哈密顿，对于一个子空间 \\(\\mathcal S \\subseteq \\mathcal H\\) ，取一个哈密顿 \\(H_2\\)，使得 \\(\\mathcal S\\) 是其特征值 \\(0\\) 的特征子空间，且 \\(\\lambda(H_2|_\\mathcal {S^{\\perp}}) \\gg ||H_1||\\) 。考虑 \\(H = H_1 + H_2\\)，投影引理表明，\\(\\lambda(H)\\) 非常接近于 \\(\\lambda(H_1\\vert_\\mathcal S)\\)。 我们称哈密顿 \\(H\\) 的惩罚值（penalty value）为 \\(\\min_{x \\in \\mathcal H, ||x|| = 1}\\langle x | H | x \\rangle\\)。 直觉地，我们发现，\\(H_2\\) 对于那些在 \\(\\mathcal S^{\\perp}\\) 上有分量的向量给出了非常大的惩罚值，因此，\\(\\lambda(H)\\) 对应的特征向量一定接近于 \\(\\mathcal S\\)，也就是接近于 \\(H_1|_\\mathcal S\\) 的特征向量。 接下来给出一个形式化的描述： 令 \\(H = H_1 + H_2\\) 为 Hilbert 空间 \\(\\mathcal H = \\mathcal S + \\mathcal S^\\perp\\) 上的两个哈密顿之和，哈密顿 \\(H_2\\) 的零特征空间为 \\(S\\)，而其在 \\(S^\\perp\\) 上的特征向量对应的特征值至少为 \\(J &gt; 2||H_1||\\)，于是： \\[ \\lambda(H_1\\vert_\\mathcal S) - \\frac{||H_1||^2}{J - 2||H_1||} \\leqslant \\lambda(H) \\leqslant \\lambda(H_1\\vert_\\mathcal{S}) \\] 注意到，如果 \\(J \\geqslant 8||H_1||^2 + 2||H_1|| = \\text{poly}(||H_1||)\\)，则我们有 \\(\\lambda(H_1\\vert_\\mathcal S) - 1/8 \\leqslant \\lambda(H) \\leqslant\\lambda(H_1\\vert_\\mathcal S)\\)。 这个引理的证明非常简单。首先表明 \\(\\lambda(H) \\leqslant \\lambda(H_1\\vert_\\mathcal S)\\) ：令 \\(|\\eta\\rangle \\in \\mathcal S\\) 为 \\(H_1|_\\mathcal S\\) 对应 \\(\\lambda(H_1|_\\mathcal S)\\) 的特征向量，则 \\[ \\langle \\eta|H|\\eta \\rangle = \\langle \\eta|H_1|\\eta \\rangle + \\langle \\eta|H_2|\\eta\\rangle = \\lambda (H_1\\vert_\\mathcal S) \\] 因此 \\(\\lambda(H_1|_\\mathcal S)\\) 也是 \\(H\\) 的特征值，\\(\\lambda(H) \\leqslant \\lambda(H_1|_\\mathcal S)\\)。 接下来证明 \\(\\lambda(H)\\) 的下界：将单位向量 \\(|v\\rangle \\in \\mathcal H\\) 分解成 \\(|v\\rangle = \\alpha_1|v_1\\rangle + \\alpha_2 |v_2\\rangle\\)，其中 \\(|v_1\\rangle\\) 和 \\(|v_2\\rangle\\) 分别为 \\(\\mathcal S\\) 和 \\(\\mathcal S^\\perp\\) 中的两个单位向量，\\(\\alpha_1, \\alpha_2\\) 为非负实数且平方和为 \\(1\\) 。令 \\(K = ||H||\\)，则： \\[\\begin{aligned} \\langle v|H|v \\rangle &amp;\\geqslant \\langle v|H_1|v\\rangle + J\\alpha_2^2\\hfill\\newline &amp;= \\alpha_1^2\\langle v_1|H|v_1\\rangle + 2\\alpha_1\\alpha_2 \\text{Re} \\langle v_1 |H_1|v_2\\rangle + \\alpha_2^2\\langle v_2|H_1|v_2\\rangle + J\\alpha_2^2\\hfill\\newline &amp;= (1 - \\alpha_2^2)\\langle v_1|H|v_1\\rangle + 2\\alpha_1\\alpha_2 \\text{Re} \\langle v_1 |H_1|v_2\\rangle + \\alpha_2^2\\langle v_2|H_1|v_2\\rangle + J\\alpha_2^2\\hfill\\newline &amp;\\geqslant \\langle v_1|H|v_1\\rangle - K\\alpha_2^2 - 2K\\alpha_2 - K \\alpha_2^2 + J \\alpha_2\\hfill\\newline &amp;= \\langle v_1|H|v_1\\rangle + (J - 2K)\\alpha_2^2 - 2K\\alpha_2 \\hfill\\newline &amp;\\geqslant \\lambda(H_1|_\\mathcal S) + (J - 2K)\\alpha_2^2 - 2K\\alpha_2\\hfill\\newline &amp;\\geqslant \\lambda(H_1|_\\mathcal S) - \\frac{K^2}{J - 2K} \\end{aligned}\\] Kitaev 构造 这里会经常用到一个非常好用的性质，对于张量积和矩阵乘法，有： \\[ (A\\otimes B)(C\\otimes D) = AB\\otimes CD \\] 直觉上看，这很好理解，当然也是有条件的。这里懒得复述其条件和证明了，反正在这都能用。 在这一节中，作者尝试应用上述投影引理重述 Kitaev 关于 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 是 \\(\\mathsf{QMA}\\) 完全的证明。也就是说，需要表明，所有 \\(\\mathsf{QMA}\\) 中的问题都可以被多项式地规约到 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\)。 我们考虑验证者 \\(V_x = V(|x\\rangle, \\cdot) = U_T\\cdots U_1\\)，其中 \\(T = \\text{poly}(|x|)\\) 作用在 \\(N = \\text{poly}(|x|)\\) 个量子比特上。最开始前面的 \\(m = p(|x|)\\) 个量子比特包含被给出的证明，后面的 \\(N - m\\) 个辅助量子比特被初始化为 \\(0\\) ，而电路的最终结果被放在第一个量子比特上。 我们构造一个作用在 \\(n = N + \\log(T+1)\\) 个量子比特上哈密顿 \\(H\\) ，其中前面 \\(N\\) 个量子比特表征计算，最后的 \\(\\log(T + 1)\\) 个量子比特表征时钟 \\(0, \\cdots, T\\) 的可能值，使得： \\[ H = H_{out} + J_{in}H_{in} + J_{prop}H_{prop} \\] 其中 \\(J_{in}\\) 和 \\(J_{prop}\\) 为 \\(N\\) 为变量的大多项式，在后面将详细讲述其构造，而其他参量构造为： \\[\\begin{aligned} H_{in} \\hfill&amp;= \\sum\\limits^N_{i=m+1} |1\\rangle\\langle1|_i\\otimes|0\\rangle\\langle0|\\hfill\\\\ H_{out} \\hfill &amp;= (T+1)|0\\rangle\\langle0|_1 \\otimes |T\\rangle\\langle T|\\hfill\\\\ H_{prop} \\hfill &amp;= \\sum\\limits_{t=1}^T H_{prop, t}\\hfill\\\\ H_{prop, t} \\hfill &amp;= \\frac 1 2 \\big(I \\otimes |t\\rangle\\langle t| + I \\otimes |t-1\\rangle\\langle t-1| - U_t \\otimes |t\\rangle\\langle t-1| - U_t^\\dagger|t-1\\rangle\\langle t| \\big) \\end{aligned}\\] 其中 \\(|\\alpha\\rangle\\langle\\alpha|_i\\) 表示在第 \\(i\\) 个量子比特为 \\(|\\alpha\\rangle\\) 的子空间上的投影。上面的张量积中，第一部分都是在 \\(N\\) 个量子比特的空间上的作用，第二部分则是为了处理时钟量子比特，\\(U_t\\) 和 \\(U_t^\\dagger\\) 作用的量子比特与在原来的电路中完全相同。直观地讲，现在构造的这一系列哈密顿量中： \\(H_{in}\\) 检查我们的输入值是正确的，也就是说，后面的 \\(N - m\\) 个量子比特确实被初始化为 \\(0\\)； \\(H_{out}\\) 检查表征结果的输出位； \\(H_{prop}\\) 检查我们的结果确实是按照原来电路的状态转移方式得到的。 由于我们只有 \\(\\log(T + 1) = O(\\log n)\\) 个时钟量子比特，所以这些哈密顿算子都是 \\(O(\\log n)\\)-局部的。接下来我们表明任何一个 \\(\\mathsf{QMA}\\) 中的问题都能规约为对上述 \\(H\\) 的 \\(O(\\log n)\\text{-}\\large\\text{L}\\small{\\text{OCAL }}\\large{\\text{H}}\\small{\\text{AMILTONIAN}}\\) 问题： 如果电路 \\(V_x\\) 对某个输入 \\(|\\xi, 0\\rangle\\) 的接受概率大于 \\(1-\\varepsilon\\)，那么哈密顿 \\(H\\) 有一个小于 \\(\\varepsilon\\) 的特征值；如果它对所有输入 \\(|\\xi, 0\\rangle\\) 的接受概率小于 \\(\\varepsilon\\)，那么哈密顿 \\(H\\) 的所有特征值均大于 \\(3/4 - \\varepsilon\\)。 这个引理的前半部分非常好证明，只需要取 \\[ |\\eta\\rangle = \\frac{1}{\\sqrt{T+1}} \\sum\\limits^T_{t=0}U_t\\cdots U_1 |\\xi, 0\\rangle \\otimes |t\\rangle \\] 接下来就可以表明： \\[ \\langle \\eta|H_{prop}|\\eta \\rangle = 0 \\] 记 \\(\\eta_j = U_j\\cdots U_1|\\xi, 0\\rangle \\otimes |j\\rangle\\)，注意到： \\[ \\langle \\eta|H_{prop}|\\eta\\rangle = \\sum\\limits_{t=1}^t \\langle\\eta|H_{prop, t}|\\eta\\rangle \\] 再次逐项展开，得： \\[ \\langle \\eta|(\\frac 1 2 I \\otimes |t\\rangle\\langle t|)|\\eta\\rangle = \\frac {1} {2(T+1)} \\langle \\sum\\limits_{t=0}^T \\eta_t |(I\\otimes |t\\rangle\\langle t|)|\\sum\\limits_{t=0}^T \\eta_t\\rangle \\] 这里如果将 \\(\\eta_t\\) 再展开，就会出现交叉项，首先考虑能不能消除它： \\[\\begin{aligned} \\langle \\eta_i | (I \\otimes |t\\rangle \\langle t|) | \\eta_j\\rangle &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle \\otimes |j\\rangle)^\\dagger(I\\otimes|t\\rangle\\langle t |)(U_i \\cdots U_1 |\\xi, 0\\rangle \\otimes |i\\rangle)\\hfill\\\\ &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_i \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle i|t\\rangle\\langle t|j\\rangle)\\hfill\\\\ &amp;= (U_j \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_i \\cdots U_1 |\\xi, 0\\rangle) \\otimes 0\\hfill\\\\ &amp;= 0\\hfill \\end{aligned}\\] 那么非交叉项呢？事实上按照上面的式子，我们已经表明，所有这些和式中只会剩下一项： \\[\\begin{aligned} \\langle \\eta|(I \\otimes |t\\rangle\\langle t|)|\\eta\\rangle &amp;= (U_t \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_t \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t|t\\rangle\\langle t|t\\rangle) \\hfill\\\\ &amp;= I \\otimes 1\\hfill\\\\ &amp;= I\\hfill \\end{aligned}\\] 第二项如法炮制： \\[\\begin{aligned} \\langle \\eta|(I \\otimes |t-1\\rangle\\langle t-1|)|\\eta\\rangle &amp;= (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger I (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t-1|t-1\\rangle\\langle t-1|t-1\\rangle)\\hfill\\\\ &amp;= I \\otimes 1\\hfill\\\\ &amp;= I\\hfill \\end{aligned}\\] 后面两项同理展开，不过需要注意左边的不再是 \\(I\\) 了： \\[\\begin{aligned} \\langle \\eta|(U_t \\otimes |t\\rangle\\langle t -1 |)|\\eta\\rangle &amp;= \\langle \\eta_{t}|(U_t \\otimes |t\\rangle\\langle t-1|)|\\eta_{t-1}\\rangle\\hfill\\\\ &amp;= (U_{t} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger U_t (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t|t\\rangle\\langle t-1|t-1\\rangle)\\hfill\\\\ &amp;= I \\otimes1\\hfill\\\\ &amp;= I\\hfill\\\\ \\langle \\eta|(U_t \\otimes |t -1\\rangle\\langle t |)|\\eta\\rangle &amp;= \\langle \\eta_{t-1}|(U_t^\\dagger \\otimes |t-1\\rangle\\langle t|)|\\eta_{t}\\rangle\\hfill\\\\ &amp;= (U_{t-1} \\cdots U_1 |\\xi, 0\\rangle)^\\dagger U_t^\\dagger (U_{t} \\cdots U_1 |\\xi, 0\\rangle) \\otimes (\\langle t-1|t-1\\rangle\\langle t|t\\rangle)\\hfill\\\\ &amp;= I \\otimes1\\hfill\\\\ &amp;= I\\hfill\\\\ \\end{aligned}\\] 于是我们成功地表明了 \\(\\langle \\eta|H_{prop}|\\eta \\rangle = 0\\)。 接下来的式子就简单了： \\[\\begin{aligned} \\langle \\eta|H_{in}|\\eta \\rangle = 0, \\langle \\eta|H_{out}|\\eta \\rangle &lt; \\varepsilon \\end{aligned}\\] 合起来就有： \\[ \\lambda(H) \\leqslant\\langle \\eta|H|\\eta \\rangle = \\langle \\eta|H_{out}|\\eta \\rangle &lt; \\varepsilon \\] 嗯，确实非常好证明，容易到原作者都没有仔细写。接下来的第二部分会更加复杂一些：假设 \\(V_x\\) 对于所有输入 \\(|\\xi, 0\\rangle\\) 的接受概率都小于 \\(|\\varepsilon\\rangle\\) ，令 \\(\\mathcal S_{prop}\\) 为 \\(H_{prop}\\) 的基态空间，很显然，它是 \\(2^N\\) 维的，它的一组基是： \\[ |\\eta_i\\rangle = \\frac {1}{\\sqrt{T + 1}} \\sum\\limits^{T}_{t=0} U_t\\cdots U_1|i\\rangle \\otimes |t\\rangle \\] 其中 \\(|i\\rangle\\) 表示 \\(N\\) 个进入计算的量子比特，它们的特征值为 \\(0\\)，\\(\\mathcal S_{prop}\\) 事实上就表征了正确的状态转移方式。接下来我们要对这个子空间应用可爱的投影引理，为了做到这一点，首先需要标明 \\(J_{prop}H_{prop}\\) 对处于 \\(\\mathcal{S}_{prop}^\\perp\\) 中的状态给出了一个 \\(\\text{poly}(N)\\) 的惩罚值，也就是说，\\(H_{prop}\\) 中最小的非零特征值反比于某个关于 \\(N\\) 的多项式。于是，我们给出以下命题： \\(\\exists c &gt; 0\\)，使得 \\(H_{prop}\\) 的最小非零特征值至少为 \\(c/T^2\\)。 这个命题的证明也不太复杂，首先构造一个基的变换： \\[ W = \\sum\\limits_{t=0}^T U_t\\cdots U_1 \\otimes |t\\rangle\\langle t| \\] 将其应用到 \\(H_{prop}\\) 上： \\[ W^\\dagger H_{prop}W = \\sum\\limits_{t=1}^T I \\otimes \\frac 1 2(|t\\rangle\\langle t| + |t-1\\rangle\\langle t-1| - |t\\rangle\\langle t-1| - |t-1\\rangle\\langle t|) \\] 这里的计算方式和上面的证明很像，就不再重复了。当然，这个变换并不会改变 \\(H_{prop}\\) 的特征谱，但它成功地将我们的哈密顿块对角化了： \\[ W^\\dagger H_{prop}W = I \\otimes \\begin{bmatrix} \\frac 1 2 &amp; -\\frac 1 2 &amp; 0 &amp;&amp;&amp;\\cdots&amp; 0\\\\ -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;&amp; \\vdots\\\\ 0 &amp; -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;\\vdots \\\\ &amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\vdots\\\\ \\vdots&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 \\\\ &amp;&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 \\\\ 0 &amp;&amp;\\cdots&amp;&amp; 0 &amp;-\\frac 1 2 &amp;\\frac 1 2 \\end{bmatrix} \\] 漂亮，这样我们就可以开始估计 \\((T+1) \\times (T+1)\\) 小矩阵的特征值了。作者在这里说，使用“标准方法”即可，本来打算用 Givens 变换求解，但是算着实在烦人，于是在这里给出一个（看上去）稍微简单点的思路： 考虑到第一行和最后一行破坏了这个矩阵的美感，我们先把它们无视掉，来看一看中间这个矩阵： \\[ \\begin{bmatrix} 1 &amp; -\\frac 1 2 &amp; 0 &amp;&amp;&amp;\\cdots&amp; 0\\\\ -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;&amp; \\vdots\\\\ 0 &amp; -\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 &amp; \\ddots &amp;\\vdots \\\\ &amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\ddots&amp;\\vdots\\\\ \\vdots&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 &amp; 0 \\\\ &amp;&amp;&amp;0 &amp;-\\frac 1 2 &amp; 1 &amp; -\\frac 1 2 \\\\ 0 &amp;&amp;\\cdots&amp;&amp; 0 &amp;-\\frac 1 2 &amp; 1 \\end{bmatrix} \\] 这个矩阵是个 Toeplitz 矩阵，其特征值还是比较容易获得的：考虑其特征多项式为 \\(\\varphi_n(\\lambda)\\) ，若其为一个 \\(n \\times n\\) 矩阵，则可以很容易地得到： \\[ \\varphi_n(\\lambda) = (1-\\lambda)\\varphi_{n-1}(\\lambda) - \\frac 1 4 \\varphi_{n-2}(\\lambda) \\] 然后观察一下这个式子，考虑到： \\[ \\varphi_0(\\lambda) = 1, \\varphi_1(\\lambda) = 1-\\lambda \\] 发现它长得和第二类切比雪夫多项式的递推式长得有点神似： \\[ \\varphi_0(x) = 1, \\varphi_1(x) = 2x, \\varphi_n(x) = 2x\\varphi_{n-1}(\\lambda) - \\varphi_{n-2}(\\lambda) \\] 那么我们可以考虑折腾一下这个矩阵，让它能够变成切比雪夫多项式的样子，只要把 \\(-\\frac 1 2\\) 这个系数提出来就可以了。这样的话得到的多项式就是： \\[ \\varphi_0 (\\lambda) = 1, \\varphi_1(\\lambda) = 2-\\lambda, \\varphi_n(\\lambda) = (2-\\lambda)\\varphi_{n-1}(\\lambda) - \\varphi_{n-2}(\\lambda) \\] 这下子我们就大功告成，只欠换元，令 \\(2x = 2-\\lambda\\)，于是 \\(\\phi_n(x) = \\varphi_n(\\lambda) = U_n(x)\\)。 接下来的事情就好办了，众所周知，第二类切比雪夫多项式的表达式是： \\[ U_n = \\frac{\\sin((n+1)\\cos^{-1}x)}{\\sin(\\cos^{-1}x)}, |x| \\leqslant 1 \\] 它的根就是： \\[ \\cos\\frac{k\\pi}{n+1}, k = 1, 2, \\cdots, n \\] 所以我们求出现在这个矩阵的特征值为： \\[ 1-\\cos\\frac{k\\pi}{n+1}, k = 1, 2, \\cdots, n \\] 接下来我们考虑按照和最后一行展开原来的矩阵，新的特征多项式为： \\[ \\psi(\\lambda) = (\\frac 1 2-\\lambda)\\xi(\\lambda) - \\frac 1 4 \\xi\\prime(\\lambda) \\] 其中： \\[\\begin{aligned} \\xi(\\lambda) &amp;= (\\frac 1 2 - \\lambda)\\varphi_{T-1}(\\lambda) - \\frac 1 4 \\varphi_{T-2}(\\lambda)\\hfill\\\\ \\xi\\prime(\\lambda) &amp;= (\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda) - \\frac 1 4 \\varphi_{T-3}(\\lambda)\\hfill\\\\ \\end{aligned}\\] 嗯，看上去很丑。整理一下，就有： \\[ \\psi(\\lambda) = (\\frac 1 2 - \\lambda)^2\\varphi_{T-1}(\\lambda) - \\frac 1 2(\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda)+ \\frac 1 {16} \\varphi_{T-3}(\\lambda) \\] 看上去似乎就没什么办法了，但是别忘了我们有 \\(\\varphi_n(\\lambda)\\) 的递推公式，现在这是我们最后的希望了： \\[\\begin{aligned} \\psi(\\lambda) &amp;= (\\frac 1 2 - \\lambda)^2\\varphi_{T-1}(\\lambda) - \\frac 1 2(\\frac 1 2 - \\lambda)\\varphi_{T-2}(\\lambda) - \\frac 1 4 \\varphi_{T-1}(\\lambda) + \\frac{1-\\lambda}4 \\varphi_{T-2}(\\lambda)\\hfill\\\\ &amp;= (\\lambda^2-\\lambda) \\varphi_{T-1}(\\lambda) + \\frac{\\lambda}{4}\\varphi_{T-2}(\\lambda)\\hfill\\\\ &amp;= -\\lambda((1-\\lambda)\\varphi_{T-1}(\\lambda) - \\frac 1 4\\varphi_{T-2}(\\lambda))\\hfill\\\\ &amp;= -\\lambda\\varphi_{T}(\\lambda)\\hfill \\end{aligned}\\] 诶嘿，这下我们就发现了，原来加边矩阵的特征值和没加边的情形是一样的。所以，特征值中的较小值就是： \\[ 1 - \\cos\\frac{\\pi}{T+1} \\geqslant \\frac c {T^2} \\] 这个不等式挺显然的，就不做证明了。 好，准备工作做完了，接下来我们就要应用我们的投影引理了。上面表明了，\\(J\\geqslant cJ_{prop}/T^2\\)。我们取： \\[ H_1 = H_{out} + J_{in}H_{in}， H_2 = J_{prop}H_{prop} \\] 只需要令 \\(J_{prop} = JT^2/c=\\text{poly}(n)\\)，那么 \\(\\lambda(H) \\geqslant \\lambda(H_1|_\\mathcal {S_{prop}}) - \\frac 1 8\\)。接下来我们考察 \\(\\lambda(H_1|_\\mathcal {S_{prop}})\\)。 考虑 \\(\\mathcal{S}_{in} \\subset \\mathcal{S}_{prop}\\) 为 \\(H_{in}|_{\\mathcal S_{prop}}\\) 的基态空间，很显然，它也是一个 \\(2^m\\) 维子空间，其基为 \\[ |\\eta_i\\rangle = \\frac{1}{\\sqrt{T+1}}\\sum\\limits^T_{t=0}U_t\\cdots U_1|j, 0\\rangle \\otimes |t\\rangle \\] 其中 \\(|j\\rangle\\) 为前面 \\(m\\) 个计算用的量子比特的基。接下来在 \\(\\mathcal S_{prop}\\) 中应用投影引理，其中： \\[ H_1 = H_{out}|_{\\mathcal S_{prop}}, H_2 = J_{in}H_{in}|_{\\mathcal S_{prop}} \\] 很显然地，\\(||H_1|| \\leqslant ||H_{out}|| = T+1 = \\text{poly}(N)\\)。而任意处于 \\(\\mathcal S_{in}^\\perp\\) 中的 \\(H_2\\) 的特征向量的特征值都至少是 \\(J_{in} / (T+1)\\)，因此，可以找到 \\(J_{in} = \\text{poly}(N)\\) 使得 \\(\\lambda(H_1+H_2) \\geqslant \\lambda(H_{out}|_{\\mathcal S_{in}}) - \\frac 1 8\\)。 根据我们在上面给出的接受概率小于 \\(\\varepsilon\\) 的假定，我们可以表明，\\(\\lambda(H_{out}|_{\\mathcal S_{in}}) &gt; 1-\\varepsilon\\)。综上所述，\\(\\lambda(H) \\geqslant 1-\\varepsilon - \\frac 2 8 = \\frac 3 4 - \\varepsilon\\)。","link":"/blog/dab644cb/"},{"title":"从 Kolmogorov 复杂度到 Martin Löf 随机性检验（上）","text":"Per Martin-Löf, The Definition of Random Sequences, Information and Control, 9, 602-619(1966) 考虑一个在有限字母表中所有字符串的集合。记字符串 \\(x = \\xi_1\\xi_2\\dots\\xi_n\\) 的长度 \\(l(x) = n\\)。接下来我们需要考虑的问题是，这个序列有多复杂？ 很显然，直观地讲，一个“随机”（我们很快会回到这一点上来）字符串要比一个有规律的字符串复杂地多。同样很直观地，我们可以把一个字符串的复杂度定义为某种“最简单的描述方法的长度”，Kolmogorov 算术复杂度就是从这个视角出发做出的形式化定义。 “描述方法”和 Kolmogorov-Solomonoff 定理 接下来我们需要反思，“描述方法”应该如何被形式化地定义出来？既然本文的 tag 中带有计算理论，很自然的一种想法就是，“描述方法”就是一种算法。 在这里，我们使用“算法”这个概念来表达一种从一个有限二进制序列到一个有限字母表上的单子的映射。算法概念的更精确的形式化定义可以采用递归论的定义模式或者其他等价的形式（本文中将不再展开），这并不影响后文的探讨。 记 \\(A\\) 为一种算法，\\(A(p) = x\\)，\\(p\\) 为一个有限二进制串，\\(x\\) 为一个有限字母表上的字符串，我们称 \\(p\\) 是在算法 \\(A\\) 下对 \\(x\\) 的描述。接下来，延续我们前面的直观认识，我们可以定义相对于算法 \\(A\\) 字符串 \\(x\\) 的复杂度为： \\[ K_A(x) = \\min\\limits_{A(p) = x}(l(p)) \\] 那么，很自然的一个问题是，是否一定存在这样的二进制串 \\(p\\) 来对任意字符串 \\(x\\) 做出描述？答案是否定的。只要考虑一个平凡的算法 \\(A_0\\)，它将任意二进制串 \\(p\\) 都映射到字符串 \\(x_0\\)，那么，其他的字符串就都不能在这个算法下做出描述。因此，为了定义的严谨性，我们需要补充说明： \\[ K_A(x) = + \\infty, \\mathrm{if}\\ \\forall p, A(p) \\neq x \\] 现在，我们剩下的一个问题就是，我们不能摆脱算法 \\(A\\) 对我们的定义的限制。我们在考虑一个序列的复杂度时，很显然不是要考虑一个字符串“在某种描述方法下”的复杂度，我们需要使得它成为一个只与字符串 \\(x\\) 有关的数。为了实现这个定义，就需要引入 Kolmogorov-Solomonoff 定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(x) \\leqslant K_B(x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 这个算法在 Kolmogorov 的著作中被称为渐进最优的（asymptotically optimal），在 Solomonoff 的著作中被称为通用的（universial），上述定理的证明如果我不鸽的话会丢进本文的附录或者其他文章里。总之，现在我们已经有了一个最好的算法来讨论如何描述字符串 \\(x\\)，于是，我们就可以定义这个字符串的复杂度 \\(K(x) = K_A(x)\\)，称其为 Kolmogorov 复杂度，或者简单地称为复杂度。 同样地，我们可以引入条件复杂度的概念。考虑一个两变量的算法 \\(A(p, x)\\)，\\(x\\) 为一个有限字母表上的字符串，若 \\(A(p, x) = y\\)，则我们将其称为在 \\(x\\) 的条件下对（可能不同于 \\(x\\) 的）字母表上的字符串 \\(y\\) 的描述。称在 \\(x\\) 的条件下相对于算法 \\(A\\) 的 \\(y\\) 的复杂度为： \\[ K_A(y \\vert x) = \\min\\limits_{A(p, x) = y}(l(p)) \\] 这个定义也是很自然的，同样与上面的讨论和我们的直观感受匹配。幸运地是，亲爱的 Kolmogorov 先生同样给出了一个与上面的定理相对应的定理： 存在一个算法 \\(A\\)，使得对于任意算法 \\(B\\)， \\[ K_A(y \\vert x) \\leqslant K_B(y \\vert x) + c \\] 其中 \\(c\\) 为一常数，且其只与 \\(A\\) 和 \\(B\\) 有关。 因此，我们也记 \\(K(y\\vert x) = K_A(y \\vert x)\\)，并称其为在 \\(x\\) 的条件下 \\(y\\) 的条件复杂度。 很直观的，对于任意长度为 \\(n\\) 的二进制串 \\(x\\)，都有 \\[ K(x \\vert n) \\leqslant n + c \\] 其中 \\(n\\) 是用于描述这个字符串所用的最多比特数，在最坏情况下，我们需要将整个串都硬编码到代码当中，那么当然需要 \\(n\\) 的长度。而 \\(c\\) 则是机器相关的常数。 同时，我们可以尝试给出一个下界，满足 \\[ K(\\xi_1\\xi_2\\dots\\xi_n \\vert n) \\geqslant n - c \\] 的序列一共有 \\((1-2^{-c})2^n\\) 个。这个结论也很平凡，留给读者自证。 于是，我们发现，当 \\(n\\) 很大的时候，会有很多字符串的复杂度的渐进上界是在 \\(O(n)\\) 这个最大的级别的。Kolmogorov 指出，这可以使我们形式化地定义一个字符串的随机性。 一些评述 看起来，对于二元算法的定义事实上意义不是很大，因为 \\(n\\) 同样可以以 \\(\\log n\\) 的复杂度编写到程序之中，这对于我们的结果并没有影响。事实上，很多较现代的论文提供了另外一种定义形式，例如 Peter D. Grünwald and Paul M. B. Vitányi, Algorithmic Information Theory 中给出的定义是： \\[ K(x) = \\min\\limits_{y, p: p(y) = x}(l(p) + l(y)) \\] 这种定义形式似乎更加符合我们的预期。另外，也将一个对象的 Kolmogorov 编码定义为 \\(E*(x)\\)，是最短的能够打印 \\(x\\) 然后停下的代码。 在这种定义形式下，我们就可以给出三种分类： 简单的对象：\\(O(\\log n)\\)，其原因已经在前面解释过了，因为 \\(n\\) 需要被硬编码进去 完全偶然对象（completely random objects）：\\(n + O(\\log n)\\)，也是显然的 随机对象（stochastic objects）：\\(\\alpha n + o(n)\\) 如果 \\(x_i\\) 是一个随机变量 \\(X_i\\) 的实现，其分布为 \\(P\\)，则这个对象是随机的，其中 \\(\\alpha &lt; 1\\)。比较常见的例子是二项分布，其 \\(\\alpha = H(p)\\) 为二值熵（binary entrophy） \\[ H(p) = -p\\log p - (1-p) \\log(1-p) \\] 随机对象的情形可以类比于扔一个有缺陷的硬币，硬币的缺陷使得这个序列不再成为完全随机的，当然，很显然，\\(p = 0.5\\) 时， \\(H(p) = 1\\)，序列还是完全偶然的。 另一个很遗憾的问题是，\\(K(x)\\) 不是可计算的，在 [Li and Vitányi, 1997] 中，他们表明它是上半可计算的（upper semicomputable），或者简单地理解就是，它是可以被近似的，但近似算法很慢，且不能确定其终点。但是，也有一些方式来解决这个问题，比如通用编码（[Cover and Thomas, 1991]），最小描述长度原理（MDL, [Solomonoff, 1997]）等方式的近似。 Blum 和 Burgin 的公理系统对于这个领域来说也是相当重要的，他们给出了关于这些性质的普遍描述，如果不鸽的话大概也会专门开一篇文章来介绍他们的成果，嗯，如果不鸽的话。","link":"/blog/dd3e0497/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 2","text":"在上一次讲座中，简单地介绍了量子电路的基本概念和量子编程的方法。这一次课将分析几个量子电路的例子和代码实现，包括： 2 位半加器 量子近似优化算法（Quantum Approximation Optimization Algorithm, QAOA），以 Ising 问题为例 Grover 搜索 2 位半加器的实现 2 位半加器的功能如下： \\[ |q_0q_1\\rangle|q_2q_3\\rangle \\rightarrow |q_0q_1\\rangle|q_0q_1 + q_2q_3\\rangle \\] 为了更好地理解其功能，我们给出几个例子： \\[ \\begin{array}{**lr**} |2\\rangle|1\\rangle \\rightarrow |2\\rangle|3\\rangle\\newline |2\\rangle \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow |2\\rangle \\dfrac{|2\\rangle + |3\\rangle}{\\sqrt{2}}\\newline \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\dfrac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\rightarrow \\dfrac{|0\\rangle + |1\\rangle + |1\\rangle + |2\\rangle}{2} \\end{array} \\] 尤其值得关注的是第二行例子，我们似乎“并行地”做了加法，这种并行性有赖于量子电路的线性性，即对于电路 \\(U\\)，有 \\[ U(|\\psi_1\\rangle + |\\psi_2\\rangle) = U|\\psi_1\\rangle + U|\\psi_2\\rangle \\] 其电路实现已经在上一讲的例子中给出了，如下图： 从左往右，第一部分为初始化模块，这个模块通过一系列门电路将全 0 的初始值转化为我们所需要的值。 第二部分为量子傅里叶变换（Quantum Fourier Transform, QFT）模块，这个模块将信息从寄存器值转移到指数上来。我们不妨首先计算一下作用于 \\(q_2\\) 和 \\(q_3\\) 上的变换矩阵： \\[ \\begin{bmatrix} 1&amp;1&amp;1&amp;1\\newline 1&amp;-1&amp;1&amp;-1\\newline 1&amp;i&amp;-1&amp;-i\\newline 1&amp;-i&amp;-1&amp;i \\end{bmatrix} \\] 未完待续","link":"/blog/42beb83a/"},{"title":"量子计算与计算复杂度（M. N. Vyalyi） Lecture 1","text":"在之前（还没更新）的课程中，主要讨论了量子计算的几种范式，并对其进行了一些形式化。从这里开始，我们将尝试对量子计算的复杂性理论做出详细的解释和说明，并表明其与经典计算复杂度类的关系。首先，有必要快速回顾一下经典复杂性理论带给我们的一些结果。 经典的复杂性理论研究的对象是受到资源限制的计算。我们需要在“简单的”和“困难的”问题之间做出区分，并将这种区分形式化。首先，我们需要考虑计算所需的资源：时间、空间，还有什么吗？ 交互资源（interaction）也是一种非标准的资源，在我们后面的讨论中，我们会经常用到相关的概念。交互资源主要有两种，谕示机（oracle）和实验者（prover）。谕示机知道问题的答案，而且它是可信的；实验者也知道问题的答案，但它是不可信的，需要提供一个证明。 谕示机（oracle）一词本来被译为“先知、神谕”，事实上这个义项可以很好地理解其意图；实验者（prover）这个说法相当奇怪，按照其直白的含义，应该叫做受质询者之类，但 prover 这个词本身并没有这种含义，所以姑且将其作此翻译。 另，实验者这个词在标准的教科书中似乎并没有出现，在下文看来它似乎与验证者（verifier）相应，在此注明。1 既然我们要讨论量子计算，那么量子过程（quantum process）也是一种资源，我们将其归为自然法则（laws of nature）一类。这一类还包括概然过程（probabilistic process），其与量子过程的差别在后文中会进一步提及。 概然过程（probabilistic process）一词似乎看起来应该译为随机过程，但是随机过程（stochastic process）在概率论中为一个专有名词，为了避免发生混淆，在这里亦作别译。 接下来我们快速地回顾以下经典复杂度理论的成果。 基本概念 为了讨论计算复杂度，我们需要从计算开始讲起。为了定义一种计算模型，我们需要给出构形空间（configuration space，可以理解为状态空间），即其所有可能的状态的总和。而一个基本的计算步骤（elementary computation step）可以被定义为一些从构形空间到其自身的函数，一个算法（algorithm）则是一串基本的计算步骤的序列。 在众多计算模型当中，我们选用图灵机（Turing machine）作为基本的计算模型。在这个模型中，构形为一个有限字母表上的序列、一个指针和一个控制态的三元组，一个基本的计算步骤为改变指针所指位置的字符、改变一格指针位置或者改变控制态。在这种情形下，我们可以很轻松地给出时间和空间复杂度的定义： 运行时间正比于一个算法所需的基本计算步骤的个数 所需花费的空间正比于任一构型中的字符串的长度 以 \\(\\vert x \\vert\\) 作为字符串 \\(x\\) 的长度，我们可以定义图灵机 \\(M\\) 代表的算法的最坏时间复杂度为： \\[ t_M(n) = \\max\\limits_{\\vert x \\vert = n} T_M(x) \\] 其中 \\(T_M(x)\\) 为输入 \\(x\\) 时图灵机 \\(M\\) 达到停机状态（halting state）所需的步数。 在复杂度理论的讨论中，我们感兴趣的是 \\(t_M(x)\\) 的渐进界，尤其是渐进上界。一种很重要的情形是多项式时间的算法，我们形式化地定义其为： \\[ t(n) \\in \\mathrm{poly}(n),\\ \\mathrm{if}\\ \\exists c_1, c_2 \\in \\mathbb{Z}_+:\\forall n \\in \\mathbb{Z}_+ t(n) \\leqslant c_1n^{c_2} \\] 一般的，我们认为有多项式时间界的算法为足够快地或者足够高效的。 大部分计算模型都是多项式时间等价的（考虑扩展的 Church-Turing 论题），因此这种分类在一般的计算模型中都是普遍可靠的，而且，它使得我们可以使用更加有力的工具（图灵机）来给出复杂度的渐进界。2 从中，我们可以抽象出复杂度类（complexity class）的概念。一个复杂度类是一些可以被给定的资源解决的问题的集合。 为了下面讨论的便利，我们定义几种计算问题。 函数的计算。记 \\(A^\\ast\\) 为一个有限集合 \\(A\\) 上的字符串的总和，计算 \\(f:A^\\ast \\rightarrow A^\\ast\\)。以下的文本中，我们都将 \\(A\\) 假定为 \\(\\{0, 1\\}\\)。 决策问题（decision problem）。我们称 \\(L \\subseteq A^\\ast\\) 为一个语言（language），一个决策问题就是计算 \\(L\\) 的示性函数（indicator function） \\(\\mathbb{1}_L(x)\\) 。 承诺问题（promise problem）。考虑两个不交的语言 \\(L_0\\) 和 \\(L_1\\)。给定 \\(x \\in L_0 \\cup L_1\\)，需要求解 \\(\\mathbb{1}_{L_1}(x)\\) 。很显然，对语言 \\(L\\) 的决策问题等价于 \\((L, L)\\) 的承诺问题。 一个很重要的复杂度类为 \\(\\mathsf{P}\\) 类，我们称 \\(L \\in \\mathsf{P}\\) ，若存在一个确定性算法使得其决策问题关于输入长度有多项式时间界。对于承诺问题，定义是类似的。 更广泛的，可以定义类 \\(\\mathsf{FP}\\)，如果一个函数 \\(f:A^\\ast \\rightarrow A^\\ast\\) 可以在多项式时间内被计算，则称 \\(f \\in \\mathsf{FP}\\) 。 复杂度类 \\(\\mathsf{NP}\\) 、规约和完全类 对于复杂度 \\(\\mathsf{NP}\\) 的定义，我们需要回到之前给出的交互资源的提法。直观地讲，在计算过程中，有验证者（verifier）和实验者。验证者只能解决 \\(\\mathsf{P}\\) 类问题，而实验者可以解决任何问题。而实验者是不受信的，因此它必须向验证者给出证明。我们形式化这种直观，将其定义如下： 我们称 \\(L \\in \\mathsf{NP}\\)，若存在 \\(V(x, y) \\in \\mathsf{P}\\) 和多项式 \\(p\\) 满足以下条件： 完备性：若 \\(x \\in L\\)，则 \\(\\exists y\\)，使得 \\(V(x, y) = 1\\) 且 \\(\\vert y \\vert \\leqslant p(\\vert x \\vert)\\) 。 可靠性：若 \\(x \\not \\in L\\)，则 \\(\\forall y\\)，\\(V(x, y) = 0\\) 。 其中 \\(V(x, y)\\) 就是对验证者的形式化。为了证明答案 \\(x\\) 是正确的，实验者需要给出证明 \\(y\\) ，其长度（耗费的空间资源）也应该是多项式的，使得利用 \\(y\\) 验证 \\(x\\) 是一个 \\(\\mathsf{P}\\) 类问题。而如果答案 \\(x\\) 是错误的，无论给出什么证明，都不能使得验证者误认为 \\(x\\) 是正确的。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{NP}\\)。我们下面不加证明地给出三个 \\(\\mathsf{NP}\\) 问题的例子，它们可能是属于 \\(\\mathsf{NP} \\setminus \\mathsf{P}\\) 的： \\(\\text{3-SAT}\\): 给定一个三变量的合取范式，确定其是否可满足。 \\(\\text{3-COLOR}\\): 给定一个图，确定其是否能被三种颜色染色。 \\(\\large\\text{P}\\small\\text{ARTITION}\\): 给定一列正整数，确定是否存在一个平均分划。 考虑计算问题的复杂度的排序方式。很直观地，如果我们能够将某个问题化作另一个问题，这个问题肯定不会比另一个问题更难解决。这种直觉使我们能够定义规约（reduction）这个概念，它定义了复杂度类中的一种二元关系。 我们称一个承诺问题 \\((L_0, L_1)\\) 可以多项式地规约（polynomial reduction, 或者 Karp reduction）到一个问题 \\((K_0, K_1)\\) ，如果存在一个函数 \\(f \\in \\mathsf{FP}\\)，使得： \\[ x \\in L_1 \\iff f(x) \\in K_1, x \\in L_0 \\iff f(x) \\in K_0 \\] 记作 \\((L_0, L_1) \\leqslant_p (K_0, K_1)\\) 。 很容易表明，这个二元关系具备传递性，只需观察到 \\(\\mathsf{FP}\\) 类中的函数的复合还在 \\(\\mathsf{FP}\\) 类中即可。这个二元关系引导我们定义出一个复杂度类中“最难”的问题，这些问题被称为完全问题（complete），因为它们事实上表征了整个复杂度类最难解的一些问题。 我们称一个问题 \\(P \\in \\mathcal{C}\\) 为 \\(\\mathcal{C}\\)-完全的，如果对任意 \\(L \\in \\mathcal{C}\\) ，有 \\(L \\leqslant_p P\\) 成立。 \\(\\mathsf{NP}\\) 类中同样包含一个完全集，这已经由 Cook 和 Levin 证明（通过 \\(\\text{3-SAT}\\) 问题）。事实上，上面举出的三个例子均为 \\(\\mathsf{NP}\\text{-complete}\\) 问题。 复杂度类的补、\\(\\text{co-}\\mathsf{NP}\\) 类 这里的考虑很好理解，既然我们定义了复杂度类，那么它自然而然地可以定义出一个补：设 \\(\\mathcal{C}\\) 为一复杂度类，则 \\(\\text{co-}\\mathcal{C}\\) 为其补，对任意 \\(L \\in \\mathcal{C}\\)，\\(\\bar L \\in \\text{co-}\\mathcal C\\)。 一个很显然的命题是，\\(\\mathsf{P} = \\text{co-}\\mathsf{P}\\)。我们只需要将算法的输出翻转一下，就可以得到 \\(\\text{co-}\\mathsf{P}\\) 问题的解。 \\(\\text{co-}\\mathsf{NP}\\) 和 \\(\\mathsf{NP}\\) 的关系仍然悬而未决，我们在这里给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\) 的问题： \\(\\large\\text{I}\\small\\text{NTEGER FACTORING}\\) 输入：一个正整数 \\(N\\) 的二进制表示 输出：\\(N\\) 的质因数分解 很显然，这不是一个决策问题。我们需要将其改写成决策问题： \\[ \\large\\text{B}\\small{\\text{IT}}\\large\\text{O}\\small{\\text{F}}\\large\\text{F}\\small\\text{ACTORING} = \\{\\langle N, i \\rangle : N \\text{ 的质因数分解第 } i \\text{ 位为 } 1\\} \\] 证明这个问题在 \\(\\mathsf{NP}\\) 中是显然的，实验者只需要给出一个分解作为证明即可。 注意到，判断一个数是否为素数是可以在多项式时间内完成的，参考 AKS 素数测试。 证明其属于 \\(\\text{co-}\\mathsf{NP}\\) 也并不困难，和上述方法是完全相同的。 我们还可以不加证明的给出一个 \\(\\mathsf{NP} \\cap \\text{co-}\\mathsf{NP}\\text{-complete}\\) 的承诺问题的实例，决策问题的例子仍然是未知的。 \\(\\large\\text{O}\\small\\text{NE}\\large\\text{O}\\small\\text{F}\\large\\text{T}\\small\\text{WO}\\) 输入：两个合取范式 \\(C_1\\), \\(C_2\\) 承诺：两者中必有一个是可满足的 问题：表明 \\(C_1\\) 是可满足的 概率性的计算，类 \\(\\mathsf{BPP}\\) 和 \\(\\mathsf{PP}\\) 如前所述，计算过程中，随机数也是一种资源。接下来我们探讨可以访问随机数的算法。在这里，我们将随机位认为是独立平均分布的，\\(0\\) 和 \\(1\\) 出现的概率各占一半。 对于一个涉及随机数的计算，出错也是难免的，因此，我们要提出的第一个问题是，如何定义一个成功的计算？ 直觉地，我们认为，一个计算如果正确的概率“过半”，那它就是成功的，设 \\(f(x)\\) 为目标函数，\\(\\text{Res}(x)\\) 为计算结果，我们可以形式化这个定义为： \\[ \\forall x, \\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; a \\leqslant \\frac 1 2 \\] 注意到我们留了一个 \\(a\\) 作为参量。这是因为，\\(a\\) 是否等于 \\(\\frac 1 2\\) 的情形是完全不同的，其区别的来源是一个算法能否被强化（amplify），即，经过多次重复这个算法（ \\(t\\) 次），然后取出现最频繁的结果，这样似乎能够增加其准确性。事实上，可以证明以下命题成立： 若 \\(\\mathbf{P}[\\text{Res}(x) \\neq f(x)] &lt; \\frac 1 2 - \\epsilon\\)，则增强后的算法出错的概率为： \\[ \\Big(2\\sqrt{\\frac 1 4 - \\epsilon ^2}\\Big)^t \\] 也就是说，\\(a &lt; \\frac 1 2\\) 时，算法出错的概率可以逐渐收敛到 \\(0\\)，若 \\(a = \\frac 1 2\\)，则我们并不能得出有用的结果。这样我们可以定义两个复杂度类： 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{BPP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 2 3\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 3\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 很显然，\\(\\mathsf{P} \\subseteq \\mathsf{BPP}\\)，只需要取 \\(p = 0\\) 即可。 若存在一个多项式 \\(p\\) 和一个多项式时间内的确定性算法 \\(V(x, r)\\) 满足以下条件，则称 \\((L_0, L_1) \\in \\mathsf{PP}\\) ： 完备性：若 \\(x \\in L_1\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &gt; \\frac 1 2\\) 可靠性：若 \\(x \\in L_0\\)，则 \\(\\mathbf{P}_{r \\leftarrow \\mathcal{U}_{p(|x|)}}[V(x, r) = 1] &lt; \\frac 1 2\\) 其中 \\(\\mathcal{U}_m\\) 是在长度 \\(m\\) 的字符串上的均匀分布。 同样显然地，\\(\\mathsf{BPP} \\subseteq \\mathsf{PP}\\)，\\(\\mathsf{PP} = \\text{co-}\\mathsf{PP}\\)。 接下来，我们要表明另一个复杂度层级，\\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)，从而使我们的复杂度继承关系形如下图： 为了给出这个证明，我们需要引出一些额外的定义，并从另一个角度重新表述 \\(\\mathsf{NP}\\) 和 \\(\\mathsf{PP}\\) 的定义。 证明 \\(\\mathsf{NP} \\subseteq \\mathsf{PP}\\)：非确定性图灵机、\\(\\mathsf{\\#P}\\)-函数和间隙函数 非确定性图灵机（non-deterministic Turing machine, NTM）与确定性图灵机的差别在于，在每一步计算中，它可以在转移函数之间做出随机选择。因此，NTM 的计算过程是一棵含根的树，而非一列构形空间的序列。树的根部为起始状态，叶为停机状态，从根部到叶的一条路径称为一条计算路径（computation path），计算路径的最大值被定义为这个 NTM 的运行时间。 我们考虑停机状态有两种，接受（accept）和拒绝（reject）。记接受的路径的总数为 \\(\\text{acc}_M(x)\\)，其中 \\(M\\) 为一图灵机，\\(x\\) 为一输入。 接下来我们定义 \\(\\mathsf{\\#P}\\)-函数和间隙函数的概念。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}_+\\) 为一个 \\(\\mathsf{\\#P}\\)-函数，若存在一个多项式运行时间的 NTM \\(M\\) 使得 \\(\\forall x, f(x) = \\text{acc}_M(x)\\)。称一函数 \\(f:\\{0, 1\\}^\\ast \\rightarrow \\mathbb{Z}\\) 为一个间隙函数（gap function），若存在两个 \\(\\mathsf{\\#P}\\)-函数 \\(g, h\\)，使得 \\(\\forall x, f(x) = g(x) - h(x)\\)。 未完待续 绿色方块标识的内容均为译注，下同。↩︎ 蓝色方块标识的内容均为原注，下同。↩︎","link":"/blog/b5738fe7/"},{"title":"量子编程（Maksim Dimitrijev） Lecture 1","text":"在近二十年间，出现了两种量子计算的主要范式。一种是量子门编程模型（gate-based model of quantum computing），也叫通用量子计算（universal quantum computing）；另一种是量子退火方法（quantum annealing），也叫绝热量子计算（adiabatic quantum computing）。从数学角度上看，这两种模型具备同等的计算能力，但在实践上，两者有显著的不同。 前两次讲座主要介绍量子门编程模型，第一次讲座的内容包括量子比特（quantum bits, qubits）和量子门（quantum gates）、以及量子电路（quantum circuits）。 量子比特和量子门 正如经典计算机一样，量子计算机也一样由门电路构成，不过其用来表示信息的单元为量子比特而非高低电平，其运算模块为量子门而非数字电路的逻辑门。 单个的量子比特 单个量子比特为计算的基本单元，处在 \\(0\\) 和 \\(1\\) 的叠加状态（superposition）之中。我们可以使用类似描述振幅的方式去描述一个量子比特 \\(|\\psi\\rangle\\)： \\[ |\\psi\\rangle = \\psi_0|0\\rangle + \\psi_1|1\\rangle = \\big ( \\begin{matrix} \\psi_0 \\\\ \\psi_1 \\end{matrix} \\big ) \\] 其中 \\(\\psi_0\\) 和 \\(\\psi_1\\) 均为复数。可以将 \\(|0\\rangle\\) 和 \\(|1\\rangle\\) 理解成一组基： \\[ |0\\rangle = \\begin{bmatrix} 1 \\newline 0 \\end{bmatrix} \\newline |1\\rangle = \\begin{bmatrix} 0 \\newline 1 \\end{bmatrix} \\] 这两个复数需要满足归一化条件： \\[ \\langle \\psi \\vert \\psi \\rangle = |\\psi_0|^2 + |\\psi_1|^2 = 1 \\] 因此，我们可以表明， \\[ \\exists \\theta \\in [0, \\pi], \\mathrm{s. t.} |\\psi_0| = \\cos \\frac{\\theta}{2}, |\\psi_1| = \\sin \\frac{\\theta}{2} \\] 因为全局相位对其状态无影响，我们可以不失一般性地令 \\[ \\psi_0 = \\cos \\frac \\theta 2 \\newline \\psi_1 = e^{i\\phi}\\sin \\frac \\theta 2 \\] 其中 \\(\\phi \\in [0, 2\\pi)\\) 表示复系数之间的相对相位。 基于这些特性，我们可以在 Bloch 球面中表达一个量子比特，如下图： 其中的 \\(r^x, r^y, r^z\\) 可以以投影的方式给出： \\[ \\mathbf r = \\begin{bmatrix} r^x \\newline r^y \\newline r^z \\end{bmatrix} = \\begin{bmatrix} \\sin\\theta\\cos\\phi \\newline \\sin\\theta\\sin\\phi \\newline \\cos\\theta \\end{bmatrix} = \\begin{bmatrix} \\langle\\psi|\\sigma^x|\\psi\\rangle \\newline \\langle \\psi|\\sigma^y|\\psi\\rangle \\newline \\langle \\psi|\\sigma^z|\\psi\\rangle \\newline \\end{bmatrix} \\] 其中 \\(\\langle\\psi|\\sigma|\\psi\\rangle = \\vert \\psi \\rangle^\\dagger \\sigma \\vert \\psi \\rangle\\)，其中 \\(A^\\dagger\\) 表示 \\(A\\) 的共轭转置，\\(\\sigma^x\\)，\\(\\sigma^y\\)，\\(\\sigma^z\\) 为 Pauli 矩阵： \\[ \\sigma^x = \\begin{bmatrix} 0 &amp; 1 \\newline 1 &amp; 0 \\end{bmatrix}, \\sigma^y = \\begin{bmatrix} 0 &amp; -i \\newline i &amp; 0 \\end{bmatrix}, \\sigma^z = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; -1 \\end{bmatrix} \\] 关于 Bloch 球面，在第十讲中会有更详尽的叙述。需要注意，在进行测量时，一个量子比特会坍缩到 \\(0\\) 或者 \\(1\\) 的定态，其测量结果为 \\(0\\) 的概率为 \\(|\\psi_0|^2\\)，为 \\(1\\) 的概率为 \\(|\\psi_1|^2\\)。 量子门 量子门可以看作是对 \\(|\\psi\\rangle\\) 在 Bloch 球面上的旋转操作，事实上就是一些 \\(2 \\times 2\\) 的酉矩阵。基于 Pauli 矩阵我们可以很方便的构造出绕坐标轴旋转的 Pauli 门： \\[ R^x(\\theta) = e^{-\\frac{i\\theta\\sigma^x}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -i\\sin\\theta 2 \\newline -i\\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^y(\\theta) = e^{-\\frac{i\\theta\\sigma^y}{2}} = \\begin{bmatrix} \\cos \\frac \\theta 2 &amp; -\\sin\\theta 2 \\newline \\sin \\frac\\theta 2 &amp; \\cos \\frac \\theta 2 \\end{bmatrix} \\newline R^z(\\theta) = e^{-\\frac{i\\theta\\sigma^z}{2}} = \\begin{bmatrix} e^{-\\frac{i\\theta}{2}} &amp; 0 \\newline 0 &amp; e^{\\frac{i\\theta}{2}} \\end{bmatrix} \\newline \\] 在实际的实现中，只会实现部分基本旋转，然后将其组合起来以实现真正的旋转门。例如，IBM Q 实现了 \\(R^x(\\frac\\theta 2)\\) 和 \\(R^z(\\theta)\\)。 可以按照如下公式组合形成能够完成绕任意轴旋转的旋转门，其中 \\(\\vec n\\) 是旋转轴的单位向量： \\[ R^{\\vec n}(\\theta) = e^{-\\frac{i\\theta\\vec n\\vec \\sigma}{2}} = I\\cos\\frac \\theta 2 - in_i\\sigma^i\\sin \\frac \\theta 2 \\] 其中 \\(I\\) 为恒等矩阵，\\(i = x, y, z\\) 还有其他常用的门，罗列如下： \\[ X = \\sigma^x, Y = \\sigma^y, Z = \\sigma^z \\newline H = \\frac 1 {\\sqrt 2} \\begin{bmatrix} 1 &amp; 1 \\newline 1 &amp; -1 \\end{bmatrix}, T = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; e^{\\frac{i\\pi}{4}}\\end{bmatrix}, S = T^2 = \\begin{bmatrix} 1 &amp; 0 \\newline 0 &amp; i\\end{bmatrix} \\] 其中比较重要的是 \\(X\\) 门，又称 \\(NOT\\) 门、翻转门（flipping gate）；\\(H\\) 门被称为 Hadamard 门，\\(T\\) 和 \\(S\\) 为相移门。 多个量子比特的情形 在具备多个量子比特的情况下，只需要由 Kronecker 积（张量积，tensor product）将它们组合起来即可。我们首先构造这样一组基： \\[ |q_0q_1q_2\\dots q_{n-1}\\rangle = |q_0\\rangle \\otimes |q_1\\rangle \\otimes |q_2\\rangle \\otimes \\dots \\otimes|q_{n - 1}\\rangle \\] 其中 \\(q_i = 0, 1\\)，可以发现，\\(q_0q_1\\dots q_{n-1}\\) 是一个大小在 \\(0\\) 到 \\(2^n - 1\\) 之间的数 \\(j\\) 的二进制表示。记 \\(|q_0q_1...q_{n-1}\\rangle = |j\\rangle\\)，于是可以将一个 \\(n\\) bit 的系统表示为 \\(\\sum\\limits_{j}\\psi_j|j\\rangle\\)。 涉及多个量子比特的门同样可以用 Kronecker 积表出，记 \\(U_i\\) 为只对第 \\(i\\) 个比特做 \\(U\\) 操作的门，则： \\[ U_i = |q_0q_1\\dots q_{i-1}\\rangle U(q_i) |q_{i+1}q_{i+2}\\dots q_{n-1}\\rangle \\] 则很显然可以得出： \\[ U_i =\\underbrace{\\overbrace{I \\otimes I \\otimes \\cdots \\otimes I}^{i-1\\text{个}} \\otimes U \\otimes I \\otimes I \\cdots \\otimes I}_{n\\text{个}} \\] 当使用多个量子比特的系统时，很显然我们不只是想操作其中的某一个比特，而是要对其中的比特进行关联的操作，例如，当某比特为某状态时，对另一比特做某操作。受控的量子门（Controlled-U gate）就实现了这一点： \\[ CU_{i_1i_2}|q_0q_1\\dots q_{n-1}\\rangle = \\begin{cases} |q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 0 \\newline |U_{i_2}|q_0q_1\\dots q_{n-1}\\rangle, &amp; q_{i_1} = 1 \\end{cases} \\] 一个暂时用不上的附注：在做 \\(CU\\) 门运算之后，全局相位会变为相对相位。 常见的多比特门如下： \\[ CNOT = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;0&amp;1\\newline 0&amp;0&amp;1&amp;0 \\end{bmatrix}, CZ = \\begin{bmatrix} 1&amp;0&amp;0&amp;0\\newline 0&amp;1&amp;0&amp;0\\newline 0&amp;0&amp;1&amp;0\\newline 0&amp;0&amp;0&amp;-1 \\end{bmatrix} \\] 读者不难自证，它们之间存在如下联系： \\[ CNOT = (I\\otimes H)CZ(I \\otimes H) \\] 量子电路及其编程 量子电路的结构类似下图： 上图表示的是量子电路中的一个 2 位半加器，最左边将几个比特初始化，从左向右依次由不同的量子门对每个比特进行处理，最终结果输出在右侧。 在实际用 Python 进行编程时，一般使用 qiskit 作为电路前端，后端模拟器有以下三种选择： qasm_simulator：初始值全 \\(0\\)，无噪声影响下的测量结果； statevector_simulator：在测量导致量子态坍缩之前的直接计算结果； unitary_simulator：给出计算过程的酉矩阵。","link":"/blog/dbb7e980/"}],"tags":[{"name":"源码阅读","slug":"源码阅读","link":"/blog/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"},{"name":"程序分析","slug":"程序分析","link":"/blog/tags/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"计算复杂性理论","slug":"计算复杂性理论","link":"/blog/tags/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7%E7%90%86%E8%AE%BA/"},{"name":"量子计算","slug":"量子计算","link":"/blog/tags/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97/"},{"name":"计算理论","slug":"计算理论","link":"/blog/tags/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"复杂度","slug":"复杂度","link":"/blog/tags/%E5%A4%8D%E6%9D%82%E5%BA%A6/"},{"name":"概率论","slug":"概率论","link":"/blog/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"信息论","slug":"信息论","link":"/blog/tags/%E4%BF%A1%E6%81%AF%E8%AE%BA/"},{"name":"数学","slug":"数学","link":"/blog/tags/%E6%95%B0%E5%AD%A6/"},{"name":"抽象代数","slug":"抽象代数","link":"/blog/tags/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0/"},{"name":"群论","slug":"群论","link":"/blog/tags/%E7%BE%A4%E8%AE%BA/"}],"categories":[{"name":"源码阅读笔记","slug":"源码阅读笔记","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"},{"name":"论文笔记","slug":"论文笔记","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"},{"name":"GDB 源码分析","slug":"源码阅读笔记/GDB-源码分析","link":"/blog/categories/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/GDB-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"name":"课程笔记","slug":"课程笔记","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"},{"name":"计算理论","slug":"论文笔记/计算理论","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/"},{"name":"量子算法与编程暑期讲习班","slug":"课程笔记/量子算法与编程暑期讲习班","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/"},{"name":"Kempe(2005)","slug":"论文笔记/计算理论/Kempe-2005","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/Kempe-2005/"},{"name":"Martin-Löf(1966)","slug":"论文笔记/计算理论/Martin-Lof-1966","link":"/blog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E7%90%86%E8%AE%BA/Martin-Lof-1966/"},{"name":"量子编程","slug":"课程笔记/量子算法与编程暑期讲习班/量子编程","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/%E9%87%8F%E5%AD%90%E7%BC%96%E7%A8%8B/"},{"name":"量子计算复杂性","slug":"课程笔记/量子算法与编程暑期讲习班/量子计算复杂性","link":"/blog/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/%E9%87%8F%E5%AD%90%E7%AE%97%E6%B3%95%E4%B8%8E%E7%BC%96%E7%A8%8B%E6%9A%91%E6%9C%9F%E8%AE%B2%E4%B9%A0%E7%8F%AD/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7/"},{"name":"上课笔记","slug":"上课笔记","link":"/blog/categories/%E4%B8%8A%E8%AF%BE%E7%AC%94%E8%AE%B0/"},{"name":"抽象代数续论","slug":"上课笔记/抽象代数续论","link":"/blog/categories/%E4%B8%8A%E8%AF%BE%E7%AC%94%E8%AE%B0/%E6%8A%BD%E8%B1%A1%E4%BB%A3%E6%95%B0%E7%BB%AD%E8%AE%BA/"}]}